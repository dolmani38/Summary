{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "GAN based Korean summarizer using probability distribution by phrase",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary/blob/master/GAN-based_Korean_summarizer_using_probability_distribution_by_phrase.v0.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQCxNatSIOk"
      },
      "source": [
        "# GAN based Korean summarizer using probability distribution by phrase\r\n",
        "\r\n",
        "---\r\n",
        "이훈석(1), 안순홍(2), 김승훈(교신)\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "## Abstract\r\n",
        "\r\n",
        " 영어의 경우 Sate of art를 달성한 요약 알고리즘 및 모델들이 개발 되어 졌다. 대부분 GAN 이나 AVE 알고리즘을 이용하여 문장을 생성하는 방식을 기반으로 한다.\r\n",
        "영어의 경우 English Gigaword와 같이 원문과 요약문 데이터셋을 대량으로 구비하고 있어, 요약 모델을 생성하는데 유리하다. 하지만 아직 한국어의 경우 양질의 대량 여약 데이터셋이 준비되어 있지 않다. 하여, 한국어의 경우 좋은 성능의 요약 알고리즘이 아직 연구가 미비하다.\r\n",
        " 본 연구에서는 원문에 대한 유사 확율을 구문(?)별 추출하고 높은 확률의 구문만을 골자로 하여 나머지 원문의 구문을 재활용 추출하여 한국에 문법에 맞게 재조합 시키는 방법으로 원문을 요약하기 방법을 제안한다.[방식의 명칭을 지어야 함]\r\n",
        "이를 통해, 대량의 요약문 데이터셋이 없어도 원문을 요약할 수 있으며, 특히, 스토리 흐름이 있는 문성의 경우, 일부 발췌가 아닌 전체 스토리를 요약할 수 있는 장점을 갖는다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBmgUn9GV7Fm"
      },
      "source": [
        "## Introduction\r\n",
        "\r\n",
        "ref : https://www.machinelearningplus.com/nlp/text-summarization-approaches-nlp-example/\r\n",
        "\r\n",
        "When you open news sites, do you just start reading every news article? Probably not. We typically glance the short news summary and then read more details if interested. Short, informative summaries of the news is now everywhere like magazines, news aggregator apps, research sites, etc.\r\n",
        "\r\n",
        "Well, It is possible to create the summaries automatically as the news comes in from various sources around the world.\r\n",
        "\r\n",
        "The method of extracting these summaries from the original huge text without losing vital information is called as Text Summarization. It is essential for the summary to be a fluent, continuous and depict the significant.\r\n",
        "\r\n",
        "In fact, the google news, the inshorts app and various other news aggregator apps take advantage of text summarization algorithms.\r\n",
        "\r\n",
        "In this post, I discuss and use various traditional and advanced methods to implement automatic Text Summarization.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "> * Types of Text Summarization\r\n",
        "\r\n",
        "> Text summarization methods can be grouped into two main categories: Extractive and Abstractive methods\r\n",
        "\r\n",
        "> * Extractive Text Summarization\r\n",
        "\r\n",
        "> It is the traditional method developed first. The main objective is to identify the significant sentences of the text and add them to the summary. You need to note that the summary obtained contains exact sentences from the original text.\r\n",
        "\r\n",
        "> * Abstractive Text Summarization\r\n",
        "\r\n",
        "> It is a more advanced method, many advancements keep coming out frequently(I will cover some of the best here). The approach is to identify the important sections, interpret the context and reproduce in a new way. This ensures that the core information is conveyed through shortest text possible. Note that here, the sentences in summary are generated, not just extracted from original text.\r\n",
        "\r\n",
        "In the next sections, I will discuss different extractive and abstractive methods. At the end, you can compare the results and know for yourself the advantages and limitations of each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aADtcrL_XtG1"
      },
      "source": [
        "# Related Work\r\n",
        "\r\n",
        "* Text Summarization using Gensim with TextRank\r\n",
        "\r\n",
        "> gensim is a very handy python library for performing NLP tasks. The text summarization process using gensim library is based on TextRank Algorithm\r\n",
        "\r\n",
        "> What is TextRank algorithm?\r\n",
        "\r\n",
        "> TextRank is an extractive summarization technique. It is based on the concept that words which occur more frequently are significant. Hence , the sentences containing highly frequent words are important .\r\n",
        "\r\n",
        "> Based on this , the algorithm assigns scores to each sentence in the text . The top-ranked sentences make it to the summary.\r\n",
        "\r\n",
        "* Text Summarization with Sumy\r\n",
        "> Along with TextRank , there are various other algorithms to summarize text.<br>\r\n",
        "> Don’t you think it would be very smooth and beneficial to have a library, which will let you perform summarization through multiple algorithms?<br>\r\n",
        "> Fortunately, we already have the sumy library for it !\r\n",
        "sumy libraray provides you several algorithms to implement Text Summarzation. Just import your desired algorithm rather having to code it on your own.<br>\r\n",
        "> In this section, I shall discuss on implementation of the below algorithms for summarization using sumy :\r\n",
        ">> LexRank<br>\r\n",
        "> Luhn<br>\r\n",
        "> Latent Semantic Analysis, LSA<br>\r\n",
        "> KL-Sum<br>\r\n",
        "\r\n",
        "* LexRank (ref : G¨une¸s Erkan. (2004). LexRank: Graph-based Lexical Centrality as Salience in Text Summarization, https://arxiv.org/pdf/1109.2128.pdf)\r\n",
        "> First, let me introduce you to summarization with LexRank.\r\n",
        "> How does LexRank work?\r\n",
        "> A sentence which is similar to many other sentences of the text has a high probability of being important. The approach of LexRank is that a particular sentence is recommended by other similar sentences and hence is ranked higher.\r\n",
        "> Higher the rank, higher is the priority of being included in the summarized text.\r\n",
        "\r\n",
        "* LSA (Latent semantic analysis) (ref:참조논문 찾기)\r\n",
        "> Latent Semantic Analysis is a unsupervised learning algorithm that can be used for extractive text summarization.<br>\r\n",
        "> It extracts semantically significant sentences by applying singular value decomposition(SVD) to the matrix of term-document frequency. To learn more about this algorithm, check out here <br>\r\n",
        "> Let me demonstrate how to use LSA for summarization . First, import the summarizer from sumy.\r\n",
        "\r\n",
        "* Luhn (ref:참조논문 찾기)\r\n",
        "> Luhn Summarization algorithm’s approach is based on TF-IDF (Term Frequency-Inverse Document Frequency). It is useful when very low frequent words as well as highly frequent words(stopwords) are both not significant.<br>\r\n",
        "> Based on this, sentence scoring is carried out and the high ranking sentences make it to the summary.\r\n",
        "\r\n",
        "* KL-Sum (ref:참조논문 찾기)\r\n",
        "> Another extractive method is the KL-Sum algorithm. <br>\r\n",
        "> It selects sentences based on similarity of word distribution as the original text. It aims to lower the KL-divergence criteria (learn more). It uses greedy optimization approach and keeps adding sentences till the KL-divergence decreases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUP5F_L_Z99t"
      },
      "source": [
        "* What is Abstractive Text Summarization?\r\n",
        "\r\n",
        "> Abstractive summarization is the new state of art method, which generates new sentences that could best represent the whole text. This is better than extractive methods where sentences are just selected from original text for the summary.<br>\r\n",
        "\r\n",
        "> HuggingFace supports state of the art models to implement tasks such as summarization, classification, etc.. Some common models are GPT-2, GPT-3, BERT , OpenAI, GPT, T5.\r\n",
        "\r\n",
        ">Another awesome feature with transformers is that it provides PreTrained models with weights that can be easily instantiated through from_pretrained() method.\r\n",
        "\r\n",
        ">You can check the list of currently available PreTrained models here\r\n",
        "\r\n",
        ">This section will show you text summarization through different models of transformers library\r\n",
        "\r\n",
        "* Summarization with T5 Transformers (ref : Colin Raffel. (2020). Exploring the Limits of Transfer Learning with a Unified\r\n",
        "Text-to-Text Transformer, https://arxiv.org/pdf/1910.10683.pdf)\r\n",
        ">T5 is an encoder-decoder model. It converts all language problems into a text-to-text format.<br>\r\n",
        ">First, you need to import the tokenizer and corresponding model through below command.<br>\r\n",
        ">It is preferred to use T5ForConditionalGeneration model when the input and output are both sequences.\r\n",
        "\r\n",
        "* Summarization with BART Transformers (ref : Mike Lewis, (2019). BART: Denoising Sequence-to-Sequence Pre-training for Natural\r\n",
        "Language Generation, Translation, and Comprehension, https://arxiv.org/pdf/1910.13461.pdf)\r\n",
        "> transformers library of HuggingFace supports summarization with BART models.\r\n",
        "> Import the model and tokenizer. For problems where there is need to generate sequences , it is preferred to use BartForConditionalGeneration model.\r\n",
        "\r\n",
        "* Summarization with GPT-2 Transformers (ref : Alec Radford, (2018). Language Models are Unsupervised Multitask Learners, https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\r\n",
        ">GPT-2 transformer is another major player in text summarization, introduced by OpenAI. Thanks to transformers, the process followed is same just like with BART Transformers.<br>\r\n",
        "> First, you have to import the tokenizer and model. Make sure that you import a LM Head type model, as it is necessary to generate sequences. Next, load the pretrained gpt-2 model and tokenizer .<br>\r\n",
        ">After loading the model, you have to encode the input text and pass it as an input to model.generate().\r\n",
        "\r\n",
        "* Summarization with XLM Transformers (ref : Guillaume Lample, (2019). Cross-lingual Language Model Pretraining, https://arxiv.org/pdf/1901.07291.pdf)\r\n",
        ">Another transformer type that could be used for summarization are XLM Transformers.<br>\r\n",
        ">You can import the XLMWithLMHeadModel as it supports generation of sequences.You can load the pretrained xlm-mlm-en-2048 model and tokenizer with weights using from_pretrained() method.<br>\r\n",
        ">The nexts steps are same as the last three cases. The encoded input text is passed to generate() function with returns id sequence for the summary. You can decode and print the summary.<br>\r\n",
        "\r\n",
        "* GAN for Language Generation\r\n",
        "> In this paper, we borrow the idea of GAN to make the generator output human-readable. The major challenge in applying GAN to sentence generation is the discrete nature of natural language. To generate a word sequence, the generator usually has non-differential parts such as argmax or other sample functions which cause the original GAN to fail.\r\n",
        "In (Gulrajani et al., 2017), instead of feeding a discrete word sequence, the authors directly feed the generator output layer to the discriminator.\r\n",
        "This method works because they use the earth mover’s distance on GAN as proposed in (Arjovsky et al., 2017), which is able to evaluate the distance between a discrete and a continuous distribution.\r\n",
        "SeqGAN (Yu et al., 2017) tackles the sequence generation problem with reinforcement learning. Here, we refer to this approach as adversarial REINFORCE. However, the discriminator only measures the quality of whole sequence, and thus the rewards are extremely sparse and the rewards assigned to all the generation steps are all the same. MC search (Yu et al., 2017) is proposed to evaluate the approximate reward at each time step, but this method suffers from high time complexity.\r\n",
        "Following this idea, (Li et al., 2017) proposes partial evaluation approach to evaluate the expected reward at each time step.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVI_ewF7SIt1"
      },
      "source": [
        "DO_ALL = True # 전체 실행하면서 시간 걸리는 걸 Pass 하려면 이걸 False ...\r\n",
        "USE_PRETRAINED_MODEL = True # 이미 학습한 모델을 사용하려면.. true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2s2BOKVVQ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL9PuKQz04JS",
        "outputId": "2ebf2088-638d-4488-9cbc-54d5dc0281bc"
      },
      "source": [
        "if DO_ALL:\n",
        "    !pip install sentence-transformers==0.3.0\n",
        "    !pip install transformers==3.0.2\n",
        "    !pip install wikipedia\n",
        "    !pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/23/833e0620753a36cb2f18e2e4a4f72fd8c49c123c3f07744b69f8a592e083/sentence-transformers-0.3.0.tar.gz (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hCollecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.19.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (3.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.0-cp36-none-any.whl size=86754 sha256=a59412b8c2df2ec12aa5376910b5487d23598d5869dc12307283d6b519b4cf74\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/23/85/85d6a9a6c68f0625a1ecdaad903bb0a78df058c10cf74f9de4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9aec4dafaa48ddda45f40c99fa4a51d2be84d0a4c787cb9a63a3bc481aeea06a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.0 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting transformers==3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.8)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.9.4\n",
            "    Uninstalling tokenizers-0.9.4:\n",
            "      Successfully uninstalled tokenizers-0.9.4\n",
            "  Found existing installation: transformers 4.1.1\n",
            "    Uninstalling transformers-4.1.1:\n",
            "      Successfully uninstalled transformers-4.1.1\n",
            "Successfully installed sentencepiece-0.1.94 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=e35ba9692bbe78a4d4c01b7159e715f1e2977cf350c268fce19e537a23372be7\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.3MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, beautifulsoup4, tweepy, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZcW872104JU",
        "outputId": "fa0f00db-00b4-4635-e1eb-00353612071c"
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Dropout,Conv1D, MaxPooling1D, Flatten, Add, LeakyReLU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential, model_from_json\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "import keras.utils as ku \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input,\n",
        "                                     Dense, \n",
        "                                     BatchNormalization, \n",
        "                                     LeakyReLU,\n",
        "                                     Softmax,\n",
        "                                     Reshape, \n",
        "                                     Conv2DTranspose,\n",
        "                                     Conv2D,\n",
        "                                     Dropout,\n",
        "                                     Flatten,\n",
        "                                     Concatenate,\n",
        "                                     Lambda)\n",
        "import matplotlib.pyplot as plt\n",
        "# set seeds for reproducability\n",
        "from tensorflow.random import set_seed\n",
        "from numpy.random import seed\n",
        "set_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import urllib.request\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "za5UL6kk04JV"
      },
      "source": [
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    return txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "biAzDhZx04JW"
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "\n",
        "def get_sample_text(target_url):\n",
        "    raw_text = urllib.request.urlopen(target_url).read().decode('utf-8')\n",
        "    return nltk.sent_tokenize(clean_text(raw_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IiMMX5-304JW"
      },
      "source": [
        "ko_sentences_dataset = []\n",
        "if USE_PRETRAINED_MODEL:\n",
        "    ko_sentences_dataset += get_sample_text(\"https://raw.githubusercontent.com/dolmani38/Summary/master/data/korean_sample.txt\")\n",
        "    # 여기서 계속 수집...\n",
        "    ko_sentences_dataset += get_sample_text(\"https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-ABC%20%EC%82%B4%EC%9D%B8%EC%82%AC%EA%B1%B4.txt\")\n",
        "\n",
        "    ko_sentences_dataset += get_sample_text(\"https://raw.githubusercontent.com/dolmani38/Summary/master/data/%EC%95%A0%EA%B1%B0%EC%84%9C%ED%81%AC%EB%A6%AC%EC%8A%A4%ED%8B%B0-%EA%B7%B8%EB%A6%AC%EA%B3%A0%20%EC%95%84%EB%AC%B4%EB%8F%84%20%EC%97%86%EC%97%88%EB%8B%A4.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "blAfBUjg04JY"
      },
      "source": [
        "\n",
        "# false 문장을 만들기 위해 shffle 함수 준비\n",
        "import random\n",
        "\n",
        "def shuffling(txt):\n",
        "    txt_list = txt.split(' ')\n",
        "    random.shuffle(txt_list)\n",
        "    return ' '.join(txt_list)\n",
        "\n",
        "# true 문장, false 문장의 생성\n",
        "ko_grammar_dataset = []\n",
        "\n",
        "if USE_PRETRAINED_MODEL:\n",
        "    for txt in ko_sentences_dataset:\n",
        "        txt = txt.strip()\n",
        "        if len(txt) > 40:\n",
        "            #ko_grammar_dataset.append([txt,1])\n",
        "            txt = txt.replace('.','')\n",
        "            ko_grammar_dataset.append([txt,1]) # '.'의 위치를 보고 True, False를 판단 하기 땜에...\n",
        "            ko_grammar_dataset.append([shuffling(txt),0])\n",
        "        \n",
        "    # dataset을 전체적으로 다시 썩는다.\n",
        "    random.shuffle(ko_grammar_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2-5l3heO04Jb"
      },
      "source": [
        "okt = Okt()\n",
        "\n",
        "# 형태소 Code table의 구성\n",
        "\n",
        "_MAX_MORP_LENGTH = 128\n",
        "_PADDING_CODE = 0  # padding code\n",
        "_MISMATCH_CODE = 1 # mismatch word code               ex) @@@\n",
        "_MISMATCH_WORD = '@@@' # 이거 아래에서 쓴다.\n",
        "\n",
        "morpheme_table = {}\n",
        "morp_code = _MISMATCH_CODE+1\n",
        "morpheme_table['Pad'] = _PADDING_CODE \n",
        "morpheme_table['Mst'] = _MISMATCH_CODE \n",
        "'''\n",
        " Pad               0\n",
        " Mst               1\n",
        " Noun              2\n",
        " Punctuation       3\n",
        " Foreign           4\n",
        " Josa              5\n",
        " Verb              6\n",
        " Modifier          7\n",
        " Adjective         8\n",
        " Suffix            9\n",
        " Adverb            10\n",
        " Number            11\n",
        " Alpha             12\n",
        " Determiner        13\n",
        " Conjunction       14\n",
        " Exclamation       15\n",
        " KoreanParticle    16\n",
        " URL               17\n",
        " VerbPrefix        18\n",
        " Eomi              19\n",
        " Hashtag           20\n",
        " PreEomi           21\n",
        "'''\n",
        "morpheme_table['Noun']=2\n",
        "morpheme_table['Punctuation']=3\n",
        "morpheme_table['Foreign']=4\n",
        "morpheme_table['Josa']=5\n",
        "morpheme_table['Verb']=6\n",
        "morpheme_table['Modifier']=7\n",
        "morpheme_table['Adjective']=8\n",
        "morpheme_table['Suffix']=9\n",
        "morpheme_table['Adverb']=10\n",
        "morpheme_table['Number']=11\n",
        "morpheme_table['Alpha']=12\n",
        "morpheme_table['Determiner']=13\n",
        "morpheme_table['Conjunction']=14\n",
        "morpheme_table['Exclamation']=15\n",
        "morpheme_table['KoreanParticle']=16\n",
        "morpheme_table['URL']=17\n",
        "morpheme_table['VerbPrefix']=18\n",
        "morpheme_table['Eomi']=19\n",
        "morpheme_table['Hashtag']=20\n",
        "morpheme_table['PreEomi']=21\n",
        "morpheme_table['Email']=22"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZSOLBzT04Je",
        "outputId": "fffb8bc3-2d11-464c-d05d-b9acd006bfb6"
      },
      "source": [
        "\n",
        "print('Korean morpheme code table')\n",
        "print('----------------------------------------------------------')\n",
        "print('  Morpheme        Code')\n",
        "print('')\n",
        "for morp in morpheme_table.keys():\n",
        "    print(f' {morp.ljust(15)}   {morpheme_table[morp]}')\n",
        "print('----------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Korean morpheme code table\n",
            "----------------------------------------------------------\n",
            "  Morpheme        Code\n",
            "\n",
            " Pad               0\n",
            " Mst               1\n",
            " Noun              2\n",
            " Punctuation       3\n",
            " Foreign           4\n",
            " Josa              5\n",
            " Verb              6\n",
            " Modifier          7\n",
            " Adjective         8\n",
            " Suffix            9\n",
            " Adverb            10\n",
            " Number            11\n",
            " Alpha             12\n",
            " Determiner        13\n",
            " Conjunction       14\n",
            " Exclamation       15\n",
            " KoreanParticle    16\n",
            " URL               17\n",
            " VerbPrefix        18\n",
            " Eomi              19\n",
            " Hashtag           20\n",
            " PreEomi           21\n",
            " Email             22\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZeukKit04Jf",
        "outputId": "b95eecec-6991-4937-d440-dbf61f33676c"
      },
      "source": [
        "\n",
        "# morpheme 코드 변환기 준비\n",
        "def morpheme_encode(sentence):\n",
        "    encode=[]\n",
        "    morphemes = okt.pos(sentence)\n",
        "    x = np.zeros((_MAX_MORP_LENGTH, len(morpheme_table)), dtype=np.bool)\n",
        "    for i, (word,morp) in enumerate(morphemes):\n",
        "        if i < _MAX_MORP_LENGTH:\n",
        "            code = _MISMATCH_CODE if word==_MISMATCH_WORD else morpheme_table[morp]\n",
        "            x[i,code] = 1.0   \n",
        "    return x\n",
        "\n",
        "ko_morpheme_x = []\n",
        "ko_morpheme_y = []\n",
        "\n",
        "if USE_PRETRAINED_MODEL:\n",
        "    try:\n",
        "        ko_morpheme_x = np.load('ko_morpheme_x.npy')\n",
        "        ko_morpheme_y = np.load('ko_morpheme_y.npy')\n",
        "        print('dataset load from file.')\n",
        "        print('ko_morpheme_x.shape',ko_morpheme_x.shape)\n",
        "        print('ko_morpheme_y.shape',ko_morpheme_y.shape)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    #true / false 문장을 morpheme 코드로 모두 변환\n",
        "    tc = len(ko_grammar_dataset)\n",
        "\n",
        "    for i, (txt,label) in enumerate(ko_grammar_dataset):\n",
        "        print(f'\\r {i+1}/{tc}', end=\"\", flush=True)\n",
        "        ko_morpheme_x.append(morpheme_encode(txt))\n",
        "        ko_morpheme_y.append([label])\n",
        "\n",
        "    ko_morpheme_x = np.asarray(ko_morpheme_x)\n",
        "    ko_morpheme_y = np.asarray(ko_morpheme_y)\n",
        "    np.save('ko_morpheme_x',ko_morpheme_x)\n",
        "    np.save('ko_morpheme_y',ko_morpheme_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'ko_morpheme_x.npy'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMkYGX0u04Jh",
        "outputId": "86ca8c06-f5ca-4073-b152-11710900fe52"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "try: \n",
        "    # 20%를 testset으로 사용.,,\n",
        "    X_train, X_test, y_train, y_test = train_test_split(ko_morpheme_x,ko_morpheme_y,test_size=0.2)\n",
        "\n",
        "    print(f'Shape of X_train;{X_train.shape}')\n",
        "    print(f'Shape of X_test ;{X_test.shape}')\n",
        "    print(f'Shape of y_train;{y_train.shape}')\n",
        "    print(f'Shape of y_test ;{y_test.shape}')\n",
        "except Exception as ex:\n",
        "    print(ex)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gv0ScAn304Ji"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def r2(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    # custom R2-score metrics for keras backend\n",
        "    :param y_true: 실측 데이터\n",
        "    :param y_pred: 모델에 의한 예측 데이테\n",
        "    :return: R^2 value, 이 값이 높다고 (예:0.99)해서 예측 값이 정확 하다고 할 수 는 없음...\n",
        "    \"\"\"\n",
        "    SS_res = K.sum(K.square(y_true - y_pred))\n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return (1 - SS_res / (SS_tot + K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x0pHoNB3MSe",
        "outputId": "c15bab39-37fa-4313-fdc9-96e0b3a801ae"
      },
      "source": [
        "if USE_PRETRAINED_MODEL:\r\n",
        "    model_json_url = \"https://raw.githubusercontent.com/dolmani38/Summary/master/models/morpheme_model.json\"\r\n",
        "    model_weight_url = \"https://github.com/dolmani38/Summary/blob/master/models/morpheme_model.h5?raw=true\"\r\n",
        "    loaded_model_json = urllib.request.urlopen(model_json_url).read().decode('utf-8')\r\n",
        "    morpheme_model = model_from_json(loaded_model_json)\r\n",
        "    urllib.request.urlretrieve(model_weight_url, \"morpheme_model.h5\")\r\n",
        "    morpheme_model.load_weights(\"morpheme_model.h5\")\r\n",
        "    morpheme_model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[r2])\r\n",
        "    print('Use pretrained model...')\r\n",
        "else:\r\n",
        "    # model build\r\n",
        "    morpheme_model = Sequential()\r\n",
        "    morpheme_model.add(Conv1D(filters=256, kernel_size=4, padding='same',activation='relu',input_shape=(_MAX_MORP_LENGTH, len(morpheme_table))))\r\n",
        "    morpheme_model.add(MaxPooling1D(pool_size=2))\r\n",
        "    morpheme_model.add(Conv1D(filters=128, kernel_size=4, padding=\"same\",activation='relu'))\r\n",
        "    morpheme_model.add(MaxPooling1D(pool_size=2))\r\n",
        "    morpheme_model.add(Flatten())\r\n",
        "    morpheme_model.add(Dense(128))\r\n",
        "    morpheme_model.add(Dense(1, activation='linear'))\r\n",
        "    morpheme_model.summary() #Print model Summary\r\n",
        "\r\n",
        "    morpheme_model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[r2])\r\n",
        "    hist = morpheme_model.fit(X_train, y_train, epochs=30)\r\n",
        "\r\n",
        "discriminator = morpheme_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use pretrained model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxzfhkx804Jm",
        "outputId": "971b1073-6e66-486c-b8a0-07dacb4bd5cd"
      },
      "source": [
        "\n",
        "# 학습결과 확인\n",
        "try:\n",
        "    results = morpheme_model.evaluate(X_test, y_test)\n",
        "    print('mean_squared_error:',results)\n",
        "\n",
        "    # 학습 결과의 확인\n",
        "    predicts = morpheme_model.predict(X_test)\n",
        "    predicts = np.asarray(predicts)\n",
        "    predicts = [ 1 if x>0.5 else 0 for [x] in predicts]\n",
        "    y = np.asarray(y_test)\n",
        "    y = y.reshape(y.shape[0],)\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(classification_report(y, predicts))\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name 'X_test' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "adKbX4Pg04Jn"
      },
      "source": [
        "if USE_PRETRAINED_MODEL:\n",
        "    pass\n",
        "else:\n",
        "    model_json = morpheme_model.to_json()\n",
        "    with open(\"morpheme_model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    json_file.close()\n",
        "    print(\"save network to morpheme_model.json\")\n",
        "\n",
        "    morpheme_model.save_weights(\"morpheme_model.h5\")\n",
        "    print(\"save weights to morpheme_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jAQW6z-F04Jn"
      },
      "source": [
        "def morpheme_discriminator(queries):\n",
        "    # queries : 복수의 문장의 2차원 배열 (None,1)\n",
        "    # return : 결과 score 배열 (None,)\n",
        "    x_codes = []\n",
        "    for query in queries:\n",
        "        x_codes.append(morpheme_encode(query))\n",
        "    scores = morpheme_model.predict(np.array(x_codes))\n",
        "    return scores #1.0 if scores > 0.5 else 0.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnNY6kDt04Jo",
        "outputId": "143add6b-b81b-4877-9673-53999725080b"
      },
      "source": [
        "morpheme_discriminator([' 무럭무럭 자라서, 아기는 소녀가 예쁘고 마음씨 고운 되었어요'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20912033]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX2yrJqIa5dD"
      },
      "source": [
        "org_text = \"\"\"나무꾼이 나무를 하다가 숲 속에서 도망치는 사슴을 만났는데, 이 사슴이 사냥꾼이 쫓아오고 있으니 자신을 숨겨달라고 말했다. 말하는 사슴을 신기하게 여긴 나무꾼이 사슴을 숨겨줬고, 뒤쫓아 온 사냥꾼을 다른 방향으로 보내서 구해주었다.\r\n",
        "사슴은 은혜를 갚겠다고 하면서, 나무꾼에게 선녀들이 하늘에서 내려와서 목욕하는 선녀탕이라는 샘과 선녀들이 목욕을 하러 오는 시기, 선녀의 옷을 훔쳐 그를 아내로 삼도록 하는 꾀를 나무꾼에게 가르쳐 주었다. 나무꾼은 반신반의 하면서도 사슴이 가르쳐준 시기에 선녀들이 목욕을 하러 내려온다는 샘으로 찾아가 몸을 숨겼다. 그렇게 잠시간 기다리자 과연, 선녀들이 하늘에서 내려와 날개옷을 벗고 선녀탕에서 목욕을 하는 것이었다. 나무꾼은 사슴이 가르쳐준 대로 날개옷을 하나 훔쳤다.\r\n",
        "날개옷이 없어진 탓에 한 명의 선녀는 하늘로 올라가지 못했으며 다른 선녀들은 날개옷이 없는 선녀를 내버려두고 하늘로 돌아갔다. 이때 나무꾼이 홀로 남은 선녀에게 자신의 아내가 되어달라고 하자, 하늘나라로 올라가지 못하게 된 선녀는 할 수 없이 나무꾼에게 의탁하게 되었다.\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ew7U_2hd04Jo"
      },
      "source": [
        "org_text = \"\"\"옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요.\n",
        "소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
        "그래서 얼마 후 새어머니를 맞이했어요.\n",
        "새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요.\n",
        "그런데 이번에는 아버지마저 돌아가셨어요.\n",
        "소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요.\n",
        "해도 해도 끝이 없는 집안일이 힘들어 지칠때면\n",
        "난롯가에 앉아서 잠시 쉬곤 했지요.\n",
        "\"엄마, 저애를 신데렐라라고 불러야겠어요.\"\n",
        "\"온통 재투성이잖아요. 호호호!\" 두 언니는 소녀를 놀려 댔어요.\n",
        "어느 날, 왕궁에서 무도회가 열렸어요.\n",
        "신데렐라의 집에도 초대장이 왔어요.\n",
        "새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
        "신데렐라도 무도회에 가고 싶었어요.\n",
        "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
        "\"신데렐라, 너도 무도회에 가고 싶니?\"\n",
        "신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요.\n",
        "\"내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴.\"\n",
        "마법사 할머니가 주문을 외웠어요.\n",
        "그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요.\n",
        "이번에는 생쥐와 도마뱀을 건드렸어요.\n",
        "그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다.\n",
        "신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요.\n",
        "\"신데렐라, 발을 내밀어 보거라.\"\n",
        "할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요.\n",
        "\"신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지?\"\n",
        "왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요.\n",
        "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,신데렐라하고만 춤을 추었어요.\n",
        "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요.\n",
        "땡, 땡, 땡...... 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요.\n",
        "신데렐라가 허둥지둥 왕궁을 빠져나가는데,\n",
        "유리 구두 한 짝이 벗겨졌어요.\n",
        "하지만 구두를 주울 틈이 없었어요.\n",
        "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요.\n",
        "왕자님은 유리 구두를 가지고 임금님께 가서 말했어요.\n",
        "\"이 유리 구두의 주인과 결혼하겠어요.\"\n",
        "그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요.\n",
        "언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요.\n",
        "그때, 신데렐라가 조용히 다가와 말했어요.\n",
        "\"저도 한번 신어 볼 수 있나요?\"\n",
        "신데렐라는 신하게 건넨 유리 구두를 신었어요,\n",
        "유리 구두는 신데렐라의 발에 꼭 맞았어요.\n",
        "신하들은 신데렐라를 왕궁으로 데리고 갔어요.\n",
        "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "3ZoF9CLZ04Jp",
        "outputId": "a575020d-e7fa-4228-cd9d-b74a4946ba7d"
      },
      "source": [
        "org_text = clean_text(org_text).strip()\n",
        "org_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'나무꾼이 나무를 하다가 숲 속에서 도망치는 사슴을 만났는데 이 사슴이 사냥꾼이 쫓아오고 있으니 자신을 숨겨달라고 말했다. 말하는 사슴을 신기하게 여긴 나무꾼이 사슴을 숨겨줬고 뒤쫓아 온 사냥꾼을 다른 방향으로 보내서 구해주었다. 사슴은 은혜를 갚겠다고 하면서 나무꾼에게 선녀들이 하늘에서 내려와서 목욕하는 선녀탕이라는 샘과 선녀들이 목욕을 하러 오는 시기 선녀의 옷을 훔쳐 그를 아내로 삼도록 하는 꾀를 나무꾼에게 가르쳐 주었다. 나무꾼은 반신반의 하면서도 사슴이 가르쳐준 시기에 선녀들이 목욕을 하러 내려온다는 샘으로 찾아가 몸을 숨겼다. 그렇게 잠시간 기다리자 과연 선녀들이 하늘에서 내려와 날개옷을 벗고 선녀탕에서 목욕을 하는 것이었다. 나무꾼은 사슴이 가르쳐준 대로 날개옷을 하나 훔쳤다. 날개옷이 없어진 탓에 한 명의 선녀는 하늘로 올라가지 못했으며 다른 선녀들은 날개옷이 없는 선녀를 내버려두고 하늘로 돌아갔다. 이때 나무꾼이 홀로 남은 선녀에게 자신의 아내가 되어달라고 하자 하늘나라로 올라가지 못하게 된 선녀는 할 수 없이 나무꾼에게 의탁하게 되었다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r85RVIBinB8G",
        "outputId": "179c5592-4a8e-40a4-ffae-06c6ac88a60b"
      },
      "source": [
        "org_sentence_dataset = nltk.sent_tokenize(clean_text(org_text))\r\n",
        "org_morpheme_x = []\r\n",
        "for sentence in org_sentence_dataset:\r\n",
        "    org_morpheme_x.append(morpheme_encode(sentence))\r\n",
        "#np.random.choice(5, 3)\r\n",
        "\r\n",
        "def get_org_morpheme_sample(num):\r\n",
        "    return np.asarray(org_morpheme_x)[np.random.choice(len(org_morpheme_x), num)]\r\n",
        "\r\n",
        "get_org_morpheme_sample(3).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 128, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLhpskVk04Jq",
        "outputId": "48bdcefd-f328-4b61-b971-e19a790cc3f4"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "if DO_ALL:\n",
        "    # embedder download...\n",
        "    embedder = SentenceTransformer('xlm-r-large-en-ko-nli-ststb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.80G/1.80G [02:10<00:00, 13.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CCX6a7Gk04Jq"
      },
      "source": [
        "# 생성된 문장의 원문 유사도를 측정하기 위한 함수\n",
        "\n",
        "import scipy\n",
        "#print(doc_emb)\n",
        "def similarity_discriminator(queries,org_embedding):\n",
        "    # queries : 복수의 문장의 2차원 배열 (None,1)\n",
        "    # org_embedding : 비교 대상의 원문 embedding 1차원 배열 (1,)\n",
        "    # return : 결과 score 배열 (None,)\n",
        "    total_score = 0\n",
        "    query_embeddings = embedder.encode(queries,show_progress_bar=False)\n",
        "    for query, query_embedding in zip(queries, query_embeddings):\n",
        "        distances = scipy.spatial.distance.cdist([query_embedding], [org_embedding], \"cosine\")[0]\n",
        "        results = zip(range(len(distances)), distances)\n",
        "        for idx, distance in results:\n",
        "            total_score += 1-distance\n",
        "    return total_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3c6mcWX04Js",
        "outputId": "670c3860-bb85-419e-de50-66e81f5484a6"
      },
      "source": [
        "\n",
        "# 원문의 embedding...\n",
        "org_text_emb = embedder.encode([org_text],show_progress_bar=False)[0]\n",
        "org_text_emb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.37110206, -0.19225682, -0.25144747, ..., -0.17844181,\n",
              "        0.41148984,  0.5338639 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axpKfKxJ04Ju",
        "outputId": "63d7d267-929f-43de-a67f-8169fd00583c"
      },
      "source": [
        "org_term_set = (' ' + org_text + ' ').split(' ')\n",
        "\n",
        "_MAX_GEN_TOKEN = 40\n",
        "_NOISE_DIM = len(org_term_set)\n",
        "\n",
        "word_table = {}\n",
        "morp_table = {}\n",
        "\n",
        "for index, word in zip(range(len(org_term_set)),org_term_set):\n",
        "    word_table[index] = word\n",
        "    m = okt.pos(word)\n",
        "    morp_table[index] = m[0][1] if len(m) > 0 else ''\n",
        "    \n",
        "print('Token table of origin text')\n",
        "print('---------------------------------------------')\n",
        "print(' Code     Morp           Token     ')\n",
        "print('')\n",
        "for k in word_table.keys():\n",
        "  print( f'  {str(k).ljust(5)} {morp_table[k].ljust(10)}  {word_table[k]}')\n",
        "print('---------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token table of origin text\n",
            "---------------------------------------------\n",
            " Code     Morp           Token     \n",
            "\n",
            "  0                 \n",
            "  1     Noun        나무꾼이\n",
            "  2     Noun        나무를\n",
            "  3     Verb        하다가\n",
            "  4     Noun        숲\n",
            "  5     Noun        속에서\n",
            "  6     Verb        도망치는\n",
            "  7     Noun        사슴을\n",
            "  8     Verb        만났는데\n",
            "  9     Noun        이\n",
            "  10    Noun        사슴이\n",
            "  11    Noun        사냥꾼이\n",
            "  12    Verb        쫓아오고\n",
            "  13    Adjective   있으니\n",
            "  14    Noun        자신을\n",
            "  15    Verb        숨겨달라고\n",
            "  16    Noun        말했다.\n",
            "  17    Noun        말하는\n",
            "  18    Noun        사슴을\n",
            "  19    Adjective   신기하게\n",
            "  20    Verb        여긴\n",
            "  21    Noun        나무꾼이\n",
            "  22    Noun        사슴을\n",
            "  23    Verb        숨겨줬고\n",
            "  24    Noun        뒤쫓아\n",
            "  25    Noun        온\n",
            "  26    Noun        사냥꾼을\n",
            "  27    Noun        다른\n",
            "  28    Noun        방향으로\n",
            "  29    Verb        보내서\n",
            "  30    Noun        구해주었다.\n",
            "  31    Noun        사슴은\n",
            "  32    Noun        은혜를\n",
            "  33    Verb        갚겠다고\n",
            "  34    Verb        하면서\n",
            "  35    Noun        나무꾼에게\n",
            "  36    Noun        선녀들이\n",
            "  37    Noun        하늘에서\n",
            "  38    Verb        내려와서\n",
            "  39    Noun        목욕하는\n",
            "  40    Noun        선녀탕이라는\n",
            "  41    Noun        샘과\n",
            "  42    Noun        선녀들이\n",
            "  43    Noun        목욕을\n",
            "  44    Verb        하러\n",
            "  45    Verb        오는\n",
            "  46    Noun        시기\n",
            "  47    Noun        선녀의\n",
            "  48    Noun        옷을\n",
            "  49    Verb        훔쳐\n",
            "  50    Noun        그를\n",
            "  51    Noun        아내로\n",
            "  52    Modifier    삼도록\n",
            "  53    Verb        하는\n",
            "  54    Noun        꾀를\n",
            "  55    Noun        나무꾼에게\n",
            "  56    Verb        가르쳐\n",
            "  57    Verb        주었다.\n",
            "  58    Noun        나무꾼은\n",
            "  59    Noun        반신반의\n",
            "  60    Verb        하면서도\n",
            "  61    Noun        사슴이\n",
            "  62    Verb        가르쳐준\n",
            "  63    Noun        시기에\n",
            "  64    Noun        선녀들이\n",
            "  65    Noun        목욕을\n",
            "  66    Verb        하러\n",
            "  67    Verb        내려온다는\n",
            "  68    Noun        샘으로\n",
            "  69    Verb        찾아가\n",
            "  70    Noun        몸을\n",
            "  71    Verb        숨겼다.\n",
            "  72    Adverb      그렇게\n",
            "  73    Noun        잠시간\n",
            "  74    Verb        기다리자\n",
            "  75    Noun        과연\n",
            "  76    Noun        선녀들이\n",
            "  77    Noun        하늘에서\n",
            "  78    Verb        내려와\n",
            "  79    Noun        날개옷을\n",
            "  80    Verb        벗고\n",
            "  81    Noun        선녀탕에서\n",
            "  82    Noun        목욕을\n",
            "  83    Verb        하는\n",
            "  84    Noun        것이었다.\n",
            "  85    Noun        나무꾼은\n",
            "  86    Noun        사슴이\n",
            "  87    Verb        가르쳐준\n",
            "  88    Noun        대로\n",
            "  89    Noun        날개옷을\n",
            "  90    Noun        하나\n",
            "  91    Verb        훔쳤다.\n",
            "  92    Noun        날개옷이\n",
            "  93    Verb        없어진\n",
            "  94    Noun        탓에\n",
            "  95    Verb        한\n",
            "  96    Noun        명의\n",
            "  97    Noun        선녀는\n",
            "  98    Noun        하늘로\n",
            "  99    Verb        올라가지\n",
            "  100   VerbPrefix  못했으며\n",
            "  101   Noun        다른\n",
            "  102   Noun        선녀들은\n",
            "  103   Noun        날개옷이\n",
            "  104   Adjective   없는\n",
            "  105   Noun        선녀를\n",
            "  106   Verb        내버려두고\n",
            "  107   Noun        하늘로\n",
            "  108   Verb        돌아갔다.\n",
            "  109   Determiner  이때\n",
            "  110   Noun        나무꾼이\n",
            "  111   Noun        홀로\n",
            "  112   Verb        남은\n",
            "  113   Noun        선녀에게\n",
            "  114   Noun        자신의\n",
            "  115   Noun        아내가\n",
            "  116   Verb        되어달라고\n",
            "  117   Noun        하자\n",
            "  118   Noun        하늘나라로\n",
            "  119   Verb        올라가지\n",
            "  120   VerbPrefix  못하게\n",
            "  121   Verb        된\n",
            "  122   Noun        선녀는\n",
            "  123   Verb        할\n",
            "  124   Noun        수\n",
            "  125   Adverb      없이\n",
            "  126   Noun        나무꾼에게\n",
            "  127   Noun        의탁하게\n",
            "  128   Verb        되었다.\n",
            "  129               \n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AaxM8FAa04Jv"
      },
      "source": [
        "sota_text = \"\"\"소녀의 언니들은 심술쟁이들 이었어요. 소녀는 집안일을 도맡아 했어요. 신데렐라도 무도회에 가고 싶었어요. \n",
        "마법사 할머니가 주문을 외웠어요. 황금 마차로 드레스로 바뀌웠어요. 밤 열두시가 되면 처음대로 돌아간단다. \n",
        "왕자님도 신데렐라에게 마음을 빼았겼어요. 벽시계가 열두 시를 알리는 소리에 놀랐어요. 유리 구두 벗겨졌어요. \n",
        "왕자님은 주인을 찾아 돌아다녔어요. 구두는 신데렐라의 발에 맞았어요.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvGKdVCR04Jv",
        "outputId": "c072cc96-1bb6-49e0-daa1-131d19b9fc1f"
      },
      "source": [
        "print('Similarity of sota:',similarity_discriminator([sota_text],org_text_emb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of sota: 0.5623787199364326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vEcz3jme04Jv"
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '|', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '.' * (self.length - filledLength)\n",
        "        print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "        # Print New Line on Complete\n",
        "        if self.ite == self.total: \n",
        "            print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAL_rOIT04Jw",
        "outputId": "3e2e566d-a676-4954-aec5-bde7c2d61612"
      },
      "source": [
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "\n",
        "\n",
        "# weight 들의 초기화\n",
        "terms = np.array(list(word_table.values()))\n",
        "\n",
        "story_filters=np.array([[0,1],[0,1,2],[0,1,2,3]]) # ,[0,1,2,3,4],[0,2,4,6]])#,[0,2],[0,2,4],[0,2,4,6],[0,2,4,6,8]])\n",
        "word_filters=np.array([[0]])\n",
        "\n",
        "story_weights = np.zeros(_NOISE_DIM,)\n",
        "word_weights = np.zeros(_NOISE_DIM,)\n",
        "\n",
        "#filters=np.array([[0,2],[0,2,4],[0,2,4,6],[0,2,4,6,8]])\n",
        "#filters=np.array([[0,1,2,3,4,5]])\n",
        "terms = np.array(list(word_table.values()))\n",
        "morps = np.array(list(morp_table.values()))\n",
        "\n",
        "# story에 지배적인 word를 찾는다.\n",
        "\n",
        "# 먼저 word의 강세 분석\n",
        "for filter in word_filters:\n",
        "    #print(filter)\n",
        "    last_idx = len(terms)-(max(filter)+1)\n",
        "    pb = ProgressBar(last_idx,prefix='word density scan :')\n",
        "    for conv in range(last_idx,0,-1):\n",
        "        pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "        t = np.array(filter) + conv\n",
        "        '''\n",
        "        w = terms[t][0]\n",
        "        if w.endswith('.'):  # '.'으로 끝나는 동사 - '술어' 는 대부분 스토리상중요한 내용 포함. 하여... 이건 제외 단어에서 skip시킴\n",
        "            score = 0.0\n",
        "        else:\n",
        "            #part_sen = ' '.join(terms[t]) \n",
        "            #score = similarity_discriminator([part_sen],org_text_emb)\n",
        "            score = similarity_discriminator([w],org_text_emb)\n",
        "        '''\n",
        "\n",
        "        if morps[t][0] in ('Adjective ','Adverb','Conjunction'):\n",
        "            pass\n",
        "        else:\n",
        "            part_sen = ' '.join(terms[t]) \n",
        "            score = similarity_discriminator(part_sen.strip(),org_text_emb)\n",
        "            word_weights[t] += score\n",
        "        \n",
        "# story의 강세 분석\n",
        "for filter in story_filters:\n",
        "    #print(filter)\n",
        "    last_idx = len(terms)-(max(filter)+1)\n",
        "    pb = ProgressBar(last_idx,prefix='story density scan:')\n",
        "    for conv in range(last_idx,0,-1):\n",
        "        pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "        t = np.array(filter) + conv\n",
        "        part_sen = ' '.join(terms[t]) \n",
        "        score = similarity_discriminator([part_sen],org_text_emb)\n",
        "        story_weights[t] += score\n",
        "\n",
        "#각각의 peak를 산출\n",
        "word_peaks, _ = find_peaks(word_weights, height=0)\n",
        "story_peaks, _ = find_peaks(story_weights, height=0)\n",
        "\n",
        "#두개의 peak가 겹치는 word에 대해 한개 word가 유사도에 미치는 영향이 큰것으로 간주\n",
        "#해당 word를 유사도 판단 필터에서 제외하고 다시 필터링...\n",
        "#이를 통해 story에 대한 word를 최대한 추출 한다.\n",
        "\n",
        "dup_order = []\n",
        "for i in range(_NOISE_DIM):\n",
        "    #lst = \"\"\n",
        "    if (i in word_peaks) and (i in story_peaks):\n",
        "        if terms[i].endswith('.'):\n",
        "            pass\n",
        "        else:\n",
        "            dup_order.append(i)\n",
        "# Story에 대한 weight을 추출하기 위해, word에 유독 강세가 있는 term을 제외 시킨다.\n",
        "print('Negative words:',terms[dup_order])\n",
        "terms[dup_order] = '---'\n",
        "'''\n",
        "print('Token table of origin text')\n",
        "print('---------------------------------------------')\n",
        "print(' Code         Token      ')\n",
        "print('')\n",
        "for index, word in zip(range(len(terms)),terms):\n",
        "    print( f'  {str(index).ljust(8)}    {word}')\n",
        "print('---------------------------------------------')\n",
        "'''\n",
        "story_weights = np.zeros(_NOISE_DIM,)\n",
        "# 그리고 다시 story 분석 스캔\n",
        "for filter in story_filters:\n",
        "    #print(filter)\n",
        "    last_idx = len(terms)-(max(filter)+1)\n",
        "    pb = ProgressBar(last_idx,prefix='story density scan:')\n",
        "    for conv in range(last_idx):\n",
        "        pb.printProgress(+1,f'filer:{filter} {conv}/{last_idx}       ')\n",
        "        t = np.array(filter) + conv\n",
        "        part_sen = ' '.join(terms[t]) \n",
        "        #part_sen = part_sen.replace('소녀','---')\n",
        "        score = similarity_discriminator([part_sen],org_text_emb)\n",
        "        story_weights[t] += score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word density scan : |||||||||||||||||||||| 100.0%   filer:[0] 1/129       \n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 1/128       \n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 1/127       \n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 1/126       \n",
            "Negative words: ['사슴을' '사슴을' '사슴을' '사슴은' '나무꾼에게' '훔쳐' '나무꾼에게' '사슴이' '벗고' '사슴이' '나무꾼이'\n",
            " '나무꾼에게']\n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1] 127/128       \n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2] 126/127       \n",
            "story density scan: |||||||||||||||||||||| 100.0%   filer:[0, 1, 2, 3] 125/126       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "dWlYtVM-Al-E",
        "outputId": "46298df7-49bc-41af-d7a1-6e04db4d450d"
      },
      "source": [
        "\r\n",
        "# base line\r\n",
        "base_line = 0.0\r\n",
        "# 다시 peak 추출\r\n",
        "story_peaks, _ = find_peaks(story_weights, height=base_line)\r\n",
        "story_peaks = np.append(story_peaks,len(story_weights)-2)\r\n",
        "print(story_peaks)\r\n",
        "# story density 표출\r\n",
        "plt.figure(figsize=(12, 6))\r\n",
        "plt.plot(story_weights)\r\n",
        "plt.plot(story_peaks, story_weights[story_peaks], \"x\")\r\n",
        "plt.plot(np.zeros_like(story_weights)+base_line, \"--\", color=\"gray\")\r\n",
        "plt.show() \r\n",
        "print('Peak count:',len(story_peaks))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  4  11  21  24  26  33  39  43  47  51  58  65  71  76  78  85  93 102\n",
            " 105 114 120 128]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Peak count: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qodcFmj9Amtg",
        "outputId": "9b808abf-36a7-4e5c-e12e-717eef95d181"
      },
      "source": [
        "\r\n",
        "# story skeleton 추출\r\n",
        "skel_text = \"\"\r\n",
        "for k in story_peaks:\r\n",
        "    #print(k,term_weight[k],word_table[k])\r\n",
        "    skel_text += word_table[k]+' '  \r\n",
        "\r\n",
        "print(skel_text)\r\n",
        "print('')\r\n",
        "print(f'Peak count:{len(story_peaks)}   Similarity : {similarity_discriminator([skel_text],org_text_emb)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "숲 사냥꾼이 나무꾼이 뒤쫓아 사냥꾼을 갚겠다고 목욕하는 목욕을 선녀의 아내로 나무꾼은 목욕을 숨겼다. 선녀들이 내려와 나무꾼은 없어진 선녀들은 선녀를 자신의 못하게 되었다. \n",
            "\n",
            "Peak count:22   Similarity : 0.7400024623268161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXjghLDh04Jw",
        "outputId": "6542e1e5-66a3-4a05-b0be-e6e7c42a0ff3"
      },
      "source": [
        "for index, word in zip(range(len(org_term_set)),org_term_set):\n",
        "    word_table[index] = word\n",
        "    \n",
        "print('Token table of origin text')\n",
        "print('---------------------------------------------')\n",
        "print(' Code     Score        Token              ')\n",
        "print('')\n",
        "for k in word_table.keys(): \n",
        "  print( f'  {str(k).ljust(5)}   {str(round(story_weights[k],4)).ljust(8)}  {word_table[k]}')\n",
        "print('---------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token table of origin text\n",
            "---------------------------------------------\n",
            " Code     Score        Token              \n",
            "\n",
            "  0       1.0106    \n",
            "  1       2.1436    나무꾼이\n",
            "  2       2.7355    나무를\n",
            "  3       3.2579    하다가\n",
            "  4       3.5454    숲\n",
            "  5       2.7416    속에서\n",
            "  6       2.0499    도망치는\n",
            "  7       1.0844    사슴을\n",
            "  8       1.3335    만났는데\n",
            "  9       3.017     이\n",
            "  10      5.2377    사슴이\n",
            "  11      5.7677    사냥꾼이\n",
            "  12      5.1314    쫓아오고\n",
            "  13      3.7684    있으니\n",
            "  14      2.7738    자신을\n",
            "  15      2.1454    숨겨달라고\n",
            "  16      0.9635    말했다.\n",
            "  17      0.1297    말하는\n",
            "  18      -0.0664   사슴을\n",
            "  19      0.5978    신기하게\n",
            "  20      1.8763    여긴\n",
            "  21      3.6514    나무꾼이\n",
            "  22      3.4731    사슴을\n",
            "  23      3.8915    숨겨줬고\n",
            "  24      4.1165    뒤쫓아\n",
            "  25      3.9547    온\n",
            "  26      4.2119    사냥꾼을\n",
            "  27      2.8076    다른\n",
            "  28      1.4461    방향으로\n",
            "  29      1.0509    보내서\n",
            "  30      0.909     구해주었다.\n",
            "  31      0.4012    사슴은\n",
            "  32      0.3125    은혜를\n",
            "  33      0.4176    갚겠다고\n",
            "  34      0.1729    하면서\n",
            "  35      0.1153    나무꾼에게\n",
            "  36      0.4772    선녀들이\n",
            "  37      0.5698    하늘에서\n",
            "  38      0.9423    내려와서\n",
            "  39      1.0362    목욕하는\n",
            "  40      0.8589    선녀탕이라는\n",
            "  41      0.8701    샘과\n",
            "  42      1.159     선녀들이\n",
            "  43      1.1837    목욕을\n",
            "  44      0.7906    하러\n",
            "  45      0.3006    오는\n",
            "  46      -0.0419   시기\n",
            "  47      0.1095    선녀의\n",
            "  48      0.0338    옷을\n",
            "  49      0.1017    훔쳐\n",
            "  50      0.6472    그를\n",
            "  51      1.2454    아내로\n",
            "  52      1.087     삼도록\n",
            "  53      0.5203    하는\n",
            "  54      0.2488    꾀를\n",
            "  55      0.0372    나무꾼에게\n",
            "  56      0.492     가르쳐\n",
            "  57      1.4784    주었다.\n",
            "  58      2.7038    나무꾼은\n",
            "  59      2.077     반신반의\n",
            "  60      1.1164    하면서도\n",
            "  61      0.2714    사슴이\n",
            "  62      0.1519    가르쳐준\n",
            "  63      0.3403    시기에\n",
            "  64      1.0319    선녀들이\n",
            "  65      1.2065    목욕을\n",
            "  66      1.147     하러\n",
            "  67      1.0516    내려온다는\n",
            "  68      1.0428    샘으로\n",
            "  69      1.4646    찾아가\n",
            "  70      1.7167    몸을\n",
            "  71      1.893     숨겼다.\n",
            "  72      1.3611    그렇게\n",
            "  73      1.2421    잠시간\n",
            "  74      0.816     기다리자\n",
            "  75      0.7162    과연\n",
            "  76      0.7364    선녀들이\n",
            "  77      0.3618    하늘에서\n",
            "  78      0.4748    내려와\n",
            "  79      0.194     날개옷을\n",
            "  80      0.1944    벗고\n",
            "  81      0.4888    선녀탕에서\n",
            "  82      0.7698    목욕을\n",
            "  83      1.0108    하는\n",
            "  84      1.7491    것이었다.\n",
            "  85      2.6976    나무꾼은\n",
            "  86      1.6124    사슴이\n",
            "  87      0.7262    가르쳐준\n",
            "  88      -0.009    대로\n",
            "  89      -0.1307   날개옷을\n",
            "  90      0.2603    하나\n",
            "  91      0.973     훔쳤다.\n",
            "  92      1.1035    날개옷이\n",
            "  93      1.2037    없어진\n",
            "  94      0.8074    탓에\n",
            "  95      0.2199    한\n",
            "  96      -0.1237   명의\n",
            "  97      -0.0671   선녀는\n",
            "  98      -0.1333   하늘로\n",
            "  99      0.2805    올라가지\n",
            "  100     0.7569    못했으며\n",
            "  101     1.0525    다른\n",
            "  102     1.0603    선녀들은\n",
            "  103     0.7202    날개옷이\n",
            "  104     0.8215    없는\n",
            "  105     0.9296    선녀를\n",
            "  106     0.646     내버려두고\n",
            "  107     -0.2009   하늘로\n",
            "  108     -0.6011   돌아갔다.\n",
            "  109     -0.6387   이때\n",
            "  110     -0.1038   나무꾼이\n",
            "  111     0.7767    홀로\n",
            "  112     0.9961    남은\n",
            "  113     1.3268    선녀에게\n",
            "  114     1.5716    자신의\n",
            "  115     1.4608    아내가\n",
            "  116     0.954     되어달라고\n",
            "  117     0.3721    하자\n",
            "  118     0.0667    하늘나라로\n",
            "  119     0.2353    올라가지\n",
            "  120     0.4798    못하게\n",
            "  121     0.3464    된\n",
            "  122     0.2466    선녀는\n",
            "  123     -0.2869   할\n",
            "  124     -0.8056   수\n",
            "  125     -0.4972   없이\n",
            "  126     -0.5172   나무꾼에게\n",
            "  127     -0.3491   의탁하게\n",
            "  128     -0.1448   되었다.\n",
            "  129     0.0       \n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o1aRT1k904Jx"
      },
      "source": [
        "\n",
        "# text의 생성\n",
        "def text_gen(noise, term_length):\n",
        "    gtext = []\n",
        "    sorted_noise = np.sort(noise)[::-1]\n",
        "    order = np.where(noise > sorted_noise[term_length+1])[0][-term_length:]\n",
        "    assert len(order) == term_length\n",
        "    for k in order:\n",
        "        gtext.append((word_table[k],k))\n",
        "        #text += word_table[k]+' '    \n",
        "    return gtext "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "yO6KzT4c04Jx",
        "outputId": "70616ddc-69d7-4048-ebac-28d99aa2a977"
      },
      "source": [
        "term_weight = np.zeros(_NOISE_DIM,)\n",
        "\n",
        "verbose = False\n",
        "p_score = 0\n",
        "scale = 50\n",
        "epochs = 1000\n",
        "sum_length = len(story_peaks) + int(len(story_peaks)*1.0)\n",
        "pb = ProgressBar(epochs/scale,prefix='Train...')\n",
        "count = 1\n",
        "for epoch in range(epochs):\n",
        "    noise = np.random.rand(_NOISE_DIM,)\n",
        "    # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\n",
        "    noise[story_peaks] += np.mean(noise) \n",
        "    noise += term_weight / count\n",
        "    gtext = text_gen(noise,sum_length)\n",
        "    #print(' '.join([w for (w,k) in gtext]))\n",
        "    #print([k for (w,k) in gtext])    \n",
        "    # 문장 단위로 잘라서 문법 체크...\n",
        "    total_score = []\n",
        "    tw = \"\"\n",
        "    tk = []\n",
        "    for (w,k) in gtext:\n",
        "        tw += w + ' '\n",
        "        tk.append(k)\n",
        "        if w.endswith('.'):\n",
        "            # morpheme_discriminator\n",
        "            #print(tk)\n",
        "            score = morpheme_discriminator([tw])[0]\n",
        "            if verbose:\n",
        "                print(f'score:{score} text:{tw}')\n",
        "            term_weight[tk] += score\n",
        "            total_score.append(score)\n",
        "            tw = \"\"\n",
        "            tk = []\n",
        "            \n",
        "    if len(tk) > 0:\n",
        "        # morpheme_discriminator\n",
        "        #print(tw)\n",
        "        #print(tk)        \n",
        "        score = morpheme_discriminator([tw])[0]\n",
        "        if verbose:\n",
        "            print(f'score:{score} text:{tw}')\n",
        "        term_weight[tk] += score\n",
        "        total_score.append(score)\n",
        "        tw = \"\"\n",
        "        tk = []        \n",
        "            \n",
        "    #term_weight[order] += score\n",
        "    '''\n",
        "    reward = p_score - score\n",
        "    if (p_score ==0):\n",
        "        pass\n",
        "    else:\n",
        "        term_weight[order] += reward\n",
        "    p_score = score\n",
        "    '''\n",
        "    text = ' '.join([w for (w,k) in gtext])\n",
        "\n",
        "    score = similarity_discriminator([text],org_text_emb)\n",
        "\n",
        "    reward = p_score - score\n",
        "    if (p_score ==0):\n",
        "        pass\n",
        "    else:\n",
        "        term_weight[order] += reward\n",
        "    s_score = score\n",
        "\n",
        "    count += 1\n",
        "    if epoch%scale == 0:\n",
        "        pb.printProgress(+1,f'{epoch+scale}/{epochs} epochs, m_score:{str( np.mean(total_score)).ljust(8)} s_score:{score} {text}                                            ')\n",
        "\n",
        "        \n",
        "#plt.plot(term_weight)\n",
        "plt.plot(term_weight)\n",
        "plt.show()\n",
        "gtext = text_gen(term_weight,sum_length)\n",
        "text = ' '.join([w for (w,k) in gtext])\n",
        "score = similarity_discriminator([text],org_text_emb)\n",
        "print('result text : ',text)\n",
        "print('result score : ',score)\n",
        "print('skel_text : ',skel_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rTrain... ||...................| 5.0%   50/1000 epochs, m_score:0.18609184 s_score:0.8493128221981614 여자 아기가 태어났어요. 예쁘고 마음씨 어느날 소녀의 소녀의 아버지는 새어머니를 새어머니는 소녀보다 딸을 왔어요. 언니들은 심술쟁이들이었어요. 자기 게 못마땅했어요. 그런데 아버지마저 소녀는 하녀처럼 종일 쓸고 도맡아 해도 끝이 집안일이 힘들어 쉬곤 재투성이잖아요. 두 소녀를 신데렐라의 집에도 왔어요. 언니들을 데리고 신데렐라도 무도회에 신데렐라는 훌쩍훌쩍 신데렐라 너도 싶니? 고개를 마법사 내가 무도회에 변했어요. 도마뱀은 멋진 장식이 예쁜 신데렐라 발을 신데렐라에게 구두를 신겨 신데렐라 열두시가 마부는 돼. 반드시 밤 아름다운 마음을 왕자님은 다른 쳐다보지도 추었어요. 줄도 몰랐어요. 땡 신데렐라는 신데렐라가 허둥지둥 벗겨졌어요. 하지만 주울 없었어요. 층계에서 구두 결혼하겠어요. 그래서 유리 나라를 발을 오므려도 보고 보았지만 작았어요. 저도 한번 신어 신하게 신었어요 구두는 신데렐라의 발에 뒤                                            "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3f9a0b287778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morg_text_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-e55a48fe9200>\u001b[0m in \u001b[0;36msimilarity_discriminator\u001b[0;34m(queries, org_embedding)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# return : 결과 score 배열 (None,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mquery_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_embedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0morg_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, is_pretokenized)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentence_transformers/models/XLMRoBERTa.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#RoBERTa does not use token_type_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlm_roberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mcls_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# CLS token is first token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlCHabi4oupu"
      },
      "source": [
        "# 효과적으로 구성된 것인지는 모르겠음... 이것은 아직 많은 연구가 필요함.\r\n",
        "# 또한 LSTM으로 바꾸어 길이의 한게를 극복해야 할 것...\r\n",
        "\r\n",
        "def make_generator_model(term_length):\r\n",
        "    input = Input(shape=(term_length), dtype='float64') \r\n",
        "    bias_input = Input(shape=(term_length), dtype='float64') \r\n",
        "    output = Dense(term_length*2, use_bias=False)(input)\r\n",
        "    output = LeakyReLU(0.2)(output)\r\n",
        "    output = Dense(term_length*4, use_bias=False)(output)\r\n",
        "    output = LeakyReLU(0.2)(output)\r\n",
        "    output = Dense(term_length, use_bias=False,activation='linear')(output)\r\n",
        "    output = Add()([output, bias_input])\r\n",
        "    model = Model([input,bias_input],output)\r\n",
        "    \r\n",
        "    model.summary()\r\n",
        "    return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E7Bhf0dsknD",
        "outputId": "4159f53a-9a27-48a1-950a-eb623cd37692"
      },
      "source": [
        "generator = make_generator_model(_NOISE_DIM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 130)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 260)          33800       input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 260)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 520)          135200      leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 520)          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 130)          67600       leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 130)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 130)          0           dense_9[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 236,600\n",
            "Trainable params: 236,600\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVM6VlUE5arZ"
      },
      "source": [
        "def discrete_discriminator(weights,term_length,verbose=0):\r\n",
        "    fake_gen_out = np.zeros(weights.shape)\r\n",
        "    fake_dis_out = []\r\n",
        "    real_dis_out = []\r\n",
        "    real_morphemes = get_org_morpheme_sample(weights.shape[0])\r\n",
        "    for i, noise in enumerate(weights):\r\n",
        "        gtext = text_gen(noise,term_length)\r\n",
        "        tw = \"\"\r\n",
        "        tk = []\r\n",
        "        fake_scores = []\r\n",
        "        for (w,k) in gtext:\r\n",
        "            tw += w + ' '\r\n",
        "            tk.append(k)\r\n",
        "            if w.endswith('.'):\r\n",
        "                # morpheme_discriminator\r\n",
        "                #print(tk)\r\n",
        "                fake_score = morpheme_discriminator([tw])[0]\r\n",
        "                fake_gen_out[i,tk] += fake_score\r\n",
        "                fake_dis_out.append(fake_score[0])\r\n",
        "                real_score = morpheme_model(np.array([real_morphemes[i]]))[0]\r\n",
        "                #print(real_score)\r\n",
        "                real_dis_out.append(real_score[0])\r\n",
        "                if verbose:\r\n",
        "                    print(f'score:{str(fake_score).ljust(12)} text:{tw}')\r\n",
        "                tw = \"\"\r\n",
        "                tk = []\r\n",
        "                \r\n",
        "        if len(tk) > 0:\r\n",
        "            # morpheme_discriminator\r\n",
        "            #print(tw)\r\n",
        "            #print(tk)        \r\n",
        "            fake_score = morpheme_discriminator([tw])[0]\r\n",
        "            fake_gen_out[i,tk] += fake_score\r\n",
        "            fake_dis_out.append(fake_score[0])\r\n",
        "            real_score = morpheme_model(np.array([real_morphemes[i]]))[0]\r\n",
        "            #print(real_score)            \r\n",
        "            real_dis_out.append(real_score.numpy()[0])\r\n",
        "            if verbose:\r\n",
        "                print(f'score:{str(fake_score).ljust(12)} text:{tw}')\r\n",
        "            tw = \"\"\r\n",
        "            tk = []\r\n",
        "        #print(fake_gen_out)\r\n",
        "        #print(fake_dis_out)\r\n",
        "        #print(real_dis_out)\r\n",
        "    return tf.constant(fake_gen_out,tf.float64), tf.constant(fake_dis_out,tf.float64), tf.constant(real_dis_out,tf.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGQygTH2CqlQ"
      },
      "source": [
        "def discrete_discriminator2(weights,term_length,verbose=0):\r\n",
        "    fake_gen_out = np.zeros(weights.shape)\r\n",
        "    real_morphemes = get_org_morpheme_sample(weights.shape[0])\r\n",
        "    fake_morps = []\r\n",
        "    real_morps = []\r\n",
        "    apply_order = []\r\n",
        "    for i, noise in enumerate(weights):\r\n",
        "        gtext = text_gen(noise,term_length)\r\n",
        "        tw = \"\"\r\n",
        "        tk = []\r\n",
        "        fake_scores = []\r\n",
        "        for (w,k) in gtext:\r\n",
        "            tw += w + ' '\r\n",
        "            tk.append(k)\r\n",
        "            if w.endswith('.'):\r\n",
        "                fake_morps.append(morpheme_encode(tw))\r\n",
        "                real_morps.append(real_morphemes[i])\r\n",
        "                apply_order.append((i,tk))\r\n",
        "                tw = \"\"\r\n",
        "                tk = []\r\n",
        "                \r\n",
        "        if len(tk) > 0:\r\n",
        "            fake_morps.append(morpheme_encode(tw))\r\n",
        "            real_morps.append(real_morphemes[i])\r\n",
        "            apply_order.append((i,tk))\r\n",
        "\r\n",
        "    fake_dis_out=discriminator(np.asarray(fake_morps))\r\n",
        "    real_dis_out=discriminator(np.asarray(real_morps))\r\n",
        "    for j, (i,tk) in enumerate(apply_order):\r\n",
        "        fake_gen_out[i,tk] += fake_dis_out[j].numpy()\r\n",
        "\r\n",
        "    return tf.constant(fake_gen_out,tf.float64), fake_dis_out, real_dis_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnedA6uHxi8i"
      },
      "source": [
        "N = 1\r\n",
        "count = tf.Variable(1.0)\r\n",
        "tf_term_weight = tf.zeros([_NOISE_DIM])\r\n",
        "noise = np.random.rand(N,_NOISE_DIM)\r\n",
        "biased_noise = np.random.rand(N,_NOISE_DIM)\r\n",
        "# stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\r\n",
        "biased_noise[:,story_peaks] += np.mean(noise) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5fJ5VHctssK",
        "outputId": "63e35c16-07a1-4b52-d544-28b99d8443c6"
      },
      "source": [
        "sw = generator([noise,biased_noise], training=False)\r\n",
        "sw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 130), dtype=float32, numpy=\n",
              "array([[-2.727211  , -2.6566296 , -3.6468713 , -2.353024  , -3.4145613 ,\n",
              "        -3.4427161 , -1.8853716 , -3.9607382 , -5.070578  ,  0.8872408 ,\n",
              "         0.81301165,  2.5031197 , -4.3385944 , -4.8531575 , -4.7797728 ,\n",
              "        -3.7902186 , -3.879929  , -3.5928535 , -4.661707  ,  1.4843042 ,\n",
              "        -3.5804267 ,  3.280509  ,  2.9683967 , -1.8485756 ,  2.2089078 ,\n",
              "        -2.4236448 , -3.9157438 , -4.749207  , -4.957942  , -3.4112616 ,\n",
              "         1.4930211 , -4.7299266 ,  2.6713061 ,  1.5714413 , -4.384794  ,\n",
              "        -4.3578877 , -5.3620815 ,  2.0236015 , -3.5562139 ,  3.928235  ,\n",
              "        -3.722928  , -5.015372  , -3.6316612 ,  3.305924  , -2.8360155 ,\n",
              "        -4.8435287 , -3.9334033 ,  2.181071  , -4.46212   , -4.0843196 ,\n",
              "        -3.4476504 ,  3.0143917 , -4.195564  , -2.8834424 , -4.6018543 ,\n",
              "        -3.2716677 , -3.0480032 ,  2.8386292 ,  4.289023  , -3.6119418 ,\n",
              "         2.9379623 ,  6.4975004 , -4.3132772 , -2.8354778 , -3.7726412 ,\n",
              "         1.8866329 ,  2.0881302 ,  3.2979114 , -2.7376719 , -2.8378897 ,\n",
              "         1.365592  , -4.549559  , -3.9934297 , -4.0529556 ,  4.2603116 ,\n",
              "        -3.7750697 ,  4.1004558 , -3.9679816 ,  5.503526  , -3.6207592 ,\n",
              "        -3.5306451 , -2.1393378 , -4.013399  , -2.9705186 , -2.5656986 ,\n",
              "         5.564089  , -2.9556785 ,  3.9128675 , -3.0598147 , -4.4023967 ,\n",
              "        -3.6520445 , -3.8980827 ,  4.934049  ,  5.6173735 , -3.27919   ,\n",
              "        -3.1637058 , -4.7076674 ,  3.0646863 , -4.857986  , -3.504841  ,\n",
              "        -0.2616485 , -3.1821663 ,  3.5653179 , -3.6037881 , -3.485555  ,\n",
              "         2.7928405 , -4.0903397 ,  3.571803  ,  3.9127061 , -4.4447236 ,\n",
              "         3.0645638 ,  2.8372536 ,  2.2655306 , -4.0572624 ,  4.281524  ,\n",
              "        -3.3159833 , -4.4838715 , -2.9480796 , -4.078302  , -2.1968544 ,\n",
              "         4.1455274 , -4.090524  ,  4.9983053 ,  6.357575  , -1.8331937 ,\n",
              "        -3.4866436 , -3.55341   , -5.5684237 ,  4.78827   , -1.9401534 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlE7dPry5BfF",
        "outputId": "bbad14d2-75e2-49d4-f15b-7f0daca30afc"
      },
      "source": [
        ".shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRdqMTNC6SAV",
        "outputId": "12aaaee2-a62f-47a6-c112-edf4836e5306"
      },
      "source": [
        "# skeleton_length + N%의 길이로 생성\r\n",
        "gen_length = len(story_peaks) + int(len(story_peaks)*1.0)\r\n",
        "sw = generator([noise,biased_noise], training=False)\r\n",
        "fake_gen_out, fake_dis_out, real_dis_out = discrete_discriminator2(sw,gen_length,verbose=0)\r\n",
        "print(fake_gen_out)\r\n",
        "print(fake_dis_out)\r\n",
        "print(real_dis_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.80133879 0.80133879\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.80133879 0.         0.80133879 0.80133879 0.80133879\n",
            "  0.80133879 0.         0.         0.         0.         0.\n",
            "  0.80133879 0.         1.17922378 1.17922378 0.         0.\n",
            "  0.         1.17922378 0.         1.17922378 0.         0.\n",
            "  0.         1.17922378 0.         0.         0.         1.17922378\n",
            "  0.         0.         0.         1.17922378 0.         0.\n",
            "  0.         0.         0.         1.17922378 1.15970588 0.\n",
            "  1.15970588 1.15970588 0.         0.         0.         1.15970588\n",
            "  1.15970588 1.15970588 0.         0.         1.15970588 0.\n",
            "  0.         0.         1.15970588 0.         1.15970588 0.\n",
            "  1.15970588 0.         0.         0.         0.         0.\n",
            "  0.         1.15970588 0.         1.15970588 0.         0.\n",
            "  0.         0.         1.15970588 1.15970588 0.         0.\n",
            "  0.         1.15970588 0.         0.         1.15970588 0.\n",
            "  1.15970588 0.         0.         1.15970588 0.         1.15970588\n",
            "  1.15970588 0.         1.08138812 1.08138812 1.08138812 0.\n",
            "  1.08138812 0.         0.         0.         0.         0.\n",
            "  1.08138812 0.         1.08138812 1.08138812 0.         0.\n",
            "  0.         0.         1.08138812 0.        ]], shape=(1, 130), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[0.8013388]\n",
            " [1.1792238]\n",
            " [1.1597059]\n",
            " [1.0813881]], shape=(4, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1.0651408]\n",
            " [1.0651408]\n",
            " [1.0651408]\n",
            " [1.0651408]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhTzyHuN60Dd"
      },
      "source": [
        "## generator의 학습!!!\r\n",
        "\r\n",
        "def train(epochs=10,batch_size=10):\r\n",
        "    # In the Deepmind paper they use RMSProp however then Adam optimizer\r\n",
        "    # improves training time\r\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "    # This method returns a helper function to compute cross entropy loss\r\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "    gen_length = len(story_peaks) + int(len(story_peaks)*1.0)\r\n",
        "    pb = ProgressBar(epochs,prefix='Train...')\r\n",
        "    gen_loss_history = []\r\n",
        "    dis_loss_history = []    \r\n",
        "    for i in range(epochs):\r\n",
        "        noise = np.random.rand(batch_size,_NOISE_DIM)\r\n",
        "        biased_noise = np.random.rand(batch_size,_NOISE_DIM)\r\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\r\n",
        "        biased_noise[:,story_peaks] += np.mean(noise)\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "        \r\n",
        "            sw = generator([noise,biased_noise], training=True)\r\n",
        "            fake_gen_out, fake_dis_out, real_dis_out = discrete_discriminator2(sw,gen_length)\r\n",
        "        \r\n",
        "            gen_loss = cross_entropy(fake_gen_out, sw)\r\n",
        "\r\n",
        "            # 진짜를 넣은 것에 대한 output\r\n",
        "            real_loss = cross_entropy(tf.ones_like(real_dis_out), real_dis_out)\r\n",
        "            fake_loss = cross_entropy(tf.zeros_like(fake_dis_out), fake_dis_out)\r\n",
        "            dis_loss = real_loss + fake_loss\r\n",
        "\r\n",
        "        # Backpropagation\r\n",
        "        dis_grads = tape.gradient(dis_loss, discriminator.trainable_variables)\r\n",
        "        generator_optimizer.apply_gradients(zip(dis_grads, discriminator.trainable_variables))\r\n",
        "\r\n",
        "\r\n",
        "        noise = np.random.rand(batch_size,_NOISE_DIM)\r\n",
        "        biased_noise = np.random.rand(batch_size,_NOISE_DIM)\r\n",
        "        # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\r\n",
        "        biased_noise[:,story_peaks] += np.mean(noise)\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            sw = generator([noise,biased_noise], training=True)\r\n",
        "            fake_gen_out, fake_dis_out, real_dis_out = discrete_discriminator2(sw,gen_length)\r\n",
        "            gen_loss = cross_entropy(fake_gen_out, sw)\r\n",
        "\r\n",
        "        gen_grads = tape.gradient(gen_loss, generator.trainable_variables)\r\n",
        "        generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\r\n",
        "\r\n",
        "        gen_loss_history.append(gen_loss)\r\n",
        "        dis_loss_history.append(dis_loss)\r\n",
        "\r\n",
        "        pb.printProgress(+1,f'{i+1}/{epochs} epochs, gen_loss:{gen_loss}, dis_loss:{dis_loss}             ')\r\n",
        "\r\n",
        "    return  {'gen_loss':gen_loss_history,'dis_loss':dis_loss_history}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbn613VWeW7z"
      },
      "source": [
        "def genere_summary(count):\r\n",
        "    texts = []\r\n",
        "    gen_length = len(story_peaks) + int(len(story_peaks)*1.0)\r\n",
        "    noise = np.random.rand(count,_NOISE_DIM)\r\n",
        "    biased_noise = np.random.rand(count,_NOISE_DIM)\r\n",
        "    # stroy peak에 해당하는 term에게 평균값에 해당하는 bias를 추가 한다.\r\n",
        "    biased_noise[:,story_peaks] += np.mean(noise)\r\n",
        "    sw = generator.predict([noise,biased_noise])\r\n",
        "    for noise in sw:\r\n",
        "        gtext = text_gen(noise,gen_length)\r\n",
        "        text = ' '.join([w for (w,k) in gtext])\r\n",
        "        #print(text)\r\n",
        "        texts.append(text)\r\n",
        "    return texts\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR1NDncNdqwI",
        "outputId": "c307f5e2-75ad-483a-d825-5ad9553b2fd9"
      },
      "source": [
        "history = train(epochs=50,batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train... |||||||||||||||||||||| 100.0%   50/50 epochs, gen_loss:0.3115934729576111, dis_loss:1.0081886053085327             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrrq79vlfJDk",
        "outputId": "abdf7246-fca7-49d1-fdba-cda1d17e044c"
      },
      "source": [
        "texts = genere_summary(2)\r\n",
        "for txt in texts:\r\n",
        "    print('text:',txt)\r\n",
        "print('skel:',skel_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: 이 사슴이 사냥꾼이 신기하게 나무꾼이 사슴을 숨겨줬고 뒤쫓아 구해주었다. 은혜를 갚겠다고 하늘에서 목욕하는 선녀들이 목욕을 선녀의 아내로 주었다. 나무꾼은 하면서도 사슴이 목욕을 하러 내려온다는 몸을 기다리자 선녀들이 내려와 선녀탕에서 나무꾼은 날개옷이 없어진 선녀는 선녀들은 선녀를 하늘로 돌아갔다. 홀로 자신의 올라가지 못하게 선녀는 할 되었다.\n",
            "text: 이 사슴이 사냥꾼이 신기하게 나무꾼이 사슴을 숨겨줬고 뒤쫓아 구해주었다. 은혜를 갚겠다고 하늘에서 목욕하는 목욕을 선녀의 아내로 주었다. 나무꾼은 하면서도 사슴이 목욕을 하러 내려온다는 몸을 기다리자 선녀들이 내려와 선녀탕에서 나무꾼은 날개옷이 없어진 선녀는 선녀들은 선녀를 하늘로 돌아갔다. 나무꾼이 홀로 자신의 올라가지 못하게 선녀는 할 되었다.\n",
            "skel: 숲 사냥꾼이 나무꾼이 뒤쫓아 사냥꾼을 갚겠다고 목욕하는 목욕을 선녀의 아내로 나무꾼은 목욕을 숨겼다. 선녀들이 내려와 나무꾼은 없어진 선녀들은 선녀를 자신의 못하게 되었다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNQLESjyeONH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}