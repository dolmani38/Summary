{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_abstractive_summarizaion_v1.2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary/blob/master/reinforce_based_summarization_v0.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdM3q73ReHxs"
      },
      "source": [
        "# **Korean Summarizer Using Multiple Discriminators**\n",
        "\n",
        "참조 : https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n",
        "\n",
        "참조 : https://github.com/williamSYSU/TextGAN-PyTorch\n",
        "\n",
        "* 2020년12월27일 v1.0 완전히 실패...\n",
        "* 2020년12월27일 오후 Generator 다시 만들고... 역시 실패 한듯... v1.2 완전히 실패...\n",
        "* 문법 Discriminator를 먼저 학습하고... transfer learning을 사용해 보자.\n",
        "* 그래도 역시 Generator는 다시 만들어야 할 듯."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBNW5dMZ13G",
        "trusted": true
      },
      "source": [
        "DO_ALL = True # 전체 실행하면서 시간 걸리는 걸 Pass 하려면 이걸 False ...\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "FlvsCFJaeHxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9f1436-112a-4117-e4f1-007a6bd7732e"
      },
      "source": [
        "\n",
        "if DO_ALL:\n",
        "    !pip install sentence-transformers==0.3.0\n",
        "    !pip install transformers==3.0.2\n",
        "    !pip install wikipedia\n",
        "    !pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers==0.3.0 in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (4.41.1)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.0) (3.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.1.94)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.8.1rc1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (20.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.1.94)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.0.43)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (1.0.0)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Em1oCkJceHxz"
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "import keras.utils as ku \n",
        "\n",
        "# set seeds for reproducability\n",
        "from tensorflow.random import set_seed\n",
        "from numpy.random import seed\n",
        "set_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdj0QfSeHx1"
      },
      "source": [
        "# 학습을 위한 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94NlJEeHeHx3"
      },
      "source": [
        "네이버 뉴스에서 아무거나 하나 Text를 얻어옴\n",
        "\n",
        "이것을 '요약' 목표"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lz5XtC9MeHx5"
      },
      "source": [
        "org_text = \"\"\"\n",
        "옛날 어느 집에 귀여운 여자 아기가 태어났어요.\n",
        "아기는 무럭무럭 자라서, 예쁘고 마음씨 고운 소녀가 되었어요.\n",
        "그러던 어느날, 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요.\n",
        "소녀의 아버지는 홀로 남은 소녀가 걱정되었어요.\n",
        "그래서 얼마 후 새어머니를 맞이했어요.\n",
        "새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요.\n",
        "그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요.\n",
        "새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요.\n",
        "그런데 이번에는 아버지마저 돌아가셨어요.\n",
        "소녀는 하녀처럼 하루 종일 쓸고, 닦고, 집안일을 도맡아 했어요.\n",
        "해도 해도 끝이 없는 집안일이 힘들어 지칠때면\n",
        "난롯가에 앉아서 잠시 쉬곤 했지요.\n",
        "\"엄마, 저애를 신데렐라라고 불러야겠어요.\"\n",
        "\"온통 재투성이잖아요. 호호호!\" 두 언니는 소녀를 놀려 댔어요.\n",
        "어느 날, 왕궁에서 무도회가 열렸어요.\n",
        "신데렐라의 집에도 초대장이 왔어요.\n",
        "새어머니는 언니들을 데리고 무도회장으로 떠났어요.\n",
        "신데렐라도 무도회에 가고 싶었어요.\n",
        "혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요.\n",
        "\"신데렐라, 너도 무도회에 가고 싶니?\"\n",
        "신데렐라가 고개를 들어보니, 마법사 할머니가 빙그레 웃고 있었어요.\n",
        "\"내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리, 도마뱀을 구해 오렴.\"\n",
        "마법사 할머니가 주문을 외웠어요.\n",
        "그리고 지팡이로 호박을 건드리자, 호박이 화려한 황금 마차로 변했어요.\n",
        "이번에는 생쥐와 도마뱀을 건드렸어요.\n",
        "그랬더니 생쥐는 흰말로, 도마뱀은 멋진 마부로 변했답니다.\n",
        "신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요.\n",
        "\"신데렐라, 발을 내밀어 보거라.\"\n",
        "할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요.\n",
        "\"신데렐라, 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로, 흰말은 생쥐로, 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지?\"\n",
        "왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요.\n",
        "왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고,\n",
        "신데렐라하고만 춤을 추었어요.\n",
        "신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요.\n",
        "땡, 땡, 땡...... 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요.\n",
        "신데렐라가 허둥지둥 왕궁을 빠져나가는데,\n",
        "유리 구두 한 짝이 벗겨졌어요.\n",
        "하지만 구두를 주울 틈이 없었어요.\n",
        "신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요.\n",
        "왕자님은 유리 구두를 가지고 임금님께 가서 말했어요.\n",
        "\"이 유리 구두의 주인과 결혼하겠어요.\"\n",
        "그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요.\n",
        "언니들은 발을 오므려도 보고, 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요.\n",
        "그때, 신데렐라가 조용히 다가와 말했어요.\n",
        "\"저도 한번 신어 볼 수 있나요?\"\n",
        "신데렐라는 신하게 건넨 유리 구두를 신었어요,\n",
        "유리 구두는 신데렐라의 발에 꼭 맞았어요.\n",
        "신하들은 신데렐라를 왕궁으로 데리고 갔어요.\n",
        "그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요.\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qa-qIW1h3DkA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "e63f9a76-0a3a-4809-96ca-c8888de9ad36"
      },
      "source": [
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n','')\n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    return txt \n",
        "\n",
        "org_text = clean_text(org_text)\n",
        "org_text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'옛날 어느 집에 귀여운 여자 아기가 태어났어요. 아기는 무럭무럭 자라서 예쁘고 마음씨 고운 소녀가 되었어요. 그러던 어느날 소녀의 어머니가 병이들어 그만 세상을 떠나고 말았어요. 소녀의 아버지는 홀로 남은 소녀가 걱정되었어요. 그래서 얼마 후 새어머니를 맞이했어요. 새어머니는 소녀보다 나이가 위인 두 딸을 데리고 왔어요. 그러나 새어머니와 언니들은 성질이 고약한 심술쟁이들이었어요. 새어머니는 소녀가 자기 딸들보다 예쁘고 착한 게 못마땅했어요. 그런데 이번에는 아버지마저 돌아가셨어요. 소녀는 하녀처럼 하루 종일 쓸고 닦고 집안일을 도맡아 했어요. 해도 해도 끝이 없는 집안일이 힘들어 지칠때면난롯가에 앉아서 잠시 쉬곤 했지요. 엄마 저애를 신데렐라라고 불러야겠어요. 온통 재투성이잖아요. 호호호! 두 언니는 소녀를 놀려 댔어요. 어느 날 왕궁에서 무도회가 열렸어요. 신데렐라의 집에도 초대장이 왔어요. 새어머니는 언니들을 데리고 무도회장으로 떠났어요. 신데렐라도 무도회에 가고 싶었어요. 혼자 남은 신데렐라는 훌쩍훌쩍 울기 시작했어요. 신데렐라 너도 무도회에 가고 싶니?신데렐라가 고개를 들어보니 마법사 할머니가 빙그레 웃고 있었어요. 내가 너를 무도회에 보내주마 호박 한개와 생쥐 두마리 도마뱀을 구해 오렴. 마법사 할머니가 주문을 외웠어요. 그리고 지팡이로 호박을 건드리자 호박이 화려한 황금 마차로 변했어요. 이번에는 생쥐와 도마뱀을 건드렸어요. 그랬더니 생쥐는 흰말로 도마뱀은 멋진 마부로 변했답니다. 신데렐라의 옷도 구슬 장식이 반짝이는 예쁜 드레스로 바뀌웠어요. 신데렐라 발을 내밀어 보거라. 할머니는 신데렐라에게 반짝반짝 빛나는 유리 구두를 신겨 주었어요. 신데렐라 밤 열두시가 되면 모든게 처음대로 돌아간단다. 황금 마차는 호박으로 흰말은 생쥐로 마부는 도마뱀으로 변하게 돼. 그러니까 반드시 밤 열두 시가 되기 전에 돌아와야 해. 알겠지?왕자님도 아름다운 신데렐라에게 마음을 빼았겼어요. 왕자님은 무도회장에 모인 다른 아가씨들은 쳐다보지도 않고신데렐라하고만 춤을 추었어요. 신데렐라는 왕자님과 춤을 추느라 시간 가는 줄도 몰랐어요. 땡 땡 땡 벽시계가 열두 시를 알리는 소리에 신데렐라는 화들짝 놀랐어요. 신데렐라가 허둥지둥 왕궁을 빠져나가는데유리 구두 한 짝이 벗겨졌어요. 하지만 구두를 주울 틈이 없었어요. 신데렐라를 뛰쫓아오던 왕자님은 층계에서 유리 구두 한 짝을 주웠어요. 왕자님은 유리 구두를 가지고 임금님께 가서 말했어요. 이 유리 구두의 주인과 결혼하겠어요. 그래서 신하들은 유리 구두의 주인을 찾아 온 나라를 돌아다녔어요. 언니들은 발을 오므려도 보고 구두를 늘려도 보았지만 한눈에 보기에도 유리 구두는 너무 작았어요. 그때 신데렐라가 조용히 다가와 말했어요. 저도 한번 신어 볼 수 있나요?신데렐라는 신하게 건넨 유리 구두를 신었어요유리 구두는 신데렐라의 발에 꼭 맞았어요. 신하들은 신데렐라를 왕궁으로 데리고 갔어요. 그 뒤 신데렐라는 왕자님과 결혼하여 오래오래 행복하게 살았대요. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-k66tHNeHx6"
      },
      "source": [
        "## 한국어 문법 구분 discriminator 학습\n",
        "\n",
        "* '한글 위키백과'에서 임의의 문장을 수집 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oi6AfKSzeHx7"
      },
      "source": [
        "#한국어 위키백과에서 스크랩핑\n",
        "\n",
        "import wikipedia as wiki\n",
        "wiki.set_lang('ko')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ekFwbQVxeHx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b9fbd6-1e1a-45f2-eeaa-580cb8863dd0"
      },
      "source": [
        "# '전래동화' 라는 keyword로 100개 page의 Text를 취득\n",
        "\n",
        "def __search_from_wiki(question,max_rank):\n",
        "    results = wiki.search(question,results=max_rank)\n",
        "    print(results)\n",
        "    contents = []\n",
        "    for result in results:\n",
        "        try:\n",
        "            page = wiki.page(result)\n",
        "            #print(f\"Top wiki result: {page}\")\n",
        "            text = page.content\n",
        "            ln = len(text)\n",
        "            #print(f'Collecting page : {page} , text length {str(ln)}')\n",
        "            #if ln < 4000:\n",
        "            #  contents.append(text)\n",
        "            #else:\n",
        "            #  contents.append(text[0:4000])\n",
        "            contents.append(text)\n",
        "        except Exception as ex:\n",
        "            print(ex)\n",
        "    return contents\n",
        "\n",
        "if DO_ALL:\n",
        "    ko_grammar_set_raw = __search_from_wiki(\"동화\",300)\n",
        "    print(f'전체 수집한 Page Count : {len(ko_grammar_set_raw)}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['동화', '니코니코 동화', '동화중학교 (경기)', '문화 동화', '조곡 니코니코 동화', '동화사', '신에이 동화', '동화작용', '번암초등학교 동화분교', '책상 서랍 속의 동화', '동화초등학교 (경기)', '동화약품', '동화기업', '동화역', '동화고등학교', '동화면세점', '동화초등학교 (전남)', '화성동화중학교', '그림 동화', '동화초등학교 (강원)', '단백동화 스테로이드', '가을동화', '동화 (언어학)', '동화초등학교 (충북)', '애니메이션', '수성알파시티 동화아이위시', '동화도서관', '훈1등 욱일동화대수장', '동화초등학교', '도에이 애니메이션', '동화중학교 (강원)', '동화은행', '전북동화중학교', '대전동화초등학교', 'TV로 보는 원작동화', '동윤', '대전동화중학교', '신 전래동화', '동화초등학교 (제주)', '도라에몽 (1973년 애니메이션)', '한스 크리스티안 안데르센', '대원씨아이', '빌헬름 하우프', '동화면', '그림 형제', '동화 읽어주는 TV', '빛가람장성로', '아동 문학', 'TV동화 행복한 세상', '권설 설측 접근음', '촉한', '정이서', '동화운수 (인천)', '대구막항', '동문항', '질소 고정', '전한', '대구 동화사 비로암 삼층석탑', '대한민국의 국회의원 선거구 목록', '유글레나류', '리하르트 빌슈테터', '코파반장의 동화수사대', '팔공산', '쥐', '리루프릿', '1844년', '스튜디오 지브리', '동화 (후한)', '동화운수 (광주)', '대구 동화사 당간지주', '동화처럼', '주엽어린이도서관', '아돌프 폰 바이어', '必UP되다', '신-맨', '산서초등학교 (전북)', '샤를 페로', '란티스 조곡 feat.Nico Nico Artists', '오엘엠', '스튜디오 딘', '등장인물', '동화 (화폐)', '루트비히 티크', '대구 동화사 마애여래좌상', '일본동화협회', '삼성물산', '한국의 사찰', '곰돌이 푸', '사랑의 시나리오', '김지우 (1983년)', '안녕 자두야', '쇼 바이 락!!', '도라에몽 그리기', '순천 동화사 삼층석탑', '동화나라 꿈동산', '불도그', '귀스타브 도레', '주화', '도가코보', '장성소방서', '보그 (스타 트렉)', '호리구치 유키코', '도라에몽: 스탠바이미', '은비까비의 옛날옛적에', '호시조라 미유키', '야코프 그림', '동화 (영화)', '백설 공주', '황민화 정책', '짱구는 못말려 극장판: 태풍을 부르는 장엄한 전설의 전투', '정범균', 'Oneiric Diary (幻想日記)', '잠자는 숲속의 미녀', '한다시', '불꽃놀이 (1997년 드라마)', '짱구는 못말려 극장판: 태풍을 부르는 노래하는 엉덩이 폭탄!', '장 드 라 퐁텐', '조류 (수생 생물)', '방정환', '서울동화축제', '삽화가', '일본의 애니메이션', '권정생', '프린세스 츄츄', '아이 러브 이태리', '옛날 옛적에 (애니메이션)', '지방도 제743호선', '슈렉', 'TVB 코리아', '클레오', '영심이', '책', '스튜어트 리틀', '남세균', '계몽사', '머털도사', '판타지 문학', '잠자는 숲속의 미녀 (1959년 영화)', '피노키오', '마야', '오로라 (디즈니)', '천사의 분노', '와우중학교', '라푼첼', '짱구는 못말려 극장판: 어른 제국의 역습', '극장판 도라에몽: 진구의 달 탐사기', '황록조류', '짱구는 못말려 극장판: 폭풍을 부르는 정글', '그림명작극장', '이산 (태국)', '대구 동화사 대웅전', '신데렐라 (디즈니)', '블랙★록 슈터', '동우에이앤이', '리미티드 애니메이션', '벨 (디즈니)', '대구 동화사 부도군', '바다의 전설 장보고', '이세진 (희극인)', '구성주의 (교육)', '허구 국가', '대구 동화사 비로암 석조비로자나불좌상', '대구 동화사 보조국사 지눌 진영', '마해송', '예른 안데르센', '지방도 제312호선', '유대인', '서울동화프로덕션', '정상희', '인어 공주 (1989년 영화)', '빌리빌리', '오즈의 마법사 (1939년 영화)', '대구 동화사 극락전', '헨젤과 그레텔', '우뢰매', '봉담고등학교', 'KBS 키즈', '한국일보', '검정고무신', '조안 (배우)', '동화 만화 캘린더', '복현규', '마크 트웨인', '에어맨을 쓰러뜨릴 수 없어', '루이스 세풀베다', '슈퍼 시로', '유루캠Δ', '내 여동생이 이렇게 귀여울 리가 없어의 에피소드 목록', '아이누', '간현역', '서울시립 어린이도서관', '빨간 자전거', '출판사', '아스트리드 린드그렌', '라이먼 프랭크 바움', '원주민', '꾸러기 수비대', '아기공룡 둘리', '신춘문예', '일본인', '극장판 도라에몽 진구의 아프리카 모험: 베코와 5인의 탐험대', '떠돌이 까치', 'P.A. 웍스', '이화작용', '청자 동화연화문 표주박모양 주전자', '슈퍼 태권 V', '니코니코 생방송', '산서중학교', '이언 플레밍', '겨울연가', '물망초 (드라마)', '대구 동화사 염불암 청석탑', '비의', '채은정', '효행로', '에리얼 (디즈니)', 'DR 무비', '아바르', '으랏차차 짠돌이네', '허브 (영화)', '오세암', 'ATC 코드 A14', '제비', '사이비 종교', '공주와 개구리', '인어', 'MBC 베스트셀러극장', '욱일장', 'SUPER SHOW 2', '동게르만족', '백설 공주와 일곱 난쟁이 (영화)', '눈의 여왕', '음운 규칙', 'Love in me', '이광모', '강제동화', '대구 동화사 아미타회상도', '이카보드와 토드경의 모험', '토키와 타카코', '나카시마 테츠야', '이동윤', '지방도 제616호선', '프랜시스 호지슨 버넷', '대사경로', '이종혁 (성우)', '짱구는 못말려 극장판: 폭풍을 부르는 석양의 떡잎마을 방범대', '독고탁 2 - 내 이름은 독고탁', '순수의 시대 (드라마)', 'ㅥ', '꼬비꼬비', '이솝 우화', '대구 동화사 염불암 마애여래좌상 및 보살좌상', '동화 (동음이의)', '봉담읍', '동요', '신춘호', '남자친구 (드라마)', '핑두시', '일선동조론', 'Into The New World (콘서트)', '신데렐라 (1950년 영화)', '나두야 간다', '메틸말로닐-CoA', '걸리버 여행기', '류칭윈', '대구 동화사 사명당 유정 진영', '총림', '이원수 (작가)', '비밀정원', '위세 성', '셉티미우스 세베루스', '바이윈구 (광저우시)', '대공원역 (과천)', '여름향기', '그린세이버', '자전거 도둑 (박완서)', '흑마녀 나가신다!!', '파파야 (음악 그룹)', '짱구는 못말려 극장판: 태풍을 부르는 영광의 불고기 로드', '물질대사', '1805년', '대구 동화사 삼장보살도', '니코니코 대백과', '흙꼭두장군', '송정천 (울산)', '멜랑슈', '의왕백운호수축제', '산서고등학교', '하종오', '귄터 폰 클루게', '최강희 (배우)', '빨간 두건', '문학', '대구 동화사 금당암 동·서 삼층석탑', '사토 준이치', '녹색조류', '1835년', '1875년', '베이후구', '쇼와 국가주의']\n",
            "\"동화초등학교\" may refer to: \n",
            "동화초등학교\n",
            "동화초등학교\n",
            "동화초등학교\n",
            "동화초등학교\n",
            "동화초등학교\n",
            "대전동화초등학교\n",
            "\"마야\" may refer to: \n",
            "마야 문명\n",
            "마야 (종교)\n",
            "마야 달력\n",
            "마야 숫자\n",
            "마야 문자\n",
            "마야 역\n",
            "마야 (소프트웨어)\n",
            "MAYA\n",
            "마야 (가수)\n",
            "마야\n",
            "요시다 마야\n",
            "유네스키 마야\n",
            "마야 미키\n",
            "마야 산사\n",
            "마야 루돌프\n",
            "마야 앤절로\n",
            "코이즈미 마야\n",
            "마야 로렌스\n",
            "마야 카린\n",
            "마야 스토얀\n",
            "마야 아바바자니\n",
            "마야 보호시에비치\n",
            "마야 카잔\n",
            "마야 알데린\n",
            "마야 쿨리예바\n",
            "모리 마야\n",
            "마야 오스타셰프스카\n",
            "마야 히르슈\n",
            "마야 다간\n",
            "마야 디아브\n",
            "마야 나세르\n",
            "에드워드 마야\n",
            "마야 야게르\n",
            "마야 눌키츠\n",
            "내 이름은 마야\n",
            "꿀벌 마야\n",
            "마야 (1966년 영화)\n",
            "마야 (2014년 영화)\n",
            "마야 아일랜드 항공\n",
            "\"동화 (동음이의)\" may refer to: \n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화\n",
            "동화 (가수)\n",
            "전체 수집한 Page Count : 297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tu_6jZAmeHx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976ae952-4e93-4874-c54b-c497b887bc5c"
      },
      "source": [
        "# 간단한 전처리\n",
        "\n",
        "ko_grammar_set_raw = [clean_text(x) for x in ko_grammar_set_raw]\n",
        "print('Sample text : ')\n",
        "print('--------------------------------------------------------------------------------------------')\n",
        "print(ko_grammar_set_raw[50])\n",
        "print('--------------------------------------------------------------------------------------------')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample text : \n",
            "--------------------------------------------------------------------------------------------\n",
            "정이서(1993년 8월 13일 ~ )는 대한민국의 배우이다. 학력 동덕여자대학교 방송연예학과 출연 작품 영화 《조제》 (2020년) - 나영 역《삼진그룹 영어토익반》 (2020년) - 감사실 역《7월7일》 (2020년) - 미주 역《기생충》 (2019년) - 피자사장 역《산책》 (2018년)《수성못》 (2018년) - 도를 믿는 여자 역《리얼》 (2017년) - 밀실클럽 중독자 역《레볼루션》 (2015년) - 동화 역 드라마 《구미호뎐》 (2020년 tvN) - 김새롬 역《KBS 드라마 스페셜 - 굿바이 비원》 (2019년 KBS2) - 박경혜 역《보이스 3》 (2019년 OCN) - 권세영 역《고양이 바텐더》 (2019년 웹드라마) - 은주 역《마이 엑스 다이어리》 (2018년 웹드라마) - 보나 역 각주 외부 링크 정이서 - 인스타그램\n",
            "--------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqJHLPaReHx-"
      },
      "source": [
        "문장으로 잘라 낸다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_b8WKqYXeHx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6369d6-ff89-4d4c-c664-e2c8a81baaf3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "#Split the document into sentences\n",
        "ko_grammar_sentences = []\n",
        "for document in ko_grammar_set_raw:\n",
        "    ko_grammar_sentences += nltk.sent_tokenize(document)\n",
        "\n",
        "print(\"Num sentences:\", len(ko_grammar_sentences))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Num sentences: 5734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scF3dYlQWv62"
      },
      "source": [
        "f = open(\"ko_sentence_set.txt\", \"a\")\r\n",
        "for t in ko_grammar_sentences:\r\n",
        "    f.write(t+'\\n')\r\n",
        "f.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doo-8nFPThrQ"
      },
      "source": [
        "# false 문장을 만들기 위해 shffle 함수 준비\r\n",
        "import random\r\n",
        "\r\n",
        "def shuffling(txt):\r\n",
        "    txt_list = txt.split(' ')\r\n",
        "    random.shuffle(txt_list)\r\n",
        "    return ' '.join(txt_list)\r\n",
        "\r\n",
        "# true 문장, false 문장의 생성\r\n",
        "ko_grammar_dataset = []\r\n",
        "for txt in ko_grammar_sentences:\r\n",
        "    ko_grammar_dataset.append([txt,1])\r\n",
        "    ko_grammar_dataset.append([shuffling(txt),0])\r\n",
        "    \r\n",
        "# dataset을 전체적으로 다시 썩는다.\r\n",
        "random.shuffle(ko_grammar_dataset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdj8wrm8eHyC"
      },
      "source": [
        "형태소 분리하여 모든 문장을 형태소 Code로 변환 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OY8VTXraeHyF"
      },
      "source": [
        "from konlpy.tag import Twitter\n",
        "twitter = Twitter()\n",
        "\n",
        "# 형태소 Code table의 구성\n",
        "\n",
        "_MAX_MORP_LENGTH = 128\n",
        "_PADDING_CODE = 0  # padding code\n",
        "_MISMATCH_CODE = 1 # mismatch word code               ex) @@@\n",
        "_MISMATCH_WORD = '@@@' # 이거 아래에서 쓴다.\n",
        "\n",
        "morpheme_table = {}\n",
        "morp_code = _MISMATCH_CODE+1\n",
        "morpheme_table['Pad'] = _PADDING_CODE \n",
        "morpheme_table['Mst'] = _MISMATCH_CODE \n",
        "for sentence in ko_grammar_sentences[:2000]:\n",
        "    morphemes = twitter.pos(sentence)\n",
        "    for (word,morp) in morphemes:\n",
        "        if morp in morpheme_table:\n",
        "            pass\n",
        "        else:\n",
        "            morpheme_table[morp] = morp_code\n",
        "            morp_code += 1\n",
        "\n",
        "morpheme_table['URL']=20 # 빠진거 채워넣음..."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "asiTeu8SeHyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39626ed8-7c54-43c5-aa8d-32368f75267b"
      },
      "source": [
        "print('Korean morpheme code table')\n",
        "print('----------------------------------------------------------')\n",
        "print('  Morpheme        Code')\n",
        "print('')\n",
        "for morp in morpheme_table.keys():\n",
        "    print(f' {morp.ljust(15)}   {morpheme_table[morp]}')\n",
        "print('----------------------------------------------------------')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Korean morpheme code table\n",
            "----------------------------------------------------------\n",
            "  Morpheme        Code\n",
            "\n",
            " Pad               0\n",
            " Mst               1\n",
            " Noun              2\n",
            " Punctuation       3\n",
            " Foreign           4\n",
            " Josa              5\n",
            " Verb              6\n",
            " Modifier          7\n",
            " Adjective         8\n",
            " Suffix            9\n",
            " Adverb            10\n",
            " Number            11\n",
            " Alpha             12\n",
            " Determiner        13\n",
            " Conjunction       14\n",
            " Exclamation       15\n",
            " KoreanParticle    16\n",
            " VerbPrefix        17\n",
            " Eomi              18\n",
            " PreEomi           19\n",
            " URL               20\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RQfjoYbceHyH"
      },
      "source": [
        "# morpheme 코드 변환기 준비\n",
        "def morpheme_encode(sentence):\n",
        "    encode=[]\n",
        "    morphemes = twitter.pos(sentence)\n",
        "    for (word,morp) in morphemes:\n",
        "        encode.append(_MISMATCH_CODE if word==_MISMATCH_WORD else morpheme_table[morp])\n",
        "\n",
        "    if len(encode) <= _MAX_MORP_LENGTH:\n",
        "        encode = encode + [_PADDING_CODE for i in range(_MAX_MORP_LENGTH-len(encode))]\n",
        "    else:\n",
        "        encode = encode[:_MAX_MORP_LENGTH]       \n",
        "    return encode\n",
        "\n",
        "#true / false 문장을 morpheme 코드로 모두 변환\n",
        "ko_morpheme_x = []\n",
        "ko_morpheme_y = []\n",
        "for (txt,label) in ko_grammar_dataset:\n",
        "    ko_morpheme_x.append(morpheme_encode(txt))\n",
        "    ko_morpheme_y.append([label])\n",
        "\n",
        "ko_morpheme_x = np.asarray(ko_morpheme_x)\n",
        "ko_morpheme_y = np.asarray(ko_morpheme_y)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knw_P_zswIXC"
      },
      "source": [
        "trainset 과 testset의 분리 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5vbAwY4Znc2",
        "outputId": "83804944-c700-4756-e1aa-db454827c6fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "# 20%를 testset으로 사용.,,\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(ko_morpheme_x,ko_morpheme_y,test_size=0.2)\r\n",
        "\r\n",
        "print(f'Shape of X_train;{X_train.shape}')\r\n",
        "print(f'Shape of X_test ;{X_test.shape}')\r\n",
        "print(f'Shape of y_train;{y_train.shape}')\r\n",
        "print(f'Shape of y_test ;{y_test.shape}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train;(9174, 128)\n",
            "Shape of X_test ;(2294, 128)\n",
            "Shape of y_train;(9174, 1)\n",
            "Shape of y_test ;(2294, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es6toINDwSQa"
      },
      "source": [
        "Model을 생성하고 학습 시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxG8Wtf1cShr",
        "outputId": "a901959e-43c5-4e8f-b077-ef2a5d1f749a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# model build\r\n",
        "\r\n",
        "morpheme_model = Sequential()\r\n",
        "morpheme_model.add(Dense(500, input_dim=128, activation= \"relu\"))\r\n",
        "morpheme_model.add(Dense(100, activation= \"relu\"))\r\n",
        "morpheme_model.add(Dense(50, activation= \"relu\"))\r\n",
        "morpheme_model.add(Dense(1))\r\n",
        "morpheme_model.summary() #Print model Summary\r\n",
        "\r\n",
        "morpheme_model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\r\n",
        "morpheme_model.fit(X_train, y_train, epochs=100)\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               64500     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               50100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 119,701\n",
            "Trainable params: 119,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "287/287 [==============================] - 2s 3ms/step - loss: 0.3776 - mean_squared_error: 0.3776\n",
            "Epoch 2/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2546 - mean_squared_error: 0.2546\n",
            "Epoch 3/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2457 - mean_squared_error: 0.2457\n",
            "Epoch 4/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2396 - mean_squared_error: 0.2396\n",
            "Epoch 5/100\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.2304 - mean_squared_error: 0.2304\n",
            "Epoch 6/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2213 - mean_squared_error: 0.2213\n",
            "Epoch 7/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2160 - mean_squared_error: 0.2160\n",
            "Epoch 8/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.2049 - mean_squared_error: 0.2049\n",
            "Epoch 9/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1997 - mean_squared_error: 0.1997\n",
            "Epoch 10/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1892 - mean_squared_error: 0.1892\n",
            "Epoch 11/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1819 - mean_squared_error: 0.1819\n",
            "Epoch 12/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1682 - mean_squared_error: 0.1682\n",
            "Epoch 13/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1591 - mean_squared_error: 0.1591\n",
            "Epoch 14/100\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.1510 - mean_squared_error: 0.1510\n",
            "Epoch 15/100\n",
            "287/287 [==============================] - 1s 2ms/step - loss: 0.1408 - mean_squared_error: 0.1408\n",
            "Epoch 16/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1325 - mean_squared_error: 0.1325\n",
            "Epoch 17/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1195 - mean_squared_error: 0.1195\n",
            "Epoch 18/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1125 - mean_squared_error: 0.1125\n",
            "Epoch 19/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1060 - mean_squared_error: 0.1060\n",
            "Epoch 20/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.1020 - mean_squared_error: 0.1020\n",
            "Epoch 21/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0937 - mean_squared_error: 0.0937\n",
            "Epoch 22/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0865 - mean_squared_error: 0.0865\n",
            "Epoch 23/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0784 - mean_squared_error: 0.0784\n",
            "Epoch 24/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0747 - mean_squared_error: 0.0747\n",
            "Epoch 25/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0726 - mean_squared_error: 0.0726\n",
            "Epoch 26/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0690 - mean_squared_error: 0.0690\n",
            "Epoch 27/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0653 - mean_squared_error: 0.0653\n",
            "Epoch 28/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0620 - mean_squared_error: 0.0620\n",
            "Epoch 29/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0605 - mean_squared_error: 0.0605\n",
            "Epoch 30/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0598 - mean_squared_error: 0.0598\n",
            "Epoch 31/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0536 - mean_squared_error: 0.0536\n",
            "Epoch 32/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
            "Epoch 33/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0509 - mean_squared_error: 0.0509\n",
            "Epoch 34/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0468 - mean_squared_error: 0.0468\n",
            "Epoch 35/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0476 - mean_squared_error: 0.0476\n",
            "Epoch 36/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0464 - mean_squared_error: 0.0464\n",
            "Epoch 37/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0414 - mean_squared_error: 0.0414\n",
            "Epoch 38/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0459 - mean_squared_error: 0.0459\n",
            "Epoch 39/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0410 - mean_squared_error: 0.0410\n",
            "Epoch 40/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0404 - mean_squared_error: 0.0404\n",
            "Epoch 41/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0399 - mean_squared_error: 0.0399\n",
            "Epoch 42/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0432 - mean_squared_error: 0.0432\n",
            "Epoch 43/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0469 - mean_squared_error: 0.0469\n",
            "Epoch 44/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0365 - mean_squared_error: 0.0365\n",
            "Epoch 45/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0342 - mean_squared_error: 0.0342\n",
            "Epoch 46/100\n",
            "287/287 [==============================] - 1s 4ms/step - loss: 0.0309 - mean_squared_error: 0.0309\n",
            "Epoch 47/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0358 - mean_squared_error: 0.0358\n",
            "Epoch 48/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0413 - mean_squared_error: 0.0413\n",
            "Epoch 49/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0454 - mean_squared_error: 0.0454\n",
            "Epoch 50/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0344 - mean_squared_error: 0.0344\n",
            "Epoch 51/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0315 - mean_squared_error: 0.0315\n",
            "Epoch 52/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0300 - mean_squared_error: 0.0300\n",
            "Epoch 53/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0288 - mean_squared_error: 0.0288\n",
            "Epoch 54/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0357 - mean_squared_error: 0.0357\n",
            "Epoch 55/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0346 - mean_squared_error: 0.0346\n",
            "Epoch 56/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0304 - mean_squared_error: 0.0304\n",
            "Epoch 57/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
            "Epoch 58/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0331 - mean_squared_error: 0.0331\n",
            "Epoch 59/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0364 - mean_squared_error: 0.0364\n",
            "Epoch 60/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0303 - mean_squared_error: 0.0303\n",
            "Epoch 61/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0296 - mean_squared_error: 0.0296\n",
            "Epoch 62/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0266 - mean_squared_error: 0.0266\n",
            "Epoch 63/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
            "Epoch 64/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0363 - mean_squared_error: 0.0363\n",
            "Epoch 65/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
            "Epoch 66/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0284 - mean_squared_error: 0.0284\n",
            "Epoch 67/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0293 - mean_squared_error: 0.0293\n",
            "Epoch 68/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
            "Epoch 69/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0264 - mean_squared_error: 0.0264\n",
            "Epoch 70/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0299 - mean_squared_error: 0.0299\n",
            "Epoch 71/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0236 - mean_squared_error: 0.0236\n",
            "Epoch 72/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0229 - mean_squared_error: 0.0229\n",
            "Epoch 73/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0240 - mean_squared_error: 0.0240\n",
            "Epoch 74/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0238 - mean_squared_error: 0.0238\n",
            "Epoch 75/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0322 - mean_squared_error: 0.0322\n",
            "Epoch 76/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0350 - mean_squared_error: 0.0350\n",
            "Epoch 77/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
            "Epoch 78/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0267 - mean_squared_error: 0.0267\n",
            "Epoch 79/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0230 - mean_squared_error: 0.0230\n",
            "Epoch 80/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0264 - mean_squared_error: 0.0264\n",
            "Epoch 81/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
            "Epoch 82/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0261 - mean_squared_error: 0.0261\n",
            "Epoch 83/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0298 - mean_squared_error: 0.0298\n",
            "Epoch 84/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0234 - mean_squared_error: 0.0234\n",
            "Epoch 85/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 86/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 87/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0220 - mean_squared_error: 0.0220\n",
            "Epoch 88/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
            "Epoch 89/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0287 - mean_squared_error: 0.0287\n",
            "Epoch 90/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0305 - mean_squared_error: 0.0305\n",
            "Epoch 91/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
            "Epoch 92/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0214 - mean_squared_error: 0.0214\n",
            "Epoch 93/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0201 - mean_squared_error: 0.0201\n",
            "Epoch 94/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0198 - mean_squared_error: 0.0198\n",
            "Epoch 95/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0203 - mean_squared_error: 0.0203\n",
            "Epoch 96/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0192 - mean_squared_error: 0.0192\n",
            "Epoch 97/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
            "Epoch 98/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0383 - mean_squared_error: 0.0383\n",
            "Epoch 99/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0277 - mean_squared_error: 0.0277\n",
            "Epoch 100/100\n",
            "287/287 [==============================] - 1s 3ms/step - loss: 0.0226 - mean_squared_error: 0.0226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3043c17240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvrVAccWpwAm",
        "outputId": "56e1d32e-f546-4498-ae7b-cf5463703fef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 학습결과 확인\r\n",
        "\r\n",
        "results = morpheme_model.evaluate(X_test, y_test)\r\n",
        "print(results)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72/72 [==============================] - 0s 1ms/step - loss: 0.3104 - mean_squared_error: 0.3104\n",
            "[0.3103533387184143, 0.3103533387184143]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5i2wtQvsWyY",
        "outputId": "db922997-0909-4b7b-d648-1d064fde586d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 학습 결과의 확인\r\n",
        "predicts = morpheme_model.predict(X_test)\r\n",
        "predicts = np.asarray(predicts)\r\n",
        "predicts = [ 1 if x>0.5 else 0 for [x] in predicts]\r\n",
        "y = np.asarray(y_test)\r\n",
        "y = y.reshape(y.shape[0],)\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y, predicts))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.61      0.63      1175\n",
            "           1       0.62      0.65      0.63      1119\n",
            "\n",
            "    accuracy                           0.63      2294\n",
            "   macro avg       0.63      0.63      0.63      2294\n",
            "weighted avg       0.63      0.63      0.63      2294\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdnf-b-ywwup"
      },
      "source": [
        "# 모델의 저장\r\n",
        "\r\n",
        "morpheme_model.save('morpheme_model.h5')\r\n",
        "morpheme_model.save_weights('morpheme_model.weights')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bkJ7Abs2XG3"
      },
      "source": [
        "def morpheme_discriminator(queries):\r\n",
        "    # queries : 복수의 문장의 2차원 배열 (None,1)\r\n",
        "    # return : 결과 score 배열 (None,)\r\n",
        "    x_codes = []\r\n",
        "    for query in queries:\r\n",
        "        x_codes.append(morpheme_encode(query))\r\n",
        "    scores = morpheme_model.predict(x_codes)\r\n",
        "    return scores"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgjWTMGt3SC6",
        "outputId": "052cf26e-b08e-45a3-8bbe-ef3959003e66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ko_grammar_sentences[100:102]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['바로 옆에 동화고등학교가 있다.', '건물은 사랑관 소망관 믿음관 송학관 여호수아홀이 있다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU7aOemq3WqY",
        "outputId": "ac16f129-f7d2-4261-fff1-51cafaf4bc0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "morpheme_discriminator(ko_grammar_sentences[100:102])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.82350856],\n",
              "       [1.0028942 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZF3lwa70lB0"
      },
      "source": [
        "## 문서 유사도 Discriminator 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKNnwvwx0kLN",
        "outputId": "0def28d6-b1f9-4de9-b40d-86c777867909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\r\n",
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "if DO_ALL:\r\n",
        "    # embedder download...\r\n",
        "    embedder = SentenceTransformer('xlm-r-large-en-ko-nli-ststb')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.80G/1.80G [01:12<00:00, 24.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiICVLIm1SZv"
      },
      "source": [
        "\r\n",
        "# 생성된 문장의 원문 유사도를 측정하기 위한 함수\r\n",
        "\r\n",
        "import scipy\r\n",
        "#print(doc_emb)\r\n",
        "def similarity_discriminator(queries,org_embedding):\r\n",
        "    # queries : 복수의 문장의 2차원 배열 (None,1)\r\n",
        "    # org_embedding : 비교 대상의 원문 embedding 1차원 배열 (1,)\r\n",
        "    # return : 결과 score 배열 (None,)\r\n",
        "    total_score = 0\r\n",
        "    query_embeddings = embedder.encode(queries,show_progress_bar=False)\r\n",
        "    for query, query_embedding in zip(queries, query_embeddings):\r\n",
        "        distances = scipy.spatial.distance.cdist([query_embedding], [org_embedding], \"cosine\")[0]\r\n",
        "        results = zip(range(len(distances)), distances)\r\n",
        "        for idx, distance in results:\r\n",
        "            total_score += 1-distance\r\n",
        "    return total_score"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrAYyyNP4HXf"
      },
      "source": [
        "# 원문의 embedding...\r\n",
        "\r\n",
        "org_text_emb = embedder.encode([org_text],show_progress_bar=False)[0]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXrhGn_W4VZF",
        "outputId": "1a5fad92-f090-4b97-8921-99a3246c766e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "org_text_emb"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.15200941,  0.92120737, -0.17669249, ..., -0.7280674 ,\n",
              "        0.74224526, -0.4155289 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gypz5XEH4cUv"
      },
      "source": [
        "## 원문 base의 generator 준비 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p66D6hso4t3N"
      },
      "source": [
        "org_term_set = org_text.split(' ')\r\n",
        "\r\n",
        "_MAX_GEN_TOKEN = 40\r\n",
        "_NOISE_DIM = len(org_term_set)\r\n",
        "\r\n",
        "word_table = {}\r\n",
        "\r\n",
        "for index, word in zip(range(len(org_term_set)),org_term_set):\r\n",
        "    word_table[index] = word"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv5g266R42Y6",
        "outputId": "9b0d9018-0cf3-4fef-ea3d-27e36b9a472f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Token table of origin text')\r\n",
        "print('---------------------------------------------')\r\n",
        "print(' Code         Token      ')\r\n",
        "print('')\r\n",
        "for k in word_table.keys():\r\n",
        "  print( f'  {str(k).ljust(8)}    {word_table[k]}')\r\n",
        "print('---------------------------------------------')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token table of origin text\n",
            "---------------------------------------------\n",
            " Code         Token      \n",
            "\n",
            "  0           옛날\n",
            "  1           어느\n",
            "  2           집에\n",
            "  3           귀여운\n",
            "  4           여자\n",
            "  5           아기가\n",
            "  6           태어났어요.\n",
            "  7           아기는\n",
            "  8           무럭무럭\n",
            "  9           자라서\n",
            "  10          예쁘고\n",
            "  11          마음씨\n",
            "  12          고운\n",
            "  13          소녀가\n",
            "  14          되었어요.\n",
            "  15          그러던\n",
            "  16          어느날\n",
            "  17          소녀의\n",
            "  18          어머니가\n",
            "  19          병이들어\n",
            "  20          그만\n",
            "  21          세상을\n",
            "  22          떠나고\n",
            "  23          말았어요.\n",
            "  24          소녀의\n",
            "  25          아버지는\n",
            "  26          홀로\n",
            "  27          남은\n",
            "  28          소녀가\n",
            "  29          걱정되었어요.\n",
            "  30          그래서\n",
            "  31          얼마\n",
            "  32          후\n",
            "  33          새어머니를\n",
            "  34          맞이했어요.\n",
            "  35          새어머니는\n",
            "  36          소녀보다\n",
            "  37          나이가\n",
            "  38          위인\n",
            "  39          두\n",
            "  40          딸을\n",
            "  41          데리고\n",
            "  42          왔어요.\n",
            "  43          그러나\n",
            "  44          새어머니와\n",
            "  45          언니들은\n",
            "  46          성질이\n",
            "  47          고약한\n",
            "  48          심술쟁이들이었어요.\n",
            "  49          새어머니는\n",
            "  50          소녀가\n",
            "  51          자기\n",
            "  52          딸들보다\n",
            "  53          예쁘고\n",
            "  54          착한\n",
            "  55          게\n",
            "  56          못마땅했어요.\n",
            "  57          그런데\n",
            "  58          이번에는\n",
            "  59          아버지마저\n",
            "  60          돌아가셨어요.\n",
            "  61          소녀는\n",
            "  62          하녀처럼\n",
            "  63          하루\n",
            "  64          종일\n",
            "  65          쓸고\n",
            "  66          닦고\n",
            "  67          집안일을\n",
            "  68          도맡아\n",
            "  69          했어요.\n",
            "  70          해도\n",
            "  71          해도\n",
            "  72          끝이\n",
            "  73          없는\n",
            "  74          집안일이\n",
            "  75          힘들어\n",
            "  76          지칠때면난롯가에\n",
            "  77          앉아서\n",
            "  78          잠시\n",
            "  79          쉬곤\n",
            "  80          했지요.\n",
            "  81          엄마\n",
            "  82          저애를\n",
            "  83          신데렐라라고\n",
            "  84          불러야겠어요.\n",
            "  85          온통\n",
            "  86          재투성이잖아요.\n",
            "  87          호호호!\n",
            "  88          두\n",
            "  89          언니는\n",
            "  90          소녀를\n",
            "  91          놀려\n",
            "  92          댔어요.\n",
            "  93          어느\n",
            "  94          날\n",
            "  95          왕궁에서\n",
            "  96          무도회가\n",
            "  97          열렸어요.\n",
            "  98          신데렐라의\n",
            "  99          집에도\n",
            "  100         초대장이\n",
            "  101         왔어요.\n",
            "  102         새어머니는\n",
            "  103         언니들을\n",
            "  104         데리고\n",
            "  105         무도회장으로\n",
            "  106         떠났어요.\n",
            "  107         신데렐라도\n",
            "  108         무도회에\n",
            "  109         가고\n",
            "  110         싶었어요.\n",
            "  111         혼자\n",
            "  112         남은\n",
            "  113         신데렐라는\n",
            "  114         훌쩍훌쩍\n",
            "  115         울기\n",
            "  116         시작했어요.\n",
            "  117         신데렐라\n",
            "  118         너도\n",
            "  119         무도회에\n",
            "  120         가고\n",
            "  121         싶니?신데렐라가\n",
            "  122         고개를\n",
            "  123         들어보니\n",
            "  124         마법사\n",
            "  125         할머니가\n",
            "  126         빙그레\n",
            "  127         웃고\n",
            "  128         있었어요.\n",
            "  129         내가\n",
            "  130         너를\n",
            "  131         무도회에\n",
            "  132         보내주마\n",
            "  133         호박\n",
            "  134         한개와\n",
            "  135         생쥐\n",
            "  136         두마리\n",
            "  137         도마뱀을\n",
            "  138         구해\n",
            "  139         오렴.\n",
            "  140         마법사\n",
            "  141         할머니가\n",
            "  142         주문을\n",
            "  143         외웠어요.\n",
            "  144         그리고\n",
            "  145         지팡이로\n",
            "  146         호박을\n",
            "  147         건드리자\n",
            "  148         호박이\n",
            "  149         화려한\n",
            "  150         황금\n",
            "  151         마차로\n",
            "  152         변했어요.\n",
            "  153         이번에는\n",
            "  154         생쥐와\n",
            "  155         도마뱀을\n",
            "  156         건드렸어요.\n",
            "  157         그랬더니\n",
            "  158         생쥐는\n",
            "  159         흰말로\n",
            "  160         도마뱀은\n",
            "  161         멋진\n",
            "  162         마부로\n",
            "  163         변했답니다.\n",
            "  164         신데렐라의\n",
            "  165         옷도\n",
            "  166         구슬\n",
            "  167         장식이\n",
            "  168         반짝이는\n",
            "  169         예쁜\n",
            "  170         드레스로\n",
            "  171         바뀌웠어요.\n",
            "  172         신데렐라\n",
            "  173         발을\n",
            "  174         내밀어\n",
            "  175         보거라.\n",
            "  176         할머니는\n",
            "  177         신데렐라에게\n",
            "  178         반짝반짝\n",
            "  179         빛나는\n",
            "  180         유리\n",
            "  181         구두를\n",
            "  182         신겨\n",
            "  183         주었어요.\n",
            "  184         신데렐라\n",
            "  185         밤\n",
            "  186         열두시가\n",
            "  187         되면\n",
            "  188         모든게\n",
            "  189         처음대로\n",
            "  190         돌아간단다.\n",
            "  191         황금\n",
            "  192         마차는\n",
            "  193         호박으로\n",
            "  194         흰말은\n",
            "  195         생쥐로\n",
            "  196         마부는\n",
            "  197         도마뱀으로\n",
            "  198         변하게\n",
            "  199         돼.\n",
            "  200         그러니까\n",
            "  201         반드시\n",
            "  202         밤\n",
            "  203         열두\n",
            "  204         시가\n",
            "  205         되기\n",
            "  206         전에\n",
            "  207         돌아와야\n",
            "  208         해.\n",
            "  209         알겠지?왕자님도\n",
            "  210         아름다운\n",
            "  211         신데렐라에게\n",
            "  212         마음을\n",
            "  213         빼았겼어요.\n",
            "  214         왕자님은\n",
            "  215         무도회장에\n",
            "  216         모인\n",
            "  217         다른\n",
            "  218         아가씨들은\n",
            "  219         쳐다보지도\n",
            "  220         않고신데렐라하고만\n",
            "  221         춤을\n",
            "  222         추었어요.\n",
            "  223         신데렐라는\n",
            "  224         왕자님과\n",
            "  225         춤을\n",
            "  226         추느라\n",
            "  227         시간\n",
            "  228         가는\n",
            "  229         줄도\n",
            "  230         몰랐어요.\n",
            "  231         땡\n",
            "  232         땡\n",
            "  233         땡\n",
            "  234         벽시계가\n",
            "  235         열두\n",
            "  236         시를\n",
            "  237         알리는\n",
            "  238         소리에\n",
            "  239         신데렐라는\n",
            "  240         화들짝\n",
            "  241         놀랐어요.\n",
            "  242         신데렐라가\n",
            "  243         허둥지둥\n",
            "  244         왕궁을\n",
            "  245         빠져나가는데유리\n",
            "  246         구두\n",
            "  247         한\n",
            "  248         짝이\n",
            "  249         벗겨졌어요.\n",
            "  250         하지만\n",
            "  251         구두를\n",
            "  252         주울\n",
            "  253         틈이\n",
            "  254         없었어요.\n",
            "  255         신데렐라를\n",
            "  256         뛰쫓아오던\n",
            "  257         왕자님은\n",
            "  258         층계에서\n",
            "  259         유리\n",
            "  260         구두\n",
            "  261         한\n",
            "  262         짝을\n",
            "  263         주웠어요.\n",
            "  264         왕자님은\n",
            "  265         유리\n",
            "  266         구두를\n",
            "  267         가지고\n",
            "  268         임금님께\n",
            "  269         가서\n",
            "  270         말했어요.\n",
            "  271         이\n",
            "  272         유리\n",
            "  273         구두의\n",
            "  274         주인과\n",
            "  275         결혼하겠어요.\n",
            "  276         그래서\n",
            "  277         신하들은\n",
            "  278         유리\n",
            "  279         구두의\n",
            "  280         주인을\n",
            "  281         찾아\n",
            "  282         온\n",
            "  283         나라를\n",
            "  284         돌아다녔어요.\n",
            "  285         언니들은\n",
            "  286         발을\n",
            "  287         오므려도\n",
            "  288         보고\n",
            "  289         구두를\n",
            "  290         늘려도\n",
            "  291         보았지만\n",
            "  292         한눈에\n",
            "  293         보기에도\n",
            "  294         유리\n",
            "  295         구두는\n",
            "  296         너무\n",
            "  297         작았어요.\n",
            "  298         그때\n",
            "  299         신데렐라가\n",
            "  300         조용히\n",
            "  301         다가와\n",
            "  302         말했어요.\n",
            "  303         저도\n",
            "  304         한번\n",
            "  305         신어\n",
            "  306         볼\n",
            "  307         수\n",
            "  308         있나요?신데렐라는\n",
            "  309         신하게\n",
            "  310         건넨\n",
            "  311         유리\n",
            "  312         구두를\n",
            "  313         신었어요유리\n",
            "  314         구두는\n",
            "  315         신데렐라의\n",
            "  316         발에\n",
            "  317         꼭\n",
            "  318         맞았어요.\n",
            "  319         신하들은\n",
            "  320         신데렐라를\n",
            "  321         왕궁으로\n",
            "  322         데리고\n",
            "  323         갔어요.\n",
            "  324         그\n",
            "  325         뒤\n",
            "  326         신데렐라는\n",
            "  327         왕자님과\n",
            "  328         결혼하여\n",
            "  329         오래오래\n",
            "  330         행복하게\n",
            "  331         살았대요.\n",
            "  332         \n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lejMbMq654is"
      },
      "source": [
        "_MAX_GEN_TOKEN = 40\r\n",
        "\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E04x981k7Gzh",
        "outputId": "eb3bd81c-da82-469f-cc12-98fd6aa15233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "noise = np.random.rand(_NOISE_DIM,)\r\n",
        "def text_gen(noise):\r\n",
        "    text = \"\"\r\n",
        "    sorted_noise = np.sort(noise)[::-1]\r\n",
        "    order = np.where(noise > sorted_noise[_MAX_GEN_TOKEN])[0][:_MAX_GEN_TOKEN]\r\n",
        "    assert len(order) == _MAX_GEN_TOKEN\r\n",
        "    for k in order:\r\n",
        "        text += word_table[k]+' '    \r\n",
        "    return text,order \r\n",
        "\r\n",
        "text,order = text_gen(noise)\r\n",
        "\r\n",
        "text"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'자라서 소녀가 게 못마땅했어요. 잠시 무도회가 신데렐라의 집에도 데리고 너도 싶니?신데렐라가 들어보니 마법사 빙그레 웃고 내가 생쥐 오렴. 신데렐라의 구슬 신데렐라 신겨 되면 황금 마부는 열두 해. 다른 벽시계가 놀랐어요. 하지만 가지고 주인과 주인을 발을 구두는 신하게 신하들은 왕궁으로 뒤 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sweJG7zR_MAb"
      },
      "source": [
        "'''\r\n",
        "for i in range(10):\r\n",
        "    noise = tf.random.normal([1,_NOISE_DIM])\r\n",
        "    texts,embeddings,compratios,morpcodes = generator(noise, training=True)\r\n",
        "    p_score = 0\r\n",
        "    for txt in texts:\r\n",
        "        embedding = embedder.encode([txt.numpy().decode('utf-8')],show_progress_bar=False)\r\n",
        "        distances = scipy.spatial.distance.cdist(embedding, [org_text_emb], \"cosine\")[0]\r\n",
        "        score = 1-distances[0]\r\n",
        "        reward = p_score - score\r\n",
        "        if p_score == 0:\r\n",
        "            reward = -reward\r\n",
        "        print(f'score:{score} reward:{reward}') # 1-distance\r\n",
        "        p_score = score\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}