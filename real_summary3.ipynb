{"cells":[{"metadata":{"id":"vz7O2Dt-VoI0"},"cell_type":"markdown","source":"# **Beginners Guide to Text Generation using LSTMs**\n\nhttps://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n\n참조 : https://github.com/williamSYSU/TextGAN-PyTorch\n"},{"metadata":{"trusted":true,"id":"n2F_YwA-s-zL","outputId":"c2583825-4233-452b-e654-bb5a346da9d1"},"cell_type":"code","source":"!pip install sentence-transformers==0.3.0\n!pip install transformers==3.0.2","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting sentence-transformers==0.3.0\n  Downloading sentence-transformers-0.3.0.tar.gz (61 kB)\n\u001b[K     |████████████████████████████████| 61 kB 266 kB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: transformers>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (3.5.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nRequirement already satisfied: torch>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.7.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (0.23.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.4.1)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (2.1.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.4.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (0.14.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (3.7.4.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.1.91)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.0.43)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2020.4.4)\nRequirement already satisfied: tokenizers==0.9.3 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.9.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2.23.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (20.1)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.0) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2020.4.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.0) (7.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (0.14.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.0-py3-none-any.whl size=86752 sha256=f25574e1d03f6dd04ca25c452ebb3a4ae9c189c98de88fd42992ce3c3b40750e\n  Stored in directory: /root/.cache/pip/wheels/3e/15/94/49bc84289d2c77b5059bca513f840c6006d4e2cc7f10275d49\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-0.3.0\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting transformers==3.0.2\n  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n\u001b[K     |████████████████████████████████| 769 kB 884 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.45.0)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.91)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (20.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.43)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (1.18.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2.23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.0.10)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (1.14.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (2.4.7)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2020.12.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (1.14.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.45.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (7.1.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (0.14.1)\nCollecting tokenizers==0.8.1.rc1\n","name":"stdout"},{"output_type":"stream","text":"  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |████████████████████████████████| 3.0 MB 2.2 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.9.3\n    Uninstalling tokenizers-0.9.3:\n      Successfully uninstalled tokenizers-0.9.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 3.5.1\n    Uninstalling transformers-3.5.1:\n      Successfully uninstalled transformers-3.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 1.2.2 requires transformers<3.6,>=3.4, but you have transformers 3.0.2 which is incompatible.\u001b[0m\nSuccessfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"id":"P1m66KMMVs-P","trusted":true},"cell_type":"code","source":"# keras module for building LSTM \nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom tensorflow.python.framework import tensor_shape\nimport keras.utils as ku \n\n# set seeds for reproducability\nfrom tensorflow.random import set_seed\nfrom numpy.random import seed\nset_seed(2)\nseed(1)\n\nimport pandas as pd\nimport numpy as np\nimport string, os \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":2,"outputs":[]},{"metadata":{"id":"8cLgLP9Ws-zX"},"cell_type":"markdown","source":"# 여기서부터 본론..."},{"metadata":{"trusted":true,"id":"BUH5iWxCs-zX"},"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom transformers import BertTokenizer\n# embedder download...\nembedder = SentenceTransformer('xlm-r-large-en-ko-nli-ststb')","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n100%|██████████| 1.80G/1.80G [01:37<00:00, 18.4MB/s]\n","name":"stderr"}]},{"metadata":{"id":"9D0W9vI4FB1c","trusted":true},"cell_type":"code","source":"document = \"\"\"\n주호영 국민의힘 원내대표는 22일 고위공직자범죄수사처(공수처)법 개정과 가덕도 신공항 건설 등을 밀어붙이고 있는 문재인 정권과 더불어민주당을 향해 \"이제 끝이 보인다\"며 \"짓밟힌 풀들이 아우성 치는 국민적 저항에 직면할 것\"이라고 경고했다.\n주 원내대표는 이날 자신의 페이스북에 \"문재인 정권이 공수처법 개정을 위한 '군사작전'에 돌입하겠다고 엄포를 놓고 있다\"며 \"정의당을 끌어들이기 위해 꼼수 선거법에 묶어 '패스트트랙'이라는 불법·탈법으로 만들어낸 공수처법을 시행도 해보지 않고 고치려 하는 것\"이라고 지적했다.\n이어 주 원내대표는 \"야당 원내대표인 제게 문재인 대통령은 사람 좋아보이는 표정으로 '공수처는 야당의 동의 없이는 절대 출범할 수 없는 것'이라고 얘기했고, 야당이 유엔 안보리 상임이사국처럼 공수처장 임명에 '비토권'을 행사할 수 있는데 무얼 걱정하느냐고, 여당 사람들이 우리를 속였다\"며 \"거짓말이라는 비난을 개의치 않는 사람들\"이라고 꼬집었다.\n주 원내대표는 \"이해찬 전 민주당 대표가 얘기한 '민주당 20년 집권'의 토대가 올해 안에 완성된다\"며 \"탈원전과 동남권 신공항은 문 대통령이 대선 공약으로 내건 사업이니 여기에 불법이 있었다고 시비를 거는 것은 민주주의를 부정하는 것이라고 청와대 출신 윤건영 민주당 의원이 윽박지른다. 이제 '민주주의 없는 민주당'이 법위에 군림하는 '반민주'를 거리낌없이 획책하는 것\"이라고 언급했다.\n그러면서 주 원내대표는 \"표를 얻기 위해 나라 곳간을 다 허물어뜨렸고, 재정 운용에서 신중함은 사라졌다\"며 \"괴물 공수처가 출범하면 공무원 누구나 대통령과 권력이 지시하는 범죄행위에 거리낌 없이 가담할 것이다. 청와대와 권부 요직에 앉아 불법으로 각종 이권을 챙기는 권력자들에 대한 사건이 불거져도 공수처가 사건을 가져가 버리면 그만\"이라고 우려했다.\n주 원내대표는 \"문 대통령은 제게 '공수처는 고위 공직자들을 처벌하는 것인데 왜 야당이 반대하는지 이해할 수 없다'고 했는데, 그런 분이 청와대와 대통령 주변을 감시하는 특별감찰관은 취임 이후 지금까지 왜 임명하지 않았는가\"라며 \"공수처는 권력형 비리의 쓰레기 하치장, 종말 처리장이 될 것\"이라고 비판했다.\n문재인 정부를 향해 주 원내대표는 \"문 대통령과 그 사도들은 법치가 미치지 않는 무오류의 화신이 될 것\"이라며 \"오류를 인정하지 않는 존재가 바로 신이며 그 아래에는 자신들의 지도자를 목숨바쳐 지킴으로서 정의를 실현하겠다는 추종자들로 넘쳐 난다. 공수처는 지도자의 신성을 인정하지 않는 세력을 정죄하는 수단으로 전락할 것\"이라고 질타했다.\n주 원내대표는 \"저도 법조인이지만 대통령과 공수처장이 마음대로 검사들과 수사관들을 임명하는 이 끔찍한 사법기구가 어떤 일을 할지 두렵기만 하다\"며 \"공수처는 검찰과 경찰 위에 있는 사법기구로, 헌법과 법으로 독립성을 보장하는 검찰총장을 이렇게 핍박하는 정권이 공수처를 어떻게 운영할지 불을 보듯 뻔한 일\"이라고 예측했다.\n그러면서 주 원내대표는 \"추미애 법무장관을 앞장 세워 윤석열 검찰의 권력 비리 수사를 저지하려다가 난관에 봉착하자 무슨 수를 써서라도 공수처를 출범시키려 한다. 공수처장 자리에는 추미애보다 더 한 막무가내 내 편을 앉힐 게 분명한 것\"이라며 \"문 정권의 파렴치와 오만함을 최전선에서 온 몸으로 겪어온 저로서는 민주당이 내일부터 국회에서 보일 행태가 환히 보인다. 180석의 민주당이 또 군사작전을 개시하면 그걸 누가 막겠는가\"라고 성토했다.\n주 원내대표는 \"공수처법을 막을 힘이 우리 야당에게는 없다. 삭발하고 장외투쟁해 봐야 눈 하나 깜짝할 사람들이 아닌 것\"이라며 \"대란대치(大亂大治), 세상을 온통 혼돈 속으로 밀어넣고 그걸 권력 유지에 이용한다는 게 이 정권의 통치기술\"이라고 규탄했다.\n아울러 주 원내대표는 \"권력은 바람, 국민은 풀이다. 바람이 불면 청보리 밭의 보리가 눕는다\"며 \"권력은 풀들이 다시는 일어서지 못하도록 풀을 짓밟지만 풀들은 다시 일어난다. 시인 김수영은 '바람보다 먼저 눕지만, 바람보다 먼저 일어나는' 민초의 힘을 노래했다\"고 말했다.\n마지막으로 주 원내대표는 \"문재인 정권은 이제 곧 국회에서 광장에서 짓밟힌 풀들이 일어서서 아우성치는 모습을 지켜보게 될 것\"이라며 \"대란대치를 끝장내려는 국민적 저항에 직면할 것\"이라고 거듭 강조했다.\n\"\"\"","execution_count":4,"outputs":[]},{"metadata":{"id":"OIxs7REEQVFO","outputId":"b563dccd-6982-469a-cac6-ea0f128bf16b","trusted":true},"cell_type":"code","source":"c = embedder.encode([document])\nc","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af35823a95cf4b8a833c7864fb2013d7"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"[array([ 0.5201436 , -0.09330627,  0.4559566 , ..., -0.54848397,\n        -0.11432096, -0.06106506], dtype=float32)]"},"metadata":{}}]},{"metadata":{"id":"ocHnmjt4FRUF","trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts([document])\ntotal_words = len(tokenizer.word_index) + 1","execution_count":6,"outputs":[]},{"metadata":{"id":"c8OViY44Fk0J","trusted":true,"outputId":"89223ad9-5a1a-484a-b4d3-e2c2ea665ba5"},"cell_type":"code","source":"print(total_words)","execution_count":7,"outputs":[{"output_type":"stream","text":"395\n","name":"stdout"}]},{"metadata":{"id":"5PeHFwITF0Ux","trusted":true,"outputId":"d2b933dc-d249-41c7-c55f-cd8668ea29ee"},"cell_type":"code","source":"# max 512 token으로 만든다. 남는건 padding\n\n_MAX_TOKEN = 512\n_MAX_LENGTH = 40\n_NOISE_DIM = 100\n_MISMATCH_WORD = '양자역학'\nword_keys = []\nword_values = []\n\nfor word,index in tokenizer.word_index.items():\n    word_keys.append(index)\n    word_values.append(word)\n\ncurrent_token_len = len(word_keys)\n\nif current_token_len > _MAX_TOKEN:\n    word_keys = word_keys[:_MAX_TOKEN]\n    word_values = word_values[:_MAX_TOKEN]\nelse:\n    for i in range(current_token_len+1,_MAX_TOKEN+1):\n        word_keys.append(i)\n        word_values.append(_MISMATCH_WORD)\n\nfor k in word_keys:\n  print(k,word_values[k-1])","execution_count":8,"outputs":[{"output_type":"stream","text":"1 원내대표는\n2 주\n3 것\n4 이라고\n5 며\n6 문재인\n7 않는\n8 문\n9 이라며\n10 이제\n11 풀들이\n12 수\n13 대통령과\n14 공수처는\n15 될\n16 있는\n17 향해\n18 보인다\n19 짓밟힌\n20 국민적\n21 저항에\n22 직면할\n23 정권이\n24 위해\n25 공수처법을\n26 제게\n27 대통령은\n28 '공수처는\n29 없는\n30 야당이\n31 공수처장\n32 사람들이\n33 민주당\n34 그러면서\n35 공수처가\n36 청와대와\n37 왜\n38 그\n39 인정하지\n40 이\n41 공수처를\n42 권력\n43 게\n44 정권의\n45 민주당이\n46 국회에서\n47 그걸\n48 권력은\n49 먼저\n50 주호영\n51 국민의힘\n52 22일\n53 고위공직자범죄수사처\n54 공수처\n55 법\n56 개정과\n57 가덕도\n58 신공항\n59 건설\n60 등을\n61 밀어붙이고\n62 정권과\n63 더불어민주당을\n64 끝이\n65 아우성\n66 치는\n67 경고했다\n68 이날\n69 자신의\n70 페이스북에\n71 공수처법\n72 개정을\n73 위한\n74 '군사작전'에\n75 돌입하겠다고\n76 엄포를\n77 놓고\n78 있다\n79 정의당을\n80 끌어들이기\n81 꼼수\n82 선거법에\n83 묶어\n84 '패스트트랙'이라는\n85 불법·탈법으로\n86 만들어낸\n87 시행도\n88 해보지\n89 않고\n90 고치려\n91 하는\n92 지적했다\n93 이어\n94 야당\n95 원내대표인\n96 사람\n97 좋아보이는\n98 표정으로\n99 야당의\n100 동의\n101 없이는\n102 절대\n103 출범할\n104 것'이라고\n105 얘기했고\n106 유엔\n107 안보리\n108 상임이사국처럼\n109 임명에\n110 '비토권'을\n111 행사할\n112 있는데\n113 무얼\n114 걱정하느냐고\n115 여당\n116 우리를\n117 속였다\n118 거짓말이라는\n119 비난을\n120 개의치\n121 사람들\n122 꼬집었다\n123 이해찬\n124 전\n125 대표가\n126 얘기한\n127 '민주당\n128 20년\n129 집권'의\n130 토대가\n131 올해\n132 안에\n133 완성된다\n134 탈원전과\n135 동남권\n136 신공항은\n137 대통령이\n138 대선\n139 공약으로\n140 내건\n141 사업이니\n142 여기에\n143 불법이\n144 있었다고\n145 시비를\n146 거는\n147 것은\n148 민주주의를\n149 부정하는\n150 것이라고\n151 청와대\n152 출신\n153 윤건영\n154 의원이\n155 윽박지른다\n156 '민주주의\n157 민주당'이\n158 법위에\n159 군림하는\n160 '반민주'를\n161 거리낌없이\n162 획책하는\n163 언급했다\n164 표를\n165 얻기\n166 나라\n167 곳간을\n168 다\n169 허물어뜨렸고\n170 재정\n171 운용에서\n172 신중함은\n173 사라졌다\n174 괴물\n175 출범하면\n176 공무원\n177 누구나\n178 권력이\n179 지시하는\n180 범죄행위에\n181 거리낌\n182 없이\n183 가담할\n184 것이다\n185 권부\n186 요직에\n187 앉아\n188 불법으로\n189 각종\n190 이권을\n191 챙기는\n192 권력자들에\n193 대한\n194 사건이\n195 불거져도\n196 사건을\n197 가져가\n198 버리면\n199 그만\n200 우려했다\n201 고위\n202 공직자들을\n203 처벌하는\n204 것인데\n205 반대하는지\n206 이해할\n207 없다'고\n208 했는데\n209 그런\n210 분이\n211 대통령\n212 주변을\n213 감시하는\n214 특별감찰관은\n215 취임\n216 이후\n217 지금까지\n218 임명하지\n219 않았는가\n220 라며\n221 권력형\n222 비리의\n223 쓰레기\n224 하치장\n225 종말\n226 처리장이\n227 비판했다\n228 정부를\n229 사도들은\n230 법치가\n231 미치지\n232 무오류의\n233 화신이\n234 오류를\n235 존재가\n236 바로\n237 신이며\n238 아래에는\n239 자신들의\n240 지도자를\n241 목숨바쳐\n242 지킴으로서\n243 정의를\n244 실현하겠다는\n245 추종자들로\n246 넘쳐\n247 난다\n248 지도자의\n249 신성을\n250 세력을\n251 정죄하는\n252 수단으로\n253 전락할\n254 질타했다\n255 저도\n256 법조인이지만\n257 공수처장이\n258 마음대로\n259 검사들과\n260 수사관들을\n261 임명하는\n262 끔찍한\n263 사법기구가\n264 어떤\n265 일을\n266 할지\n267 두렵기만\n268 하다\n269 검찰과\n270 경찰\n271 위에\n272 사법기구로\n273 헌법과\n274 법으로\n275 독립성을\n276 보장하는\n277 검찰총장을\n278 이렇게\n279 핍박하는\n280 어떻게\n281 운영할지\n282 불을\n283 보듯\n284 뻔한\n285 일\n286 예측했다\n287 추미애\n288 법무장관을\n289 앞장\n290 세워\n291 윤석열\n292 검찰의\n293 비리\n294 수사를\n295 저지하려다가\n296 난관에\n297 봉착하자\n298 무슨\n299 수를\n300 써서라도\n301 출범시키려\n302 한다\n303 자리에는\n304 추미애보다\n305 더\n306 한\n307 막무가내\n308 내\n309 편을\n310 앉힐\n311 분명한\n312 파렴치와\n313 오만함을\n314 최전선에서\n315 온\n316 몸으로\n317 겪어온\n318 저로서는\n319 내일부터\n320 보일\n321 행태가\n322 환히\n323 180석의\n324 또\n325 군사작전을\n326 개시하면\n327 누가\n328 막겠는가\n329 라고\n330 성토했다\n331 막을\n332 힘이\n333 우리\n334 야당에게는\n335 없다\n336 삭발하고\n337 장외투쟁해\n338 봐야\n339 눈\n340 하나\n341 깜짝할\n342 아닌\n343 대란대치\n344 大亂大治\n345 세상을\n346 온통\n347 혼돈\n348 속으로\n349 밀어넣고\n350 유지에\n351 이용한다는\n352 통치기술\n353 규탄했다\n354 아울러\n355 바람\n356 국민은\n357 풀이다\n358 바람이\n359 불면\n360 청보리\n361 밭의\n362 보리가\n363 눕는다\n364 다시는\n365 일어서지\n366 못하도록\n367 풀을\n368 짓밟지만\n369 풀들은\n370 다시\n371 일어난다\n372 시인\n373 김수영은\n374 '바람보다\n375 눕지만\n376 바람보다\n377 일어나는'\n378 민초의\n379 힘을\n380 노래했다\n381 고\n382 말했다\n383 마지막으로\n384 정권은\n385 곧\n386 광장에서\n387 일어서서\n388 아우성치는\n389 모습을\n390 지켜보게\n391 대란대치를\n392 끝장내려는\n393 거듭\n394 강조했다\n395 양자역학\n396 양자역학\n397 양자역학\n398 양자역학\n399 양자역학\n400 양자역학\n401 양자역학\n402 양자역학\n403 양자역학\n404 양자역학\n405 양자역학\n406 양자역학\n407 양자역학\n408 양자역학\n409 양자역학\n410 양자역학\n411 양자역학\n412 양자역학\n413 양자역학\n414 양자역학\n415 양자역학\n416 양자역학\n417 양자역학\n418 양자역학\n419 양자역학\n420 양자역학\n421 양자역학\n422 양자역학\n423 양자역학\n424 양자역학\n425 양자역학\n426 양자역학\n427 양자역학\n428 양자역학\n429 양자역학\n430 양자역학\n431 양자역학\n432 양자역학\n433 양자역학\n434 양자역학\n435 양자역학\n436 양자역학\n437 양자역학\n438 양자역학\n439 양자역학\n440 양자역학\n441 양자역학\n442 양자역학\n443 양자역학\n444 양자역학\n445 양자역학\n446 양자역학\n447 양자역학\n448 양자역학\n449 양자역학\n450 양자역학\n451 양자역학\n452 양자역학\n453 양자역학\n454 양자역학\n455 양자역학\n456 양자역학\n457 양자역학\n458 양자역학\n459 양자역학\n460 양자역학\n461 양자역학\n462 양자역학\n463 양자역학\n464 양자역학\n465 양자역학\n466 양자역학\n467 양자역학\n468 양자역학\n469 양자역학\n470 양자역학\n471 양자역학\n472 양자역학\n473 양자역학\n474 양자역학\n475 양자역학\n476 양자역학\n477 양자역학\n478 양자역학\n479 양자역학\n480 양자역학\n481 양자역학\n482 양자역학\n483 양자역학\n484 양자역학\n485 양자역학\n486 양자역학\n487 양자역학\n488 양자역학\n489 양자역학\n490 양자역학\n491 양자역학\n492 양자역학\n493 양자역학\n494 양자역학\n495 양자역학\n496 양자역학\n497 양자역학\n498 양자역학\n499 양자역학\n500 양자역학\n501 양자역학\n502 양자역학\n503 양자역학\n504 양자역학\n505 양자역학\n506 양자역학\n507 양자역학\n508 양자역학\n509 양자역학\n510 양자역학\n511 양자역학\n512 양자역학\n","name":"stdout"}]},{"metadata":{"id":"F740wH5sF9lG","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input,\n                                     Dense, \n                                     BatchNormalization, \n                                     LeakyReLU,\n                                     Softmax,\n                                     Reshape, \n                                     Conv2DTranspose,\n                                     Conv2D,\n                                     Dropout,\n                                     Flatten,\n                                     Lambda)\nimport matplotlib.pyplot as plt","execution_count":9,"outputs":[]},{"metadata":{"id":"JILw73lq6Gc0","trusted":true},"cell_type":"code","source":"\nkeys=tf.constant(word_keys,tf.int32)\nvalues=tf.constant(word_values, tf.string)\n# build a lookup table\nword_table = tf.lookup.StaticHashTable(\n    initializer=tf.lookup.KeyValueTensorInitializer(keys,values),\n    default_value=tf.constant(' '),\n    name=\"class_weight\"\n)\n\n\n# build a lookup table\n#word_table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(tf.constant(word_keys), tf.constant(word_values)),default_value=-1)\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"id":"OKH9DAGks-zb"},"cell_type":"code","source":"import sys\n\ndef to_text(w):\n    #r_value = None\n    #print(w)\n    texts = []\n    try:\n        #codes = []\n        \n        #embeddings = []\n\n        for z in w:\n            text = \"\"\n            #code = []\n            for v in z:\n                try:\n                    #print(v)\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    #if type=='code':\n                    #    code.append(key.numpy())\n                    #else:\n                    #    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    #code.append(0)\n                    text += '[   ] '                  \n            #print(generated_text)\n            #if type == 'code':\n            #    codes.append(code)\n            #else:\n            #    texts.append(text)\n            texts.append(text)\n\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n        #codes = np.random([w.shape[0],30])\n        #texts = '----------------------------------------------------'\n    '''\n    if type == 'code':\n        r_value = tf.constant(codes,dtype=tf.int32)\n    elif type == 'embedding':\n        r_value = tf.constant(embedder.encode(texts),dtype=tf.float32)\n    else:\n        r_value = tf.constant(texts,dtype=tf.string)\n    '''\n    return tf.constant(texts,dtype=tf.string)\n\n","execution_count":11,"outputs":[]},{"metadata":{"id":"xBrB8gNSggTC","outputId":"87075db3-d003-42a4-8c4b-3555bc56210a","trusted":true},"cell_type":"code","source":"w = tf.random.normal([2,_MAX_LENGTH,_MAX_TOKEN])\ne = to_text(w)\nprint(e)\nfor t in e:\n  print(t.numpy().decode('utf-8'))","execution_count":12,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[b\"\\xea\\xb2\\x80\\xec\\xb0\\xb0\\xea\\xb3\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x95\\x9e\\xec\\x9e\\xa5 \\xea\\xb7\\xb8\\xeb\\xa7\\x8c \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x82\\xac\\xeb\\x8f\\x84\\xeb\\x93\\xa4\\xec\\x9d\\x80 22\\xec\\x9d\\xbc \\xeb\\xb3\\xb4\\xec\\x9d\\xb8\\xeb\\x8b\\xa4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xea\\xb3\\xa0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xa3\\xbc\\xeb\\xb3\\x80\\xec\\x9d\\x84 \\xeb\\x8f\\x85\\xeb\\xa6\\xbd\\xec\\x84\\xb1\\xec\\x9d\\x84 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x95\\xbc\\xeb\\x8b\\xb9\\xec\\x9d\\x98 \\xec\\x9e\\xac\\xec\\xa0\\x95 \\xea\\xb9\\x9c\\xec\\xa7\\x9d\\xed\\x95\\xa0 \\xec\\xb6\\x9c\\xeb\\xb2\\x94\\xed\\x95\\x98\\xeb\\xa9\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xb2\\xad\\xec\\x99\\x80\\xeb\\x8c\\x80\\xec\\x99\\x80 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x88\\x98\\xeb\\x8b\\xa8\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xeb\\xb6\\x88\\xeb\\xb2\\x95\\xec\\x9d\\xb4 '\\xeb\\xaf\\xbc\\xec\\xa3\\xbc\\xeb\\x8b\\xb9 \\xec\\xb6\\x94\\xeb\\xaf\\xb8\\xec\\x95\\xa0\\xeb\\xb3\\xb4\\xeb\\x8b\\xa4 \\xec\\x9e\\xa5\\xec\\x99\\xb8\\xed\\x88\\xac\\xec\\x9f\\x81\\xed\\x95\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x97\\xac\\xeb\\x8b\\xb9 \\xea\\xb0\\x9c\\xec\\x8b\\x9c\\xed\\x95\\x98\\xeb\\xa9\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xeb\\x8c\\x80\\xec\\x84\\xa0 \\xec\\x96\\x98\\xea\\xb8\\xb0\\xed\\x95\\x9c \\xec\\x83\\x81\\xec\\x9e\\x84\\xec\\x9d\\xb4\\xec\\x82\\xac\\xea\\xb5\\xad\\xec\\xb2\\x98\\xeb\\x9f\\xbc \\xeb\\xb0\\x80\\xec\\x96\\xb4\\xeb\\x84\\xa3\\xea\\xb3\\xa0 \\xea\\xb1\\xb0\\xeb\\x8a\\x94 \\xea\\xb0\\x90\\xec\\x8b\\x9c\\xed\\x95\\x98\\xeb\\x8a\\x94 \"\n b\"\\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x9e\\x90\\xec\\x8b\\xa0\\xec\\x9d\\x98 \\xed\\x91\\x9c\\xec\\xa0\\x95\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x98\\xa4\\xeb\\xa7\\x8c\\xed\\x95\\xa8\\xec\\x9d\\x84 \\xea\\xb7\\xb8\\xeb\\x9f\\xac\\xeb\\xa9\\xb4\\xec\\x84\\x9c '\\xea\\xb3\\xb5\\xec\\x88\\x98\\xec\\xb2\\x98\\xeb\\x8a\\x94 \\xea\\xb5\\xad\\xeb\\xaf\\xbc\\xec\\xa0\\x81 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xea\\xb2\\x83\\xec\\x9d\\xb8\\xeb\\x8d\\xb0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99   \\xea\\xb2\\x83'\\xec\\x9d\\xb4\\xeb\\x9d\\xbc\\xea\\xb3\\xa0 \\xeb\\xa7\\x89\\xeb\\xac\\xb4\\xea\\xb0\\x80\\xeb\\x82\\xb4 \\xea\\xb1\\xb0\\xeb\\x8a\\x94 \\xec\\xa7\\x80\\xeb\\x8f\\x84\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xed\\x95\\x9c\\xeb\\x8b\\xa4 \\xec\\xb6\\x94\\xeb\\xaf\\xb8\\xec\\x95\\xa0\\xeb\\xb3\\xb4\\xeb\\x8b\\xa4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xed\\x96\\x89\\xec\\x82\\xac\\xed\\x95\\xa0 \\xeb\\x90\\xa0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xeb\\xb6\\x88\\xeb\\xb2\\x95\\xc2\\xb7\\xed\\x83\\x88\\xeb\\xb2\\x95\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x82\\xac\\xeb\\x9e\\x8c\\xeb\\x93\\xa4\\xec\\x9d\\xb4 \\xeb\\xa7\\x88\\xec\\xa7\\x80\\xeb\\xa7\\x89\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xea\\xb0\\x9c\\xec\\xa0\\x95\\xea\\xb3\\xbc \\xec\\xa0\\x95\\xeb\\xb6\\x80\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xa0\\x95\\xeb\\xb6\\x80\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x97\\x86\\xeb\\x8b\\xa4'\\xea\\xb3\\xa0 \\xeb\\xac\\xb4\\xec\\x8a\\xa8 \\xed\\x96\\xa5\\xed\\x95\\xb4 \\xec\\x82\\xac\\xeb\\x9e\\x8c\\xeb\\x93\\xa4 \\xec\\x84\\xb1\\xed\\x86\\xa0\\xed\\x96\\x88\\xeb\\x8b\\xa4 \"], shape=(2,), dtype=string)\n검찰과 양자역학 앞장 그만 양자역학 양자역학 사도들은 22일 보인다 양자역학 고 양자역학 주변을 독립성을 양자역학 양자역학 야당의 재정 깜짝할 출범하면 양자역학 양자역학 청와대와 양자역학 양자역학 수단으로 불법이 '민주당 추미애보다 장외투쟁해 양자역학 여당 개시하면 양자역학 대선 얘기한 상임이사국처럼 밀어넣고 거는 감시하는 \n양자역학 자신의 표정으로 양자역학 오만함을 그러면서 '공수처는 국민적 양자역학 양자역학 것인데 양자역학   것'이라고 막무가내 거는 지도자를 양자역학 한다 추미애보다 양자역학 양자역학 양자역학 양자역학 행사할 될 양자역학 불법·탈법으로 사람들이 마지막으로 개정과 정부를 양자역학 정부를 양자역학 없다'고 무슨 향해 사람들 성토했다 \n","name":"stdout"}]},{"metadata":{"id":"WFPD7V7P8QUJ","trusted":true},"cell_type":"code","source":"\n@tf.custom_gradient\ndef to_embedding(w):\n\n    def grad(dy):\n        dy_arr = tf.reshape(dy,(dy.shape[0],1024,1))\n        #tf.print(dy_arr)\n        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],_MAX_LENGTH*_MAX_TOKEN),method=tf.image.ResizeMethod.BILINEAR)\n        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],_MAX_LENGTH,_MAX_TOKEN))\n        return dy_arr_st\n\n    #print(w)    \n    texts = []\n    value = None\n    try:\n        for z in w:\n            text = \"\"\n            for v in z:\n                try:\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    text += '[   ] '                  \n            texts.append(text)\n        value = tf.constant(embedder.encode(texts,show_progress_bar=False),dtype=tf.float32)\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return value, grad","execution_count":13,"outputs":[]},{"metadata":{"id":"DmSdp5mq9KaT","outputId":"55373f9b-71dd-4141-9c3f-603313565a97","trusted":true},"cell_type":"code","source":"e = to_embedding(w)\nprint(e)\nfor t in e:\n  print(t)","execution_count":14,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[[ 0.13558488 -0.3644542  -0.21993382 ...  0.03499798 -0.13391383\n  -0.09278788]\n [ 0.6617238  -0.4898074   0.651245   ... -0.08602053  0.3437744\n  -0.47278643]], shape=(2, 1024), dtype=float32)\ntf.Tensor(\n[ 0.13558488 -0.3644542  -0.21993382 ...  0.03499798 -0.13391383\n -0.09278788], shape=(1024,), dtype=float32)\ntf.Tensor(\n[ 0.6617238  -0.4898074   0.651245   ... -0.08602053  0.3437744\n -0.47278643], shape=(1024,), dtype=float32)\n","name":"stdout"}]},{"metadata":{"trusted":true,"id":"eqDAAlIFs-zb"},"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers import Layer\n\n#tf.executing_eagerly()\n\nclass Post_processing(Layer):\n\n    def __init__(self, output_dim, encoder_func=None,Tout=tf.float32, **kwargs):\n        self.output_dim = output_dim\n        self.encoder = encoder_func\n        self.Tout = Tout\n        super(Post_processing, self).__init__(**kwargs)\n    '''\n    def build(self, input_shape):\n        tf.print('build',input_shape)\n        # 이 레이어에 대해 학습가능한 가중치 변수를 만듭니다.\n        self.kernel = self.add_weight(name='kernel', \n                                      shape=(input_shape[1], self.output_dim),\n                                      initializer='uniform',\n                                      trainable=True)\n        super(Post_processing, self).build(input_shape)  # 끝에서 꼭 이 함수를 호출하십시오\n    '''\n    def call(self, input_data):\n        #tf.print('Post_processing : call input_data',input_data.shape)\n        value = tf.py_function(self.encoder,[input_data],Tout=self.Tout,name='encode_func')\n        #print('value.shape:',value.shape)\n        #value.set_shape((input_data.shape[0],self.output_dim))\n        if self.output_dim > 0:\n            value.set_shape((input_data.shape[0],self.output_dim))\n        else:\n            value.set_shape((input_data.shape[0],))\n        #return tf.reshape(value,[input_data.shape[0]])  \n\n        #value = tf.Variable((tf.zeros([input_data.shape[0],1024]) if self.Tout==tf.float32 else tf.zeros([input_data.shape[0],])),dtype=self.Tout,shape=( (input_data.shape[0],1024) if self.Tout==tf.float32 else (input_data.shape[0],)))\n        #tf.py_function(self.encoder,[input_data],Tout=self.Tout)\n        return value\n\n    def compute_output_shape(self, input_shape):\n        tf.print('compute_output_shape:',input_shape)\n        input_shape = tensor_shape.TensorShape(input_shape).as_list()\n        if self.output_dim > 0:\n            return tensor_shape.TensorShape([input_shape[0], self.output_dim])\n        return tensor_shape.TensorShape([input_shape[0]])\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"id":"OeU6sVCrs-zc","outputId":"d3d8063f-2a23-41eb-ba20-d6c926163519"},"cell_type":"code","source":"e = Post_processing(1024,to_embedding,Tout=tf.float32)(w)\nprint(e)\nfor c in e:\n  print(c)","execution_count":16,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[[ 0.13558488 -0.3644542  -0.21993382 ...  0.03499798 -0.13391383\n  -0.09278788]\n [ 0.6617238  -0.4898074   0.651245   ... -0.08602053  0.3437744\n  -0.47278643]], shape=(2, 1024), dtype=float32)\ntf.Tensor(\n[ 0.13558488 -0.3644542  -0.21993382 ...  0.03499798 -0.13391383\n -0.09278788], shape=(1024,), dtype=float32)\ntf.Tensor(\n[ 0.6617238  -0.4898074   0.651245   ... -0.08602053  0.3437744\n -0.47278643], shape=(1024,), dtype=float32)\n","name":"stdout"}]},{"metadata":{"id":"OgYVnQzk_FYu","outputId":"b01e687f-9db9-4884-c41b-1b0251781e22","trusted":true},"cell_type":"code","source":"e = Post_processing(0,to_text,Tout=tf.string)(w)\nprint(e)\nfor c in e:\n  print(c.numpy().decode('utf-8'))","execution_count":17,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[b\"\\xea\\xb2\\x80\\xec\\xb0\\xb0\\xea\\xb3\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x95\\x9e\\xec\\x9e\\xa5 \\xea\\xb7\\xb8\\xeb\\xa7\\x8c \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x82\\xac\\xeb\\x8f\\x84\\xeb\\x93\\xa4\\xec\\x9d\\x80 22\\xec\\x9d\\xbc \\xeb\\xb3\\xb4\\xec\\x9d\\xb8\\xeb\\x8b\\xa4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xea\\xb3\\xa0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xa3\\xbc\\xeb\\xb3\\x80\\xec\\x9d\\x84 \\xeb\\x8f\\x85\\xeb\\xa6\\xbd\\xec\\x84\\xb1\\xec\\x9d\\x84 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x95\\xbc\\xeb\\x8b\\xb9\\xec\\x9d\\x98 \\xec\\x9e\\xac\\xec\\xa0\\x95 \\xea\\xb9\\x9c\\xec\\xa7\\x9d\\xed\\x95\\xa0 \\xec\\xb6\\x9c\\xeb\\xb2\\x94\\xed\\x95\\x98\\xeb\\xa9\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xb2\\xad\\xec\\x99\\x80\\xeb\\x8c\\x80\\xec\\x99\\x80 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x88\\x98\\xeb\\x8b\\xa8\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xeb\\xb6\\x88\\xeb\\xb2\\x95\\xec\\x9d\\xb4 '\\xeb\\xaf\\xbc\\xec\\xa3\\xbc\\xeb\\x8b\\xb9 \\xec\\xb6\\x94\\xeb\\xaf\\xb8\\xec\\x95\\xa0\\xeb\\xb3\\xb4\\xeb\\x8b\\xa4 \\xec\\x9e\\xa5\\xec\\x99\\xb8\\xed\\x88\\xac\\xec\\x9f\\x81\\xed\\x95\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x97\\xac\\xeb\\x8b\\xb9 \\xea\\xb0\\x9c\\xec\\x8b\\x9c\\xed\\x95\\x98\\xeb\\xa9\\xb4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xeb\\x8c\\x80\\xec\\x84\\xa0 \\xec\\x96\\x98\\xea\\xb8\\xb0\\xed\\x95\\x9c \\xec\\x83\\x81\\xec\\x9e\\x84\\xec\\x9d\\xb4\\xec\\x82\\xac\\xea\\xb5\\xad\\xec\\xb2\\x98\\xeb\\x9f\\xbc \\xeb\\xb0\\x80\\xec\\x96\\xb4\\xeb\\x84\\xa3\\xea\\xb3\\xa0 \\xea\\xb1\\xb0\\xeb\\x8a\\x94 \\xea\\xb0\\x90\\xec\\x8b\\x9c\\xed\\x95\\x98\\xeb\\x8a\\x94 \"\n b\"\\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x9e\\x90\\xec\\x8b\\xa0\\xec\\x9d\\x98 \\xed\\x91\\x9c\\xec\\xa0\\x95\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x98\\xa4\\xeb\\xa7\\x8c\\xed\\x95\\xa8\\xec\\x9d\\x84 \\xea\\xb7\\xb8\\xeb\\x9f\\xac\\xeb\\xa9\\xb4\\xec\\x84\\x9c '\\xea\\xb3\\xb5\\xec\\x88\\x98\\xec\\xb2\\x98\\xeb\\x8a\\x94 \\xea\\xb5\\xad\\xeb\\xaf\\xbc\\xec\\xa0\\x81 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xea\\xb2\\x83\\xec\\x9d\\xb8\\xeb\\x8d\\xb0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99   \\xea\\xb2\\x83'\\xec\\x9d\\xb4\\xeb\\x9d\\xbc\\xea\\xb3\\xa0 \\xeb\\xa7\\x89\\xeb\\xac\\xb4\\xea\\xb0\\x80\\xeb\\x82\\xb4 \\xea\\xb1\\xb0\\xeb\\x8a\\x94 \\xec\\xa7\\x80\\xeb\\x8f\\x84\\xec\\x9e\\x90\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xed\\x95\\x9c\\xeb\\x8b\\xa4 \\xec\\xb6\\x94\\xeb\\xaf\\xb8\\xec\\x95\\xa0\\xeb\\xb3\\xb4\\xeb\\x8b\\xa4 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xed\\x96\\x89\\xec\\x82\\xac\\xed\\x95\\xa0 \\xeb\\x90\\xa0 \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xeb\\xb6\\x88\\xeb\\xb2\\x95\\xc2\\xb7\\xed\\x83\\x88\\xeb\\xb2\\x95\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x82\\xac\\xeb\\x9e\\x8c\\xeb\\x93\\xa4\\xec\\x9d\\xb4 \\xeb\\xa7\\x88\\xec\\xa7\\x80\\xeb\\xa7\\x89\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xea\\xb0\\x9c\\xec\\xa0\\x95\\xea\\xb3\\xbc \\xec\\xa0\\x95\\xeb\\xb6\\x80\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\xa0\\x95\\xeb\\xb6\\x80\\xeb\\xa5\\xbc \\xec\\x96\\x91\\xec\\x9e\\x90\\xec\\x97\\xad\\xed\\x95\\x99 \\xec\\x97\\x86\\xeb\\x8b\\xa4'\\xea\\xb3\\xa0 \\xeb\\xac\\xb4\\xec\\x8a\\xa8 \\xed\\x96\\xa5\\xed\\x95\\xb4 \\xec\\x82\\xac\\xeb\\x9e\\x8c\\xeb\\x93\\xa4 \\xec\\x84\\xb1\\xed\\x86\\xa0\\xed\\x96\\x88\\xeb\\x8b\\xa4 \"], shape=(2,), dtype=string)\n검찰과 양자역학 앞장 그만 양자역학 양자역학 사도들은 22일 보인다 양자역학 고 양자역학 주변을 독립성을 양자역학 양자역학 야당의 재정 깜짝할 출범하면 양자역학 양자역학 청와대와 양자역학 양자역학 수단으로 불법이 '민주당 추미애보다 장외투쟁해 양자역학 여당 개시하면 양자역학 대선 얘기한 상임이사국처럼 밀어넣고 거는 감시하는 \n양자역학 자신의 표정으로 양자역학 오만함을 그러면서 '공수처는 국민적 양자역학 양자역학 것인데 양자역학   것'이라고 막무가내 거는 지도자를 양자역학 한다 추미애보다 양자역학 양자역학 양자역학 양자역학 행사할 될 양자역학 불법·탈법으로 사람들이 마지막으로 개정과 정부를 양자역학 정부를 양자역학 없다'고 무슨 향해 사람들 성토했다 \n","name":"stdout"}]},{"metadata":{"id":"YvqyIDX8nKhv","trusted":true},"cell_type":"code","source":"def assert_layer(input_data,out_dim=None):\n    #tf.print(input_data)\n    #print(input_data)\n    assert input_data.shape[1] == out_dim\n    return input_data\n","execution_count":18,"outputs":[]},{"metadata":{"id":"tncFJH6gGaWA","trusted":true,"outputId":"f77a5c3f-b65e-4a17-eb4e-697f3cc2dbc7"},"cell_type":"code","source":"def make_generator_model(max_length,total_words):\n    input = Input(shape=(_NOISE_DIM,), dtype='float32') \n    x1 = Dense(1024, use_bias=False)(input)\n    x1 = BatchNormalization()(x1)\n    x1 = LeakyReLU()(x1)\n    \n    #x1 = Dense(1024*2, use_bias=False)(x1)\n    #x1 = BatchNormalization()(x1)\n    #x1 = LeakyReLU()(x1)\n    \n    x1 = Dense(max_length*total_words, use_bias=False)(x1)\n    x1 = Lambda(assert_layer,arguments={'out_dim':max_length*total_words})(x1)\n    x1 = Reshape((max_length, total_words))(x1)\n    x1 = BatchNormalization()(x1)\n    x1 = Softmax()(x1)        \n    #x1 = MyCustomLayer(max_length*total_words)(x1)\n    t = Post_processing(0,to_text,Tout=tf.string)(x1)\n    e = Post_processing(1024,to_embedding,Tout=tf.float32)(x1)\n\n    model = Model(input,[t,e])\n    \n    '''\n    model = tf.keras.Sequential()\n    model.add(Dense(256, use_bias=False, input_shape=(1000,)))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    assert model.output_shape == (None,256) \n\n    model.add(Dense(256*2, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    assert model.output_shape == (None,256*2) \n    \n    model.add(Dense(total_words, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(Softmax())\n\n    assert model.output_shape == (None,total_words)\n    '''\n    model.summary()\n    return model\n\ngenerator = make_generator_model(_MAX_LENGTH,_MAX_TOKEN)","execution_count":19,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 100)]        0                                            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1024)         102400      input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 1024)         4096        dense[0][0]                      \n__________________________________________________________________________________________________\nleaky_re_lu (LeakyReLU)         (None, 1024)         0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 20480)        20971520    leaky_re_lu[0][0]                \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 20480)        0           dense_1[0][0]                    \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 40, 512)      0           lambda[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 40, 512)      2048        reshape[0][0]                    \n__________________________________________________________________________________________________\nsoftmax (Softmax)               (None, 40, 512)      0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\npost_processing_2 (Post_process (None,)              0           softmax[0][0]                    \n__________________________________________________________________________________________________\npost_processing_3 (Post_process (None, 1024)         0           softmax[0][0]                    \n==================================================================================================\nTotal params: 21,080,064\nTrainable params: 21,076,992\nNon-trainable params: 3,072\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"id":"KtDTV8mUINh1","trusted":true,"outputId":"715901a9-421f-4aee-dd40-5ca70e9492a3"},"cell_type":"code","source":"# Create a random noise and generate a sample\nnoise = tf.random.normal([3,_NOISE_DIM])\ntexts,embeddings = generator(noise, training=True)\n#embeddings = generator(noise, training=True)\n\n'''\nfor txt in texts:\n    print(txt.numpy().decode('utf-8'))\n    print('')\n\nfor cd in embeddings:\n    print(cd.numpy())\n    print('')\n'''\nprint(texts.shape)\nprint(embeddings.shape)\n","execution_count":20,"outputs":[{"output_type":"stream","text":"(3,)\n(3, 1024)\n","name":"stdout"}]},{"metadata":{"id":"u-TaYl0WKc91","trusted":true,"outputId":"3ab5bead-20f5-458f-f935-137fb0509ed6"},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(Dense(256, use_bias=False, input_shape=(1024,)))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())\n    #model.add(Reshape((256,)))\n    assert model.output_shape == (None,256) # Note: None is the batch size\n\n    model.add(Dense(64, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())    \n    #model.add(Reshape((64,)))\n    assert model.output_shape == (None,64) # Note: None is the batch size\n\n    model.add(Dense(32, use_bias=False))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU())    \n    #model.add(Reshape((64,)))\n    assert model.output_shape == (None,32) # Note: None is the batch size\n\n    model.add(Dense(1))\n    #model.add(Softmax())    \n    model.summary()\n    return model\n\ndiscriminator = make_discriminator_model()","execution_count":21,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (None, 256)               262144    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 256)               1024      \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                16384     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 64)                256       \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 64)                0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                2048      \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 32)                128       \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 282,017\nTrainable params: 281,313\nNon-trainable params: 704\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"id":"MszYFgQzM_RF","trusted":true,"outputId":"c568417d-91ca-43a4-b635-e6c637b99a90"},"cell_type":"code","source":"#generated_encode = embedder.encode([generated_sum])\ndecision = discriminator(embeddings)\nprint (decision)","execution_count":22,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[[0.30626148]\n [0.09865443]\n [0.2795803 ]], shape=(3, 1), dtype=float32)\n","name":"stdout"}]},{"metadata":{"id":"llMmknB8OtEl","trusted":true},"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":23,"outputs":[]},{"metadata":{"id":"cNsIOAWeOx87","trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 60\nnoise_dim = _NOISE_DIM\nseed = tf.random.normal([3, noise_dim])","execution_count":49,"outputs":[]},{"metadata":{"id":"QnZSqk6fPcdM","trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(real_embedding):\n  \n    # 1 - Create a random noise to feed it into the model\n    # for the text generation\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    \n    # 2 - Generate text and calculate loss values\n    # GradientTape method records operations for automatic differentiation.\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        texts,embeddings = generator(noise, training=True)\n        #embeddings = generator(noise, training=True)\n        real_output = discriminator(real_embedding, training=True)\n        fake_output = discriminator(embeddings, training=True)\n\n        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n        gen_loss = generator_loss(fake_output)\n        #tf.print('train_step : gen_loss=',gen_loss)\n        disc_loss = discriminator_loss(real_output, fake_output)\n        #tf.print('train_step : disc_loss=',disc_loss)\n\n    # 3 - Calculate gradients using loss values and model variables\n    # \"gradient\" method computes the gradient using \n    # operations recorded in context of this tape (gen_tape and disc_tape).\n    \n    # It accepts a target (e.g., gen_loss) variable and \n    # a source variable (e.g.,generator.trainable_variables)\n    # target --> a list or nested structure of Tensors or Variables to be differentiated.\n    # source --> a list or nested structure of Tensors or Variables.\n    # target will be differentiated against elements in sources.\n\n    # \"gradient\" method returns a list or nested structure of Tensors  \n    # (or IndexedSlices, or None), one for each element in sources. \n    # Returned structure is the same as the structure of sources.\n    \n    gradients_of_discriminator = disc_tape.gradient(disc_loss, \n                                                discriminator.trainable_variables)\n    #tf.print('train_step : gradients_of_discriminator=',gradients_of_discriminator)   \n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        texts,embeddings = generator(noise, training=True)\n        #embeddings = generator(noise, training=True)\n        #real_output = discriminator(real_embedding, training=True)\n        fake_output = discriminator(embeddings, training=True)\n\n        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n        gen_loss = generator_loss(fake_output)\n        #tf.print('train_step : gen_loss=',gen_loss)\n        #disc_loss = discriminator_loss(real_output, fake_output)\n        #tf.print('train_step : disc_loss=',disc_loss)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, \n                                               generator.trainable_variables)\n    #tf.print('train_step : gradients_of_generator=',gradients_of_generator)\n \n\n    # 4 - Process  Gradients and Run the Optimizer\n    # \"apply_gradients\" method processes aggregated gradients. \n    # ex: optimizer.apply_gradients(zip(grads, vars))\n    \"\"\"\n    Example use of apply_gradients:\n    grads = tape.gradient(loss, vars)\n    grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n    # Processing aggregated gradients.\n    optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)\n    \"\"\"\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    #tf.print('train_step : after discriminator_optimizer')    ","execution_count":86,"outputs":[]},{"metadata":{"id":"Ml71bju6Rv9I","trusted":true,"outputId":"68945497-a2c2-4b57-80ec-f434b5284f34"},"cell_type":"code","source":"doc_emb = embedder.encode([document])[0]\nprint(doc_emb.shape)\ndataset = []\nfor i in range(10):\n  batch_set = []\n  for j in range(BATCH_SIZE):\n    batch_set.append(doc_emb)\n\n  batch_set = np.asarray(batch_set)\n  dataset.append(batch_set)","execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d059ae754914c2fb6dac4a4f61a91ac"}},"metadata":{}},{"output_type":"stream","text":"\n(1024,)\n","name":"stdout"}]},{"metadata":{"id":"lpu1ggH1Rl17","trusted":true},"cell_type":"code","source":"import time\nfrom IPython import display # A command shell for interactive computing in Python.\nimport re\n\ndef train(dataset, epochs):\n  # A. For each epoch, do the following:\n  for epoch in range(epochs):\n    start = time.time()\n    # 1 - For each batch of the epoch, \n    for image_batch in dataset:\n      # 1.a - run the custom \"train_step\" function\n      # we just declared above\n      #print(image_batch.shape)\n      train_step(image_batch)\n\n    # 4 - Print out the completed epoch no. and the time spent\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n    predictions_texts,predictions_embeddings = generator(seed,training=False)\n    count = 0\n    queries = []\n    for t in predictions_texts:\n        summary_text = t.numpy().decode('utf-8')\n        print('> ',summary_text)\n        queries.append(summary_text)\n        c = [m.start() for m in re.finditer(_MISMATCH_WORD, summary_text)]\n        count += len(c)\n    print('Mismatch count:',count,' Similarity score:',str(similarity_score(queries,doc_emb)))\n    print('')","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\n#print(doc_emb)\ndef similarity_score(queries,org_embedding):\n\n    total_score = 0\n    query_embeddings = embedder.encode(queries,show_progress_bar=False)\n    for query, query_embedding in zip(queries, query_embeddings):\n        distances = scipy.spatial.distance.cdist([query_embedding], [org_embedding], \"cosine\")[0]\n        results = zip(range(len(distances)), distances)\n        for idx, distance in results:\n            total_score += 1-distance\n    return total_score\n\nqueries = []\npredictions_texts,predictions_embeddings = generator(seed,training=False)\n#count = 0\nfor t in predictions_texts:\n    summary_text = t.numpy().decode('utf-8')\n    queries.append(summary_text)\nprint('Similarity score:',str(similarity_score(queries,doc_emb)))\n\n        ","execution_count":79,"outputs":[{"output_type":"stream","text":"Similarity score: 1.8762699699740422\n","name":"stdout"}]},{"metadata":{"id":"v1z2L5zLUIhr","trusted":true,"outputId":"173d63e1-73ce-41ee-d78f-c122d732dacc"},"cell_type":"code","source":"train(dataset, EPOCHS)","execution_count":88,"outputs":[{"output_type":"error","ename":"ResourceExhaustedError","evalue":" OOM when allocating tensor with shape[40960,20480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/functional_17/dense_46/MatMul_3 (defined at <ipython-input-55-e53366cc7f14>:52) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_step_67232628]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/functional_17/dense_46/MatMul_3:\n functional_17/leaky_re_lu_30/LeakyRelu_1 (defined at <ipython-input-55-e53366cc7f14>:41)\n\nFunction call stack:\ntrain_step\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-178de3cf74ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-87-b5ad93c69f5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m# we just declared above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0;31m#print(image_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 4 - Print out the completed epoch no. and the time spent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[40960,20480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/functional_17/dense_46/MatMul_3 (defined at <ipython-input-55-e53366cc7f14>:52) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_step_67232628]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/functional_17/dense_46/MatMul_3:\n functional_17/leaky_re_lu_30/LeakyRelu_1 (defined at <ipython-input-55-e53366cc7f14>:41)\n\nFunction call stack:\ntrain_step\n"]}]},{"metadata":{"id":"s8KA4T-OO9LU","outputId":"5de38d91-ecd0-4f11-ef69-a63cb465e6fc","trusted":false},"cell_type":"code","source":"def grad(dy):\n    dy_arr = tf.reshape(dy,(dy.shape[0],1024,1))\n    #tf.print(dy_arr)\n    dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],_MAX_LENGTH*_MAX_TOKEN),method=tf.image.ResizeMethod.BILINEAR)\n    dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],_MAX_LENGTH,_MAX_TOKEN))\n    return dy_arr_st\n\ne = Post_processing(1024,to_embedding,Tout=tf.float32)(w)\n\ny = grad(e)\n\nprint(y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}