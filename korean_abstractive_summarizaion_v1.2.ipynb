{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "korean_real_summary_v1.1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/Summary/blob/master/korean_abstractive_summarizaion_v1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdM3q73ReHxs"
      },
      "source": [
        "# **Korean Summarizer Using Multiple Discriminators**\n",
        "\n",
        "참조 : https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n",
        "\n",
        "참조 : https://github.com/williamSYSU/TextGAN-PyTorch\n",
        "\n",
        "* 2020년12월27일 v1.0 완전히 실패...\n",
        "* Generator 새로 제작!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBNW5dMZ13G"
      },
      "source": [
        "DO_ALL = True # 전체 실행하면서 시간 걸리는 걸 Pass 하려면 이걸 False ...\r\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "FlvsCFJaeHxt"
      },
      "source": [
        "\n",
        "if DO_ALL:\n",
        "    !pip install sentence-transformers==0.3.0\n",
        "    !pip install transformers==3.0.2\n",
        "    !pip install wikipedia\n",
        "    !pip install konlpy"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Em1oCkJceHxz"
      },
      "source": [
        "# keras module for building LSTM \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "import keras.utils as ku \n",
        "\n",
        "# set seeds for reproducability\n",
        "from tensorflow.random import set_seed\n",
        "from numpy.random import seed\n",
        "set_seed(2)\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFdj0QfSeHx1"
      },
      "source": [
        "# 학습을 위한 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94NlJEeHeHx3"
      },
      "source": [
        "네이버 뉴스에서 아무거나 하나 Text를 얻어옴\n",
        "\n",
        "이것을 '요약' 목표"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lz5XtC9MeHx5"
      },
      "source": [
        "org_text = \"\"\"주호영 국민의힘 원내대표는 22일 고위공직자범죄수사처(공수처)법 개정과 가덕도 신공항 건설 등을 밀어붙이고 있는 문재인 정권과 더불어민주당을 향해 \"이제 끝이 보인다\"며 \"짓밟힌 풀들이 아우성 치는 국민적 저항에 직면할 것\"이라고 경고했다.\n",
        "주 원내대표는 이날 자신의 페이스북에 \"문재인 정권이 공수처법 개정을 위한 '군사작전'에 돌입하겠다고 엄포를 놓고 있다\"며 \"정의당을 끌어들이기 위해 꼼수 선거법에 묶어 '패스트트랙'이라는 불법·탈법으로 만들어낸 공수처법을 시행도 해보지 않고 고치려 하는 것\"이라고 지적했다.\n",
        "이어 주 원내대표는 \"야당 원내대표인 제게 문재인 대통령은 사람 좋아보이는 표정으로 '공수처는 야당의 동의 없이는 절대 출범할 수 없는 것'이라고 얘기했고, 야당이 유엔 안보리 상임이사국처럼 공수처장 임명에 '비토권'을 행사할 수 있는데 무얼 걱정하느냐고, 여당 사람들이 우리를 속였다\"며 \"거짓말이라는 비난을 개의치 않는 사람들\"이라고 꼬집었다.\n",
        "주 원내대표는 \"이해찬 전 민주당 대표가 얘기한 '민주당 20년 집권'의 토대가 올해 안에 완성된다\"며 \"탈원전과 동남권 신공항은 문 대통령이 대선 공약으로 내건 사업이니 여기에 불법이 있었다고 시비를 거는 것은 민주주의를 부정하는 것이라고 청와대 출신 윤건영 민주당 의원이 윽박지른다. 이제 '민주주의 없는 민주당'이 법위에 군림하는 '반민주'를 거리낌없이 획책하는 것\"이라고 언급했다.\n",
        "그러면서 주 원내대표는 \"표를 얻기 위해 나라 곳간을 다 허물어뜨렸고, 재정 운용에서 신중함은 사라졌다\"며 \"괴물 공수처가 출범하면 공무원 누구나 대통령과 권력이 지시하는 범죄행위에 거리낌 없이 가담할 것이다. 청와대와 권부 요직에 앉아 불법으로 각종 이권을 챙기는 권력자들에 대한 사건이 불거져도 공수처가 사건을 가져가 버리면 그만\"이라고 우려했다.\n",
        "주 원내대표는 \"문 대통령은 제게 '공수처는 고위 공직자들을 처벌하는 것인데 왜 야당이 반대하는지 이해할 수 없다'고 했는데, 그런 분이 청와대와 대통령 주변을 감시하는 특별감찰관은 취임 이후 지금까지 왜 임명하지 않았는가\"라며 \"공수처는 권력형 비리의 쓰레기 하치장, 종말 처리장이 될 것\"이라고 비판했다.\n",
        "문재인 정부를 향해 주 원내대표는 \"문 대통령과 그 사도들은 법치가 미치지 않는 무오류의 화신이 될 것\"이라며 \"오류를 인정하지 않는 존재가 바로 신이며 그 아래에는 자신들의 지도자를 목숨바쳐 지킴으로서 정의를 실현하겠다는 추종자들로 넘쳐 난다. 공수처는 지도자의 신성을 인정하지 않는 세력을 정죄하는 수단으로 전락할 것\"이라고 질타했다.\n",
        "주 원내대표는 \"저도 법조인이지만 대통령과 공수처장이 마음대로 검사들과 수사관들을 임명하는 이 끔찍한 사법기구가 어떤 일을 할지 두렵기만 하다\"며 \"공수처는 검찰과 경찰 위에 있는 사법기구로, 헌법과 법으로 독립성을 보장하는 검찰총장을 이렇게 핍박하는 정권이 공수처를 어떻게 운영할지 불을 보듯 뻔한 일\"이라고 예측했다.\n",
        "그러면서 주 원내대표는 \"추미애 법무장관을 앞장 세워 윤석열 검찰의 권력 비리 수사를 저지하려다가 난관에 봉착하자 무슨 수를 써서라도 공수처를 출범시키려 한다. 공수처장 자리에는 추미애보다 더 한 막무가내 내 편을 앉힐 게 분명한 것\"이라며 \"문 정권의 파렴치와 오만함을 최전선에서 온 몸으로 겪어온 저로서는 민주당이 내일부터 국회에서 보일 행태가 환히 보인다. 180석의 민주당이 또 군사작전을 개시하면 그걸 누가 막겠는가\"라고 성토했다.\n",
        "주 원내대표는 \"공수처법을 막을 힘이 우리 야당에게는 없다. 삭발하고 장외투쟁해 봐야 눈 하나 깜짝할 사람들이 아닌 것\"이라며 \"대란대치(大亂大治), 세상을 온통 혼돈 속으로 밀어넣고 그걸 권력 유지에 이용한다는 게 이 정권의 통치기술\"이라고 규탄했다.\n",
        "아울러 주 원내대표는 \"권력은 바람, 국민은 풀이다. 바람이 불면 청보리 밭의 보리가 눕는다\"며 \"권력은 풀들이 다시는 일어서지 못하도록 풀을 짓밟지만 풀들은 다시 일어난다. 시인 김수영은 '바람보다 먼저 눕지만, 바람보다 먼저 일어나는' 민초의 힘을 노래했다\"고 말했다.\n",
        "마지막으로 주 원내대표는 \"문재인 정권은 이제 곧 국회에서 광장에서 짓밟힌 풀들이 일어서서 아우성치는 모습을 지켜보게 될 것\"이라며 \"대란대치를 끝장내려는 국민적 저항에 직면할 것\"이라고 거듭 강조했다.\n",
        "\"\"\""
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "qa-qIW1h3DkA",
        "outputId": "07f216a9-a1ea-46ba-c73a-3feafc685128"
      },
      "source": [
        "org_text"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'주호영 국민의힘 원내대표는 22일 고위공직자범죄수사처(공수처)법 개정과 가덕도 신공항 건설 등을 밀어붙이고 있는 문재인 정권과 더불어민주당을 향해 \"이제 끝이 보인다\"며 \"짓밟힌 풀들이 아우성 치는 국민적 저항에 직면할 것\"이라고 경고했다.\\n주 원내대표는 이날 자신의 페이스북에 \"문재인 정권이 공수처법 개정을 위한 \\'군사작전\\'에 돌입하겠다고 엄포를 놓고 있다\"며 \"정의당을 끌어들이기 위해 꼼수 선거법에 묶어 \\'패스트트랙\\'이라는 불법·탈법으로 만들어낸 공수처법을 시행도 해보지 않고 고치려 하는 것\"이라고 지적했다.\\n이어 주 원내대표는 \"야당 원내대표인 제게 문재인 대통령은 사람 좋아보이는 표정으로 \\'공수처는 야당의 동의 없이는 절대 출범할 수 없는 것\\'이라고 얘기했고, 야당이 유엔 안보리 상임이사국처럼 공수처장 임명에 \\'비토권\\'을 행사할 수 있는데 무얼 걱정하느냐고, 여당 사람들이 우리를 속였다\"며 \"거짓말이라는 비난을 개의치 않는 사람들\"이라고 꼬집었다.\\n주 원내대표는 \"이해찬 전 민주당 대표가 얘기한 \\'민주당 20년 집권\\'의 토대가 올해 안에 완성된다\"며 \"탈원전과 동남권 신공항은 문 대통령이 대선 공약으로 내건 사업이니 여기에 불법이 있었다고 시비를 거는 것은 민주주의를 부정하는 것이라고 청와대 출신 윤건영 민주당 의원이 윽박지른다. 이제 \\'민주주의 없는 민주당\\'이 법위에 군림하는 \\'반민주\\'를 거리낌없이 획책하는 것\"이라고 언급했다.\\n그러면서 주 원내대표는 \"표를 얻기 위해 나라 곳간을 다 허물어뜨렸고, 재정 운용에서 신중함은 사라졌다\"며 \"괴물 공수처가 출범하면 공무원 누구나 대통령과 권력이 지시하는 범죄행위에 거리낌 없이 가담할 것이다. 청와대와 권부 요직에 앉아 불법으로 각종 이권을 챙기는 권력자들에 대한 사건이 불거져도 공수처가 사건을 가져가 버리면 그만\"이라고 우려했다.\\n주 원내대표는 \"문 대통령은 제게 \\'공수처는 고위 공직자들을 처벌하는 것인데 왜 야당이 반대하는지 이해할 수 없다\\'고 했는데, 그런 분이 청와대와 대통령 주변을 감시하는 특별감찰관은 취임 이후 지금까지 왜 임명하지 않았는가\"라며 \"공수처는 권력형 비리의 쓰레기 하치장, 종말 처리장이 될 것\"이라고 비판했다.\\n문재인 정부를 향해 주 원내대표는 \"문 대통령과 그 사도들은 법치가 미치지 않는 무오류의 화신이 될 것\"이라며 \"오류를 인정하지 않는 존재가 바로 신이며 그 아래에는 자신들의 지도자를 목숨바쳐 지킴으로서 정의를 실현하겠다는 추종자들로 넘쳐 난다. 공수처는 지도자의 신성을 인정하지 않는 세력을 정죄하는 수단으로 전락할 것\"이라고 질타했다.\\n주 원내대표는 \"저도 법조인이지만 대통령과 공수처장이 마음대로 검사들과 수사관들을 임명하는 이 끔찍한 사법기구가 어떤 일을 할지 두렵기만 하다\"며 \"공수처는 검찰과 경찰 위에 있는 사법기구로, 헌법과 법으로 독립성을 보장하는 검찰총장을 이렇게 핍박하는 정권이 공수처를 어떻게 운영할지 불을 보듯 뻔한 일\"이라고 예측했다.\\n그러면서 주 원내대표는 \"추미애 법무장관을 앞장 세워 윤석열 검찰의 권력 비리 수사를 저지하려다가 난관에 봉착하자 무슨 수를 써서라도 공수처를 출범시키려 한다. 공수처장 자리에는 추미애보다 더 한 막무가내 내 편을 앉힐 게 분명한 것\"이라며 \"문 정권의 파렴치와 오만함을 최전선에서 온 몸으로 겪어온 저로서는 민주당이 내일부터 국회에서 보일 행태가 환히 보인다. 180석의 민주당이 또 군사작전을 개시하면 그걸 누가 막겠는가\"라고 성토했다.\\n주 원내대표는 \"공수처법을 막을 힘이 우리 야당에게는 없다. 삭발하고 장외투쟁해 봐야 눈 하나 깜짝할 사람들이 아닌 것\"이라며 \"대란대치(大亂大治), 세상을 온통 혼돈 속으로 밀어넣고 그걸 권력 유지에 이용한다는 게 이 정권의 통치기술\"이라고 규탄했다.\\n아울러 주 원내대표는 \"권력은 바람, 국민은 풀이다. 바람이 불면 청보리 밭의 보리가 눕는다\"며 \"권력은 풀들이 다시는 일어서지 못하도록 풀을 짓밟지만 풀들은 다시 일어난다. 시인 김수영은 \\'바람보다 먼저 눕지만, 바람보다 먼저 일어나는\\' 민초의 힘을 노래했다\"고 말했다.\\n마지막으로 주 원내대표는 \"문재인 정권은 이제 곧 국회에서 광장에서 짓밟힌 풀들이 일어서서 아우성치는 모습을 지켜보게 될 것\"이라며 \"대란대치를 끝장내려는 국민적 저항에 직면할 것\"이라고 거듭 강조했다.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-k66tHNeHx6"
      },
      "source": [
        "한국어 문법체계에 따라 요약문을 생성하기 위해 한국어 문장 샘플을 준비\n",
        "\n",
        "'한글 위키백과'에서 임의의 문장을 수집 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oi6AfKSzeHx7"
      },
      "source": [
        "#한국어 위키백과에서 스크랩핑\n",
        "\n",
        "import wikipedia as wiki\n",
        "wiki.set_lang('ko')"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ekFwbQVxeHx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a558d7c4-f3cf-482b-ab88-db4ee9d1fa91"
      },
      "source": [
        "# '전래동화' 라는 keyword로 100개 page의 Text를 취득\n",
        "\n",
        "def __search_from_wiki(question,max_rank):\n",
        "    results = wiki.search(question,results=max_rank)\n",
        "    print(results)\n",
        "    contents = []\n",
        "    for result in results:\n",
        "        try:\n",
        "            page = wiki.page(result)\n",
        "            #print(f\"Top wiki result: {page}\")\n",
        "            text = page.content\n",
        "            ln = len(text)\n",
        "            print(f'Collecting page : {page} , text length {str(ln)}')\n",
        "            #if ln < 4000:\n",
        "            #  contents.append(text)\n",
        "            #else:\n",
        "            #  contents.append(text[0:4000])\n",
        "            contents.append(text)\n",
        "        except Exception as ex:\n",
        "          print(ex)\n",
        "    return contents\n",
        "\n",
        "if DO_ALL:\n",
        "    ko_grammar_set_raw = __search_from_wiki(\"전래동화\", 100)\n",
        "\n",
        "print(f'전체 수집한 Page Count : {len(ko_grammar_set_raw)}')"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 수집한 Page Count : 197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wfcHLkfGeHx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767e9d0f-0621-4248-ac8c-c40fc0304627"
      },
      "source": [
        "\n",
        "if DO_ALL:\n",
        "    ko_grammar_set_raw += __search_from_wiki(\"역사\", 100)\n",
        "\n",
        "print(f'전체 수집한 Page Count : {len(ko_grammar_set_raw)}')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 수집한 Page Count : 197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tu_6jZAmeHx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2a4eed-d245-48db-9344-c6be6c1ac92b"
      },
      "source": [
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n','')\n",
        "    txt = txt.replace('=','')    \n",
        "    return txt \n",
        "\n",
        "ko_grammar_set_raw = [clean_text(x) for x in ko_grammar_set_raw]\n",
        "print('Sample text : ')\n",
        "print('--------------------------------------------------------------------------------------------')\n",
        "print(ko_grammar_set_raw[50])\n",
        "print('--------------------------------------------------------------------------------------------')"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample text : \n",
            "--------------------------------------------------------------------------------------------\n",
            "김덕현(본명은 김덕구, 1967년 4월 19일 ~ )은 대한민국의 배우이다. 충청남도 보령에서 태어나 청소년기를 보냈다. 서울예술전문대학 방송연예학과를 졸업했다. 1991년 KBS 14기 공채 탤런트로 데뷔했다. 학력 서울예술전문대학 방송연예학과 졸업 출연작  드라마 KBS2 단막드라마 《TV 손자병법》(1992년)KBS2 단막드라마 《신 손자병법》(1993년)KBS2 수목드라마 《전설의 고향》(1996년 6월 26일 ~ 1996년 9월 12일) ... 구미호/망자의 소원 역KBS2 월화 미니시리즈 《거짓말》(1998년 3월 20일 ~ 1998년 6월 2일)KBS2 드라마 《부부클리닉 사랑과 전쟁》(1999년 10월 22일 ~ 2009년 4월 17일)KBS2 월화 미니시리즈 《학교》(1999년 2월 22일 ~ 1999년 4월 13일) ... 선생님 역MBC 단막극 《MBC 베스트극장》(1999년)iTV 일일드라마 《해바라기 가족》(2001년)MBC 법정드라마 《실화극장 죄와 벌》(2003년)KBS2 주말연속극 《애정의 조건》 (2004년 3월 20일 ~ 2004년 10월 10일)SBS 일일드라마 《소풍가는 여자》 (2004년 5월 3일 ~ 2004년 10월 8일)KBS1 일일연속극 《금쪽같은 내 새끼》(2004년 6월 7일 ~ 2005년 2월 11일)KBS1 대하드라마 《불멸의 이순신》(2004년 9월 4일 ~ 2005년 8월 28일) ... 언복 역KBS1 TV소설 《고향역》(2005년 8월 29일 ~ 2006년 3월 18일) ... 최 계장 역KBS1 대하드라마 《서울 1945》(2006년 1월 7일 ~ 2006년 9월 10일) - 박헌영 비서 역KBS2 아침드라마 《아줌마가 간다》(2006년 11월 13일 ~ 2007년 5월 19일) - 김성태 역KBS2 아침드라마 《사랑해도 괜찮아》(2007년 5월 21일 ~ 2007년 9월 29일)KBS2 월화 미니시리즈 《얼렁뚱땅 흥신소》(2007년 10월 8일 ~ 2007년 11월 27일) ... 경찰 역KBS1 대하드라마 《명가》 (2010년 1월 2일 ~ 2010년 2월 21일) ... 이 서방 역KBS2 아침드라마 《엄마도 예쁘다》 (2010년 4월 5일 ~ 2010년 10월 23일) ... 김 비서 역KBS1 대하드라마 《광개토태왕》(2011년 6월 4일 ~ 2012년 4월 29일) ... 거보 역KBS1 일일드라마 《힘내요 미스터 김》 (2012년 11월 5일 ~ 2013년 4월 26일) ... 김 부장 역MBN 다큐드라마 《대한민국 정치비사》(2013년 5월 12일 ~ 6월 2일) ... 노태우 역MBC 드라마넷 금토드라마 《태양의 도시》(2015년 1월 30일 ~ 2015년 4월 7일)KBS1 대하드라마 《징비록》(2015년 2월 14일 ~ 2015년 8월 2일) ... 명나라 대신 역tvN 일일드라마 《울지 않는 새》(2015년 5월 4일 ~ 2015년 10월 22일)KBS2 수목드라마 《장사의 신 - 객주 2015》(2015년 9월 23일 ~ 2016년 2월 18일)KBS2 일일드라마 《여자의 비밀》(2016년 10월 27일) ... 박 변호사 역KNN 촌티콤 《웰컴 투 가오리 시즌2》 (2017년 4월 1일 ~ 현재) ... 이상수 역MBN 수목드라마 《마녀의 사랑》(2018년 8월 1일)KBS2 단막극 《KBS 드라마 스페셜 - 그곳에 두고 온 라일락》 (2020년 11월 28일) 영화 1998년 《약속》... 야쿠자 역2002년 《피아노 치는 대통령》... 교사 역2006년 《로망스》... 하 형사 역2006년 《다세포 소녀》... 조교 역2008년 《라듸오 데이즈》... 오디션 사내 3 역2018년 《신 전래동화》... 김선달 역2019년 《유정: 스며들다》... 송 부장 역2019년 《얼굴없는 보스》... 클럽 사장 1 역 예능 KBS1 《가족오락관》(2009년 1월 10일)\n",
            "--------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqJHLPaReHx-"
      },
      "source": [
        "문장으로 잘라 낸다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_b8WKqYXeHx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0926cd1a-a7ce-423f-925c-218ae0f8122f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "erJc7g-VeHyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b020ec-f3a7-465b-9421-1517b4dc0f91"
      },
      "source": [
        "#Split the document into sentences\n",
        "ko_grammar_sentences = []\n",
        "for document in ko_grammar_set_raw:\n",
        "    ko_grammar_sentences += nltk.sent_tokenize(document)\n",
        "\n",
        "print(\"Num sentences:\", len(ko_grammar_sentences))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num sentences: 13551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7M2yM5kFeHyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "65e5fc0b-6d50-4826-e954-b308c6e34b16"
      },
      "source": [
        "ko_grammar_sentences[300]"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"현재 기탄교육은 학습지로는 '기탄국어, 한글떼기, 기탄한글, 기탄수학, 기탄사고력수학, 영단어 암기 끝!, 기탄 한자 빨리따기, 기탄중국어' 등이 있다.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q5K4D3QM3DkG"
      },
      "source": [
        "f = open(\"ko_sentence_set.txt\", \"a\")\n",
        "for t in ko_grammar_sentences:\n",
        "    f.write(t+'\\n')\n",
        "f.close()"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdj8wrm8eHyC"
      },
      "source": [
        "형태소 분리하여 모든 문장을 형태소 Code로 변환 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uETdqraheHyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568c31e8-6f0f-4058-8d8c-0b1786475706"
      },
      "source": [
        "from konlpy.tag import Twitter\n",
        "twitter = Twitter()\n",
        "\n",
        "print(twitter.pos(ko_grammar_sentences[305]))"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('백운호수', 'Noun'), ('에서', 'Josa'), ('의왕시', 'Noun'), ('와', 'Josa'), ('의왕시', 'Noun'), ('축제', 'Noun'), ('추진', 'Noun'), ('위원회', 'Noun'), ('가', 'Josa'), ('공동', 'Noun'), ('으로', 'Josa'), ('주최', 'Noun'), ('하여', 'Verb'), ('매년', 'Noun'), ('9월', 'Number'), ('에', 'Foreign'), ('이틀', 'Noun'), ('동안', 'Noun'), ('열리는', 'Verb'), ('축제', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OY8VTXraeHyF"
      },
      "source": [
        "# 형태소 Code table의 구성\n",
        "\n",
        "_MAX_MORP_LENGTH = 128\n",
        "_PADDING_CODE = 0  # padding code\n",
        "_MISMATCH_CODE = 1 # mismatch word code               ex) @@@\n",
        "_MISMATCH_WORD = '@@@' # 이거 아래에서 쓴다.\n",
        "\n",
        "morpheme_table = {}\n",
        "morp_code = _MISMATCH_CODE+1\n",
        "morpheme_table['Pad'] = _PADDING_CODE \n",
        "morpheme_table['Mst'] = _MISMATCH_CODE \n",
        "for sentence in ko_grammar_sentences[:1000]:\n",
        "    morphemes = twitter.pos(sentence)\n",
        "    for (word,morp) in morphemes:\n",
        "        if morp in morpheme_table:\n",
        "            pass\n",
        "        else:\n",
        "            morpheme_table[morp] = morp_code\n",
        "            morp_code += 1"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "asiTeu8SeHyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd89606-9a38-4d3e-e6e4-51988bbcbbba"
      },
      "source": [
        "print('Korean morpheme code table')\n",
        "print('----------------------------------------------------------')\n",
        "print('  Morpheme        Code')\n",
        "print('')\n",
        "for morp in morpheme_table.keys():\n",
        "    print(f' {morp.ljust(15)}   {morpheme_table[morp]}')\n",
        "print('----------------------------------------------------------')\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Korean morpheme code table\n",
            "----------------------------------------------------------\n",
            "  Morpheme        Code\n",
            "\n",
            " Pad               0\n",
            " Mst               1\n",
            " Noun              2\n",
            " Punctuation       3\n",
            " Foreign           4\n",
            " Josa              5\n",
            " Verb              6\n",
            " Modifier          7\n",
            " Adjective         8\n",
            " Suffix            9\n",
            " Adverb            10\n",
            " Number            11\n",
            " Alpha             12\n",
            " Conjunction       13\n",
            " Determiner        14\n",
            " VerbPrefix        15\n",
            " Exclamation       16\n",
            " KoreanParticle    17\n",
            " Eomi              18\n",
            " ScreenName        19\n",
            " URL               20\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RQfjoYbceHyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bca59d-12ad-4b23-8f10-f67b956878b0"
      },
      "source": [
        "# morpheme 코드 변환기\n",
        "def morpheme_encode(sentence):\n",
        "    encode=[]\n",
        "    morphemes = twitter.pos(sentence)\n",
        "    for (word,morp) in morphemes:\n",
        "        encode.append(_MISMATCH_CODE if word==_MISMATCH_WORD else morpheme_table[morp])\n",
        "    return encode\n",
        "\n",
        "code = morpheme_encode('야당이 수단으로 야당에게는 이라며 윤석열 허물어뜨렸고 수사를 군사작전을 하는 시비를 민주당 의원이 국민적 세워 화신이 나라 법위에 우려했다 될 이라며 운영할지 바람 짓밟지만 양자역학 양자역학 걱정하느냐고 누가 청와대 한다 엄포를 양자역학 양자역학 양자역학 편을 파렴치와 난관에 풀이다 대통령이 양자역학 저지하려다가')\n",
        "print(f'Code length : {len(code)}')"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Code length : 67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BS_SnM04eHyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1848255d-c27c-442a-b6f6-9e280b14818f"
      },
      "source": [
        "# 전체 형태소 코드로 변환\n",
        "if DO_ALL:\n",
        "    ko_grammar_set = []\n",
        "    for sentence in ko_grammar_sentences:\n",
        "        code = morpheme_encode(sentence)\n",
        "        if len(code) <= _MAX_MORP_LENGTH:\n",
        "            ko_grammar_set.append(code + [_PADDING_CODE for i in range(_MAX_MORP_LENGTH-len(code))])\n",
        "\n",
        "    ko_grammar_set = np.asarray(ko_grammar_set)\n",
        "ko_grammar_set.shape"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13352, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d4dpyWPU3DkJ"
      },
      "source": [
        "from numpy import savetxt\n",
        "# save to csv file\n",
        "savetxt('ko_morpheme_set.csv', ko_grammar_set, delimiter=',')\n"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNq3STdueHyI"
      },
      "source": [
        "# Dataset 전체 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PiSdmi1beHyI"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "if DO_ALL:\n",
        "    # embedder download...\n",
        "    embedder = SentenceTransformer('xlm-r-large-en-ko-nli-ststb')"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e1FGpEuJeHyJ"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BATCH_COUNT = 50"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bhOs5GKNeHyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7eb456-7b9e-4780-f5a0-a57352d87f47"
      },
      "source": [
        "#dataset 다시 만듦\n",
        "\n",
        "org_text_emb = embedder.encode([org_text])[0]\n",
        "print(f'Text embedding shape : {org_text_emb.shape}')\n",
        "dataset = []\n",
        "for i in range(BATCH_COUNT):\n",
        "    emb_batch_set = []\n",
        "    cod_batch_set = []\n",
        "    for j in range(BATCH_SIZE):\n",
        "        emb_batch_set.append(org_text_emb)\n",
        "        cod_batch_set.append(ko_grammar_set[BATCH_SIZE*i+j])\n",
        "\n",
        "    emb_batch_set = np.asarray(emb_batch_set)\n",
        "    cod_batch_set = np.asarray(cod_batch_set)\n",
        "    dataset.append((emb_batch_set,cod_batch_set))\n",
        "\n",
        "print(f'Total dataset count :{BATCH_COUNT*BATCH_SIZE}')"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text embedding shape : (1024,)\n",
            "Total dataset count :3200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VxfQxFQKeHyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f57fc5-538f-4dd7-c690-86d3be63d041"
      },
      "source": [
        "# 30번째 배치의 형태소코드셋 중 20번째꺼 확인\n",
        "print(dataset[30][1][20])\n",
        "print(dataset[31][1][20])"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 9 2 5 2 2 5 6 2 2 5 6 2 2 5 2 5 6 3 2 5 2 5 2 6 2 5 6 2 5 6 6 2 8 3 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[ 2  2  5  2  5  2  5  2  2  2  5  2  8  3  2  5  2  6  6  2  5  2  5  3\n",
            " 11  3 11  3 11  3 11  3 11  3 11  3 11  3  2  2  5  2  5  6  2  6  2  5\n",
            "  6  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlM5tdo1eHyL"
      },
      "source": [
        "# Generator 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jopXmV8DeHyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5a8b44-bb08-4327-9502-284e73ec3fa8"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([org_text])\n",
        "total_words = len(tokenizer.word_index)\n",
        "\n",
        "print(f'Total token count of origin text : {total_words}')"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total token count of origin text : 394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DT4gKRYeHyN"
      },
      "source": [
        "원문을 40개의 token 으로 구성된 문장으로 요약 하는것....<br>\n",
        "향후 LSTM으로 G 구성 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P_cpFugJeHyN"
      },
      "source": [
        "\n",
        "_MAX_GEN_TOKEN = 40\n",
        "_NOISE_DIM = total_words\n",
        "\n",
        "word_table = {}\n",
        "\n",
        "for word,index in tokenizer.word_index.items():\n",
        "    word_table[index-1] = word\n",
        "\n",
        "current_token_len = len(word_table)\n",
        "\n"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jg3YCjGJeHyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525de648-7cf7-46a1-d3ac-155b1c3294ea"
      },
      "source": [
        "print('Token table of origin text')\n",
        "print('---------------------------------------------')\n",
        "print(' Code         Token      ')\n",
        "print('')\n",
        "for k in word_table.keys():\n",
        "  print( f'  {str(k).ljust(8)}    {word_table[k]}')\n",
        "print('---------------------------------------------')\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token table of origin text\n",
            "---------------------------------------------\n",
            " Code         Token      \n",
            "\n",
            "  0           원내대표는\n",
            "  1           주\n",
            "  2           것\n",
            "  3           이라고\n",
            "  4           며\n",
            "  5           문재인\n",
            "  6           않는\n",
            "  7           문\n",
            "  8           이라며\n",
            "  9           이제\n",
            "  10          풀들이\n",
            "  11          수\n",
            "  12          대통령과\n",
            "  13          공수처는\n",
            "  14          될\n",
            "  15          있는\n",
            "  16          향해\n",
            "  17          보인다\n",
            "  18          짓밟힌\n",
            "  19          국민적\n",
            "  20          저항에\n",
            "  21          직면할\n",
            "  22          정권이\n",
            "  23          위해\n",
            "  24          공수처법을\n",
            "  25          제게\n",
            "  26          대통령은\n",
            "  27          '공수처는\n",
            "  28          없는\n",
            "  29          야당이\n",
            "  30          공수처장\n",
            "  31          사람들이\n",
            "  32          민주당\n",
            "  33          그러면서\n",
            "  34          공수처가\n",
            "  35          청와대와\n",
            "  36          왜\n",
            "  37          그\n",
            "  38          인정하지\n",
            "  39          이\n",
            "  40          공수처를\n",
            "  41          권력\n",
            "  42          게\n",
            "  43          정권의\n",
            "  44          민주당이\n",
            "  45          국회에서\n",
            "  46          그걸\n",
            "  47          권력은\n",
            "  48          먼저\n",
            "  49          주호영\n",
            "  50          국민의힘\n",
            "  51          22일\n",
            "  52          고위공직자범죄수사처\n",
            "  53          공수처\n",
            "  54          법\n",
            "  55          개정과\n",
            "  56          가덕도\n",
            "  57          신공항\n",
            "  58          건설\n",
            "  59          등을\n",
            "  60          밀어붙이고\n",
            "  61          정권과\n",
            "  62          더불어민주당을\n",
            "  63          끝이\n",
            "  64          아우성\n",
            "  65          치는\n",
            "  66          경고했다\n",
            "  67          이날\n",
            "  68          자신의\n",
            "  69          페이스북에\n",
            "  70          공수처법\n",
            "  71          개정을\n",
            "  72          위한\n",
            "  73          '군사작전'에\n",
            "  74          돌입하겠다고\n",
            "  75          엄포를\n",
            "  76          놓고\n",
            "  77          있다\n",
            "  78          정의당을\n",
            "  79          끌어들이기\n",
            "  80          꼼수\n",
            "  81          선거법에\n",
            "  82          묶어\n",
            "  83          '패스트트랙'이라는\n",
            "  84          불법·탈법으로\n",
            "  85          만들어낸\n",
            "  86          시행도\n",
            "  87          해보지\n",
            "  88          않고\n",
            "  89          고치려\n",
            "  90          하는\n",
            "  91          지적했다\n",
            "  92          이어\n",
            "  93          야당\n",
            "  94          원내대표인\n",
            "  95          사람\n",
            "  96          좋아보이는\n",
            "  97          표정으로\n",
            "  98          야당의\n",
            "  99          동의\n",
            "  100         없이는\n",
            "  101         절대\n",
            "  102         출범할\n",
            "  103         것'이라고\n",
            "  104         얘기했고\n",
            "  105         유엔\n",
            "  106         안보리\n",
            "  107         상임이사국처럼\n",
            "  108         임명에\n",
            "  109         '비토권'을\n",
            "  110         행사할\n",
            "  111         있는데\n",
            "  112         무얼\n",
            "  113         걱정하느냐고\n",
            "  114         여당\n",
            "  115         우리를\n",
            "  116         속였다\n",
            "  117         거짓말이라는\n",
            "  118         비난을\n",
            "  119         개의치\n",
            "  120         사람들\n",
            "  121         꼬집었다\n",
            "  122         이해찬\n",
            "  123         전\n",
            "  124         대표가\n",
            "  125         얘기한\n",
            "  126         '민주당\n",
            "  127         20년\n",
            "  128         집권'의\n",
            "  129         토대가\n",
            "  130         올해\n",
            "  131         안에\n",
            "  132         완성된다\n",
            "  133         탈원전과\n",
            "  134         동남권\n",
            "  135         신공항은\n",
            "  136         대통령이\n",
            "  137         대선\n",
            "  138         공약으로\n",
            "  139         내건\n",
            "  140         사업이니\n",
            "  141         여기에\n",
            "  142         불법이\n",
            "  143         있었다고\n",
            "  144         시비를\n",
            "  145         거는\n",
            "  146         것은\n",
            "  147         민주주의를\n",
            "  148         부정하는\n",
            "  149         것이라고\n",
            "  150         청와대\n",
            "  151         출신\n",
            "  152         윤건영\n",
            "  153         의원이\n",
            "  154         윽박지른다\n",
            "  155         '민주주의\n",
            "  156         민주당'이\n",
            "  157         법위에\n",
            "  158         군림하는\n",
            "  159         '반민주'를\n",
            "  160         거리낌없이\n",
            "  161         획책하는\n",
            "  162         언급했다\n",
            "  163         표를\n",
            "  164         얻기\n",
            "  165         나라\n",
            "  166         곳간을\n",
            "  167         다\n",
            "  168         허물어뜨렸고\n",
            "  169         재정\n",
            "  170         운용에서\n",
            "  171         신중함은\n",
            "  172         사라졌다\n",
            "  173         괴물\n",
            "  174         출범하면\n",
            "  175         공무원\n",
            "  176         누구나\n",
            "  177         권력이\n",
            "  178         지시하는\n",
            "  179         범죄행위에\n",
            "  180         거리낌\n",
            "  181         없이\n",
            "  182         가담할\n",
            "  183         것이다\n",
            "  184         권부\n",
            "  185         요직에\n",
            "  186         앉아\n",
            "  187         불법으로\n",
            "  188         각종\n",
            "  189         이권을\n",
            "  190         챙기는\n",
            "  191         권력자들에\n",
            "  192         대한\n",
            "  193         사건이\n",
            "  194         불거져도\n",
            "  195         사건을\n",
            "  196         가져가\n",
            "  197         버리면\n",
            "  198         그만\n",
            "  199         우려했다\n",
            "  200         고위\n",
            "  201         공직자들을\n",
            "  202         처벌하는\n",
            "  203         것인데\n",
            "  204         반대하는지\n",
            "  205         이해할\n",
            "  206         없다'고\n",
            "  207         했는데\n",
            "  208         그런\n",
            "  209         분이\n",
            "  210         대통령\n",
            "  211         주변을\n",
            "  212         감시하는\n",
            "  213         특별감찰관은\n",
            "  214         취임\n",
            "  215         이후\n",
            "  216         지금까지\n",
            "  217         임명하지\n",
            "  218         않았는가\n",
            "  219         라며\n",
            "  220         권력형\n",
            "  221         비리의\n",
            "  222         쓰레기\n",
            "  223         하치장\n",
            "  224         종말\n",
            "  225         처리장이\n",
            "  226         비판했다\n",
            "  227         정부를\n",
            "  228         사도들은\n",
            "  229         법치가\n",
            "  230         미치지\n",
            "  231         무오류의\n",
            "  232         화신이\n",
            "  233         오류를\n",
            "  234         존재가\n",
            "  235         바로\n",
            "  236         신이며\n",
            "  237         아래에는\n",
            "  238         자신들의\n",
            "  239         지도자를\n",
            "  240         목숨바쳐\n",
            "  241         지킴으로서\n",
            "  242         정의를\n",
            "  243         실현하겠다는\n",
            "  244         추종자들로\n",
            "  245         넘쳐\n",
            "  246         난다\n",
            "  247         지도자의\n",
            "  248         신성을\n",
            "  249         세력을\n",
            "  250         정죄하는\n",
            "  251         수단으로\n",
            "  252         전락할\n",
            "  253         질타했다\n",
            "  254         저도\n",
            "  255         법조인이지만\n",
            "  256         공수처장이\n",
            "  257         마음대로\n",
            "  258         검사들과\n",
            "  259         수사관들을\n",
            "  260         임명하는\n",
            "  261         끔찍한\n",
            "  262         사법기구가\n",
            "  263         어떤\n",
            "  264         일을\n",
            "  265         할지\n",
            "  266         두렵기만\n",
            "  267         하다\n",
            "  268         검찰과\n",
            "  269         경찰\n",
            "  270         위에\n",
            "  271         사법기구로\n",
            "  272         헌법과\n",
            "  273         법으로\n",
            "  274         독립성을\n",
            "  275         보장하는\n",
            "  276         검찰총장을\n",
            "  277         이렇게\n",
            "  278         핍박하는\n",
            "  279         어떻게\n",
            "  280         운영할지\n",
            "  281         불을\n",
            "  282         보듯\n",
            "  283         뻔한\n",
            "  284         일\n",
            "  285         예측했다\n",
            "  286         추미애\n",
            "  287         법무장관을\n",
            "  288         앞장\n",
            "  289         세워\n",
            "  290         윤석열\n",
            "  291         검찰의\n",
            "  292         비리\n",
            "  293         수사를\n",
            "  294         저지하려다가\n",
            "  295         난관에\n",
            "  296         봉착하자\n",
            "  297         무슨\n",
            "  298         수를\n",
            "  299         써서라도\n",
            "  300         출범시키려\n",
            "  301         한다\n",
            "  302         자리에는\n",
            "  303         추미애보다\n",
            "  304         더\n",
            "  305         한\n",
            "  306         막무가내\n",
            "  307         내\n",
            "  308         편을\n",
            "  309         앉힐\n",
            "  310         분명한\n",
            "  311         파렴치와\n",
            "  312         오만함을\n",
            "  313         최전선에서\n",
            "  314         온\n",
            "  315         몸으로\n",
            "  316         겪어온\n",
            "  317         저로서는\n",
            "  318         내일부터\n",
            "  319         보일\n",
            "  320         행태가\n",
            "  321         환히\n",
            "  322         180석의\n",
            "  323         또\n",
            "  324         군사작전을\n",
            "  325         개시하면\n",
            "  326         누가\n",
            "  327         막겠는가\n",
            "  328         라고\n",
            "  329         성토했다\n",
            "  330         막을\n",
            "  331         힘이\n",
            "  332         우리\n",
            "  333         야당에게는\n",
            "  334         없다\n",
            "  335         삭발하고\n",
            "  336         장외투쟁해\n",
            "  337         봐야\n",
            "  338         눈\n",
            "  339         하나\n",
            "  340         깜짝할\n",
            "  341         아닌\n",
            "  342         대란대치\n",
            "  343         大亂大治\n",
            "  344         세상을\n",
            "  345         온통\n",
            "  346         혼돈\n",
            "  347         속으로\n",
            "  348         밀어넣고\n",
            "  349         유지에\n",
            "  350         이용한다는\n",
            "  351         통치기술\n",
            "  352         규탄했다\n",
            "  353         아울러\n",
            "  354         바람\n",
            "  355         국민은\n",
            "  356         풀이다\n",
            "  357         바람이\n",
            "  358         불면\n",
            "  359         청보리\n",
            "  360         밭의\n",
            "  361         보리가\n",
            "  362         눕는다\n",
            "  363         다시는\n",
            "  364         일어서지\n",
            "  365         못하도록\n",
            "  366         풀을\n",
            "  367         짓밟지만\n",
            "  368         풀들은\n",
            "  369         다시\n",
            "  370         일어난다\n",
            "  371         시인\n",
            "  372         김수영은\n",
            "  373         '바람보다\n",
            "  374         눕지만\n",
            "  375         바람보다\n",
            "  376         일어나는'\n",
            "  377         민초의\n",
            "  378         힘을\n",
            "  379         노래했다\n",
            "  380         고\n",
            "  381         말했다\n",
            "  382         마지막으로\n",
            "  383         정권은\n",
            "  384         곧\n",
            "  385         광장에서\n",
            "  386         일어서서\n",
            "  387         아우성치는\n",
            "  388         모습을\n",
            "  389         지켜보게\n",
            "  390         대란대치를\n",
            "  391         끝장내려는\n",
            "  392         거듭\n",
            "  393         강조했다\n",
            "---------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bZgNu7SYeHyP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input,\n",
        "                                     Dense, \n",
        "                                     BatchNormalization, \n",
        "                                     LeakyReLU,\n",
        "                                     Softmax,\n",
        "                                     Reshape, \n",
        "                                     Conv2DTranspose,\n",
        "                                     Conv2D,\n",
        "                                     Dropout,\n",
        "                                     Flatten,\n",
        "                                     Concatenate,\n",
        "                                     Lambda)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Vj9qaaeHyQ"
      },
      "source": [
        "noise를 token_table을 통해 text로 변환하는 변환기 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cAv4SYIVyfL",
        "outputId": "8cf85ae7-3ba6-4424-bf39-ba8a3efe6932"
      },
      "source": [
        "\r\n",
        "b = tf.constant([1,2,3,4,5,6,11,8,9,10])\r\n",
        "c = tf.sort(b,axis=-1,direction='DESCENDING')\r\n",
        "wh = tf.where(tf.math.greater_equal(b,c[5-1]))[:5]\r\n",
        "wh"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[5],\n",
              "       [6],\n",
              "       [7],\n",
              "       [8],\n",
              "       [9]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "72FRz_bDeHyR"
      },
      "source": [
        "import sys\n",
        "\n",
        "def to_text(w):\n",
        "\n",
        "    #tf.print(w)\n",
        "    texts = []\n",
        "    try:\n",
        "        s_w = tf.sort(w,axis=-1,direction='DESCENDING')\n",
        "        #print(s_w)\n",
        "        for w_0r,s_w_0r in zip(w,s_w):\n",
        "            text = \"\"\n",
        "            wh = tf.where(tf.math.greater_equal(w_0r,s_w_0r[_MAX_GEN_TOKEN]))[:_MAX_GEN_TOKEN]\n",
        "\n",
        "            for k in tf.reshape(wh,(_MAX_GEN_TOKEN,)).numpy():\n",
        "                try:\n",
        "                    text += word_table[k]+' '\n",
        "                except Exception as ex:\n",
        "                    tf.print('to_text : word_table' + str(ex),k)\n",
        "                \n",
        "            texts.append(text)\n",
        "    except Exception as ex:\n",
        "        tf.print('to_text : ' + str(ex),sys.exc_info())\n",
        "\n",
        "    return tf.constant(texts,dtype=tf.string)"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ywMSg5noeHyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afaafef-2a41-496d-97c4-42034e2139fa"
      },
      "source": [
        "# to_text 함수의 test\n",
        "w = tf.random.normal([3,_NOISE_DIM])\n",
        "print(w.shape)\n",
        "e = to_text(w)\n",
        "for t in e:\n",
        "    print(t.numpy().decode('utf-8'))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 394)\n",
            "것 국민적 정권의 국회에서 공수처 등을 공수처법 개정을 돌입하겠다고 '패스트트랙'이라는 해보지 야당 것'이라고 비난을 꼬집었다 집권'의 동남권 군림하는 '반민주'를 곳간을 운용에서 것이다 요직에 사건이 불거져도 이해할 비리의 공수처장이 검사들과 임명하는 사법기구가 할지 경찰 이렇게 어떻게 환히 막을 밀어넣고 다시 정권은 \n",
            "풀들이 국민적 저항에 공수처법을 청와대와 국민의힘 더불어민주당을 개정을 야당 임명에 개의치 대표가 탈원전과 시비를 청와대 민주당'이 다 운용에서 없이 사건이 공직자들을 것인데 하치장 임명하는 예측했다 수사를 추미애보다 오만함을 또 야당에게는 삭발하고 장외투쟁해 하나 속으로 국민은 풀이다 바람이 밭의 바람보다 일어서서 \n",
            "왜 인정하지 권력 그걸 주호영 있다 야당 사람 좋아보이는 야당의 동의 상임이사국처럼 '비토권'을 우리를 탈원전과 대통령이 사업이니 거는 윤건영 언급했다 재정 괴물 가담할 분이 법치가 지도자를 목숨바쳐 정의를 정죄하는 저도 임명하는 두렵기만 검찰총장을 검찰의 비리 봉착하자 자리에는 내 온통 시인 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGwa9iaPeHyT"
      },
      "source": [
        "생성된 text의 embedding 변환기 구현<br>\n",
        "embedding은 org_text의 embedding과 비교하여 원문과 유사하게 민들기 위한 목적"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_D7qcRmQeHyX"
      },
      "source": [
        "# 이거 이틀걸림...잘 몰라서 ㅈㄴ 헤맴\n",
        "\n",
        "@tf.custom_gradient\n",
        "def to_embedding(w):\n",
        "\n",
        "    def grad(dy):\n",
        "        dy = tf.nn.batch_normalization(dy, 0, tf.math.reduce_std(dy), 0, 10, 1e-3)  # gradient 증폭 \n",
        "        dy_arr = tf.reshape(dy,(dy.shape[0],1024,1))\n",
        "        #tf.print(dy_arr)\n",
        "        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],w.shape[1]),method=tf.image.ResizeMethod.BILINEAR)\n",
        "        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],w.shape[1]))\n",
        "        return dy_arr_st\n",
        "\n",
        "    #print(w)    \n",
        "    texts = []\n",
        "    value = None\n",
        "    texts = []\n",
        "    try:\n",
        "        s_w = tf.sort(w,axis=-1,direction='DESCENDING')\n",
        "        #print(s_w)\n",
        "        for w_0r,s_w_0r in zip(w,s_w):\n",
        "            text = \"\"\n",
        "            wh = tf.where(tf.math.greater_equal(w_0r,s_w_0r[_MAX_GEN_TOKEN]))[:_MAX_GEN_TOKEN]\n",
        "            for k in tf.reshape(wh,(_MAX_GEN_TOKEN,)).numpy():\n",
        "                text += word_table[k]+' '\n",
        "                 \n",
        "            texts.append(text)                 \n",
        "        value = tf.constant(embedder.encode(texts,show_progress_bar=False),dtype=tf.float64)\n",
        "    except Exception as ex:\n",
        "        tf.print(ex,sys.exc_info())\n",
        "\n",
        "    return value, grad"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9Pu18GvweHyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637079fb-0859-46cb-8336-0b2aaa2ed381"
      },
      "source": [
        "# to_embedding 함수의 test\n",
        "e = to_embedding(w)\n",
        "for t in e:\n",
        "    print(t.numpy())"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.51557583 -0.23738354  0.65157902 ... -0.19659568 -0.01652551\n",
            " -0.03561371]\n",
            "[ 0.83412939 -0.24076766  0.43435761 ... -0.55511433  0.12052266\n",
            "  0.0986032 ]\n",
            "[ 0.77625871 -0.11476165  0.5568496  ... -0.33783042  0.0517711\n",
            " -0.4096759 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DWTe53wueHya"
      },
      "source": [
        "# to_compression_ratio\n",
        "\n",
        "@tf.custom_gradient\n",
        "def to_compression_ratio(w):\n",
        "    def grad(dy):\n",
        "        dy = tf.nn.batch_normalization(dy, 0, tf.math.reduce_std(dy), 0, 2, 1e-3)  # gradient 증폭, 이래도 되는 건지....\n",
        "        dy_arr = tf.reshape(dy,(dy.shape[0],1,1))\n",
        "        #tf.print(dy_arr)\n",
        "        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],w.shape[1]),method=tf.image.ResizeMethod.BILINEAR)\n",
        "        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],w.shape[1]))        \n",
        "        return dy_arr_st\n",
        "\n",
        "    const = tf.math.reduce_sum(tf.constant([x for x in range(tf.size(w[0]))],tf.int64)) \n",
        "    #print(const)\n",
        "    value = None\n",
        "    compression_ratio = [] #tf.Variable()\n",
        "    texts = []\n",
        "    try:\n",
        "        s_w = tf.sort(w,axis=-1,direction='DESCENDING')\n",
        "        #print(s_w)\n",
        "        for w_0r,s_w_0r in zip(w,s_w):\n",
        "            wh = tf.where(tf.math.greater_equal(w_0r,s_w_0r[_MAX_GEN_TOKEN]))[:_MAX_GEN_TOKEN]\n",
        "            cr = tf.math.reduce_sum(tf.reshape(wh,(_MAX_GEN_TOKEN,)))\n",
        "            compression_ratio.append(cr.numpy()/const.numpy())\n",
        "        #print(compression_ratio)\n",
        "        value = tf.constant(compression_ratio,dtype=tf.float64)\n",
        "    except Exception as ex:\n",
        "        tf.print(ex,sys.exc_info())\n",
        "\n",
        "    return value, grad\n",
        "    "
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rk25esbweHyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bba03b7-3138-4202-acf8-32694ba26814"
      },
      "source": [
        "# to_compression_ratio 함수의 test\n",
        "e = to_compression_ratio(w)\n",
        "for t in e:\n",
        "    print(t.numpy())"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09059557484403456\n",
            "0.10734813551878689\n",
            "0.09248136810426112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxlFMo3GeHyg"
      },
      "source": [
        "생성된 text의 morpheme code 변환기 구현<br>\n",
        "morpheme code는 한국어 문장들(dataset)의 morpheme code와 비교하여 한국어 문법에 가깝게 만들기 위한 목적"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yhOeXv93eHyh"
      },
      "source": [
        "\n",
        "@tf.custom_gradient\n",
        "def to_morpcoding(w):\n",
        "\n",
        "    def grad(dy):\n",
        "        dy = tf.nn.batch_normalization(dy, 0, tf.math.reduce_std(dy), 0, 2, 1e-3)  # gradient 증폭, 이래도 되는 건지....\n",
        "        dy_arr = tf.reshape(dy,(dy.shape[0],_MAX_MORP_LENGTH,1))\n",
        "        #tf.print(dy_arr)\n",
        "        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],w.shape[1]),method=tf.image.ResizeMethod.BILINEAR)\n",
        "        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],w.shape[1]))\n",
        "        return dy_arr_st\n",
        "\n",
        "    #print(w)    \n",
        "    codes = []\n",
        "    value = None\n",
        "    texts = []\n",
        "    try:\n",
        "        s_w = tf.sort(w,axis=-1,direction='DESCENDING')\n",
        "        #print(s_w)\n",
        "        for w_0r,s_w_0r in zip(w,s_w):\n",
        "            text = \"\"\n",
        "            wh = tf.where(tf.math.greater_equal(w_0r,s_w_0r[_MAX_GEN_TOKEN]))[:_MAX_GEN_TOKEN]\n",
        "            for k in tf.reshape(wh,(_MAX_GEN_TOKEN,)).numpy():\n",
        "                text += word_table[k]+' '\n",
        "                 \n",
        "            texts.append(text)    \n",
        "            \n",
        "        for sentence in texts:\n",
        "            code = morpheme_encode(sentence)\n",
        "            if len(code) <= _MAX_MORP_LENGTH:\n",
        "                codes.append(code + [_PADDING_CODE for i in range(_MAX_MORP_LENGTH-len(code))])\n",
        "            else:\n",
        "                codes.append(code[:_MAX_MORP_LENGTH])\n",
        "        value = tf.constant(codes,dtype=tf.int32)\n",
        "    except Exception as ex:\n",
        "        tf.print('to_morpcoding :' + str(ex),sys.exc_info())\n",
        "\n",
        "    return value, grad"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S-C_pxE5eHyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7339503-2b53-407d-de2c-5506b3284634"
      },
      "source": [
        "# to_morpcoding 함수의 test\n",
        "e = to_morpcoding(w)\n",
        "for t in e:\n",
        "    print(t.numpy())"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2  2  9  2  5  2  5  7  7  2  2  5  7  7  2  2  5  2  6  3  2  2  3  5\n",
            "  6  2  2  3  5  2  5  6  2  3  2  2  2  9  5  3  7  2  3  2  2  5  2  5\n",
            "  2  5  7  2  5  2  5  6  2  6  2  5  7  7  2  9  2  9  5  2  6  2  7  2\n",
            "  6  2 10  8  8  2  5  6  6  2  2  5  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n",
            "[ 2  9  5  2  9  2  5  7  7  2  5  2  5  2  5  2  6  2  5  2  5  2  2  5\n",
            "  2  2  2  5  2  2  5  2  5  2  2  3  2 10  2  5 10  2  5  2  9  5  2  5\n",
            "  2  9  2  6  2  6  2  5  2  5  8  2  2  5  2  5  2  2  2  2  2  5  2  5\n",
            "  2  5  2  5  2  5  2  5  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n",
            "[ 2  2  6  2 10  2  8  2  2  8  6  2  5  2  2  5  3  2  9  3  5  2  5  2\n",
            "  2  5  2  5  2  5  2  5  2  2  6  2  2  2  6  2  5  2  5  2  5  2  6  2\n",
            "  5  2  9  5  2  5  2  6  8  2  5  2  5  2  2  6  2  5  2  2  2  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLtq1YP_eHyj"
      },
      "source": [
        "Network 구성을 위해 사용자 정의 Layer 를 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "F9EfbbSreHyk"
      },
      "source": [
        "# 이것도 잘 몰라서 하루 걸림... ㅜㅜ\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "\n",
        "#tf.executing_eagerly()\n",
        "\n",
        "class Post_processing(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, encoder_func=None,Tout=tf.float64, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        self.encoder = encoder_func\n",
        "        self.Tout = Tout\n",
        "        super(Post_processing, self).__init__(**kwargs)\n",
        "    '''\n",
        "    def build(self, input_shape):\n",
        "        tf.print('build',input_shape)\n",
        "        # 이 레이어에 대해 학습가능한 가중치 변수를 만듭니다.\n",
        "        self.kernel = self.add_weight(name='kernel', \n",
        "                                      shape=(input_shape[1], self.output_dim),\n",
        "                                      initializer='uniform',\n",
        "                                      trainable=True)\n",
        "        super(Post_processing, self).build(input_shape)  # 끝에서 꼭 이 함수를 호출하십시오\n",
        "    '''\n",
        "    def call(self, input_data):\n",
        "        #tf.print('Post_processing : call input_data',input_data.shape)\n",
        "        value = tf.py_function(self.encoder,[input_data],Tout=self.Tout,name='encode_func')\n",
        "        #print('value.shape:',value.shape)\n",
        "        #value.set_shape((input_data.shape[0],self.output_dim))\n",
        "        if self.output_dim > 0:\n",
        "            value.set_shape((input_data.shape[0],self.output_dim))\n",
        "        else:\n",
        "            value.set_shape((input_data.shape[0],))\n",
        "        #return tf.reshape(value,[input_data.shape[0]])  \n",
        "\n",
        "        #value = tf.Variable((tf.zeros([input_data.shape[0],1024]) if self.Tout==tf.float64 else tf.zeros([input_data.shape[0],])),dtype=self.Tout,shape=( (input_data.shape[0],1024) if self.Tout==tf.float64 else (input_data.shape[0],)))\n",
        "        #tf.py_function(self.encoder,[input_data],Tout=self.Tout)\n",
        "        return value\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        tf.print('compute_output_shape:',input_shape)\n",
        "        input_shape = tensor_shape.TensorShape(input_shape).as_list()\n",
        "        if self.output_dim > 0:\n",
        "            return tensor_shape.TensorShape([input_shape[0], self.output_dim])\n",
        "        return tensor_shape.TensorShape([input_shape[0]])"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iT--4r5BeHyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9acf9f6f-d65f-48b4-dbc2-8e43aa206b40"
      },
      "source": [
        "# 구성한 Layer의 test\n",
        "e = Post_processing(1024,to_embedding,Tout=tf.float64)(w)\n",
        "for c in e:\n",
        "    print(c)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0.51557583 -0.23738354  0.65157902 ... -0.19659568 -0.01652551\n",
            " -0.03561371], shape=(1024,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ 0.83412939 -0.24076766  0.43435761 ... -0.55511433  0.12052266\n",
            "  0.0986032 ], shape=(1024,), dtype=float64)\n",
            "tf.Tensor(\n",
            "[ 0.77625871 -0.11476165  0.5568496  ... -0.33783042  0.0517711\n",
            " -0.4096759 ], shape=(1024,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X0RIQRZ4eHyl"
      },
      "source": [
        "# 별로 중요하지는 않지만 Lambda layer를 활용하기 위한 assert 함수 구성\n",
        "def assert_layer(input_data,out_dim=None):\n",
        "    #tf.print(input_data)\n",
        "    #print(input_data)\n",
        "    assert input_data.shape[1] == out_dim\n",
        "    return input_data"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VJazT7y-eHyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f53ab7-3e9e-4b93-a0c1-a95e55cd38db"
      },
      "source": [
        "# 드디어 generator 구현\n",
        "# 효과적으로 구성된 것인지는 모르겠음... 이것은 아직 많은 연구가 필요함.\n",
        "# 또한 LSTM으로 바꾸어 길이의 한게를 극복해야 할 것...\n",
        "\n",
        "def make_generator_model(org_words):\n",
        "    input = Input(shape=(org_words,), dtype='float64') \n",
        "    x1 = Dense(org_words*2, use_bias=False)(input)\n",
        "    #x1 = BatchNormalization()(x1)\n",
        "    x1 = LeakyReLU()(x1)\n",
        "    \n",
        "    x1 = Dense(org_words*4, use_bias=False)(x1)\n",
        "    #x1 = BatchNormalization()(x1)\n",
        "    x1 = LeakyReLU()(x1)\n",
        "    \n",
        "    #x1 = Dense(max_length*total_words, use_bias=False, activation='tanh')(x1)\n",
        "    x1 = Dense(org_words, use_bias=False)(x1)\n",
        "    x1 = Lambda(assert_layer,arguments={'out_dim':org_words})(x1)\n",
        "    #x1 = Reshape((max_length, total_words))(x1)\n",
        "    #x1 = BatchNormalization()(x1)\n",
        "    #x1 = Softmax()(x1)        \n",
        "    #x1 = MyCustomLayer(max_length*total_words)(x1)\n",
        "    txt = Post_processing(0,to_text,Tout=tf.string)(x1)\n",
        "    emb = Post_processing(1024,to_embedding,Tout=tf.float64)(x1)\n",
        "    cmr = Post_processing(0,to_compression_ratio,Tout=tf.float64)(x1)\n",
        "    cod = Post_processing(128,to_morpcoding,Tout=tf.int32)(x1)\n",
        "    \n",
        "    model = Model(input,[txt,emb,cmr,cod])\n",
        "    \n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model(_NOISE_DIM)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           [(None, 394)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 788)          310472      input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 788)          0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 1576)         1241888     leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 1576)         0           dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 394)          620944      leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 394)          0           dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "post_processing_40 (Post_proces (None,)              0           lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "post_processing_41 (Post_proces (None, 1024)         0           lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "post_processing_42 (Post_proces (None,)              0           lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "post_processing_43 (Post_proces (None, 128)          0           lambda_8[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,173,304\n",
            "Trainable params: 2,173,304\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sQya4kMheHym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9256674-7c7b-4b10-db81-48a0caeb4ee0"
      },
      "source": [
        "# generator의 test\n",
        "# Create a random noise and generate a sample\n",
        "noise = tf.random.normal([3,_NOISE_DIM])\n",
        "texts,embeddings,compratios,morpcodes = generator(noise, training=True)\n",
        "print(texts.shape)\n",
        "for i,txt in zip(range(len(texts)),texts):\n",
        "    print(f\" {i+1}> {txt.numpy().decode('utf-8')}\" )\n",
        "print(embeddings.shape)\n",
        "print(compratios.shape)\n",
        "print(morpcodes.shape)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,)\n",
            " 1> 이제 공수처는 '공수처는 사람들이 인정하지 위한 정의당을 끌어들이기 선거법에 만들어낸 사람 행사할 '민주당 내건 부정하는 것이라고 법위에 앉아 이권을 반대하는지 이후 쓰레기 자신들의 지킴으로서 넘쳐 공수처장이 사법기구가 불을 앞장 수를 내 행태가 장외투쟁해 눈 이용한다는 아울러 다시 일어난다 힘을 광장에서 \n",
            " 2> 보인다 인정하지 게 아우성 묶어 이어 원내대표인 사람 안보리 행사할 우리를 완성된다 탈원전과 시비를 출신 군림하는 재정 출범하면 권력이 챙기는 우려했다 분이 난다 신성을 수단으로 검사들과 임명하는 사법기구가 할지 검찰총장을 법무장관을 비리 저지하려다가 내 분명한 군사작전을 야당에게는 혼돈 바람이 일어서지 \n",
            " 3> 주 대통령은 '공수처는 정권의 22일 건설 아우성 돌입하겠다고 꼼수 만들어낸 있는데 걱정하느냐고 '민주당 20년 안에 내건 있었다고 거는 민주주의를 군림하는 '반민주'를 곳간을 사라졌다 공직자들을 라며 공수처장이 할지 앞장 세워 출범시키려 막무가내 행태가 힘이 하나 온통 혼돈 아울러 바람이 고 정권은 \n",
            "(3, 1024)\n",
            "(3,)\n",
            "(3, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41aWytGveHyo"
      },
      "source": [
        "# Discriminator 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtjQGj54eHyo"
      },
      "source": [
        "먼저 요약을 구분하기 위한 discriminator_summ 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fx3GgEXEeHyo"
      },
      "source": [
        "# 문장에 대한 embeddings를 이용하여 org_text_emb (org_text의 embedding)과의 유사도를 계산한다.\n",
        "import scipy\n",
        "\n",
        "@tf.custom_gradient\n",
        "def to_similarity(w):\n",
        "\n",
        "    def grad(dy):\n",
        "        dy = tf.nn.batch_normalization(dy, 0, tf.math.reduce_std(dy), 0, 10, 1e-3)  # gradient 증폭, 이래도 되는 건지....\n",
        "        dy_arr = tf.reshape(dy,(dy.shape[0],1,1))\n",
        "        #tf.print(dy_arr)\n",
        "        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],1024),method=tf.image.ResizeMethod.BILINEAR)\n",
        "        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],1024))\n",
        "        return dy_arr_st\n",
        "\n",
        "    similarities = []\n",
        "    value = None\n",
        "    try:\n",
        "        for embedding in w:\n",
        "            distances = scipy.spatial.distance.cdist([embedding], [org_text_emb], \"cosine\")[0]\n",
        "            similarities.append(distances[0])\n",
        "            \n",
        "        value = tf.constant(similarities,dtype=tf.float64)\n",
        "    except Exception as ex:\n",
        "        tf.print(ex,sys.exc_info())\n",
        "\n",
        "    return value, grad\n"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DNIQNvIveHyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a960a9-2c99-4925-8382-ae278a9167e3"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    input_emb = Input(shape=(1024,), dtype='float64') \n",
        "    x1 = Post_processing(0,to_similarity,Tout=tf.float64)(input_emb)\n",
        "    x1 = Reshape((1,))(x1)    \n",
        "    #x1 = Dense(1024*2)(input_emb)\n",
        "    #x1 = BatchNormalization()(x1)\n",
        "    #x1 = LeakyReLU()(x1)\n",
        "\n",
        "    \n",
        "    input_cmp = Input(shape=(), dtype='float64') \n",
        "    imput_mrp = Input(shape=(_MAX_MORP_LENGTH,), dtype='int32')\n",
        "\n",
        "    x2 = Reshape((1,))(input_cmp)\n",
        "    x3 = Dense(256)(imput_mrp)\n",
        "    #x3 = BatchNormalization()(x3)\n",
        "    x3 = LeakyReLU()(x3)\n",
        "\n",
        "    x3 = Dense(256*3)(x3)\n",
        "    #x3 = BatchNormalization()(x3)\n",
        "    x3 = LeakyReLU()(x3)\n",
        "\n",
        "    concatted = Concatenate(axis=1)([x1, x2, x3])\n",
        "    x4 = Flatten()(concatted)\n",
        "    x4 = Dense(64, use_bias=False)(x4)\n",
        "    #x4 = BatchNormalization()(x4)\n",
        "    x4 = LeakyReLU()(x4)\n",
        "    x4 = Dense(1)(x4)\n",
        "    \n",
        "    model = Model([input_emb,input_cmp,imput_mrp],x4)\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 256)          33024       input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 256)          0           dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "post_processing_44 (Post_proces (None,)              0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 768)          197376      leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 1)            0           post_processing_44[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 1)            0           input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, 768)          0           dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 770)          0           reshape_11[0][0]                 \n",
            "                                                                 reshape_12[0][0]                 \n",
            "                                                                 leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 770)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 64)           49280       flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, 64)           0           dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_55 (Dense)                (None, 1)            65          leaky_re_lu_39[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 279,745\n",
            "Trainable params: 279,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y7owqbg4eHyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3bdeb2-cde8-42da-89c3-064250e35f60"
      },
      "source": [
        "# discriminator test\n",
        "\n",
        "predict = discriminator([embeddings,compratios,morpcodes])\n",
        "print(predict)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.88418627]\n",
            " [-0.87208325]\n",
            " [-1.8090582 ]], shape=(3, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmvyPAVSeHyq"
      },
      "source": [
        "# GAN 을 이용한 loss 의 gradient 구현 --> 빡심"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ECEMH-yweHyr"
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cvBC5yS6eHys"
      },
      "source": [
        "# 디짐\n",
        "@tf.function\n",
        "def train_step(real_embedding,real_morpcoding):\n",
        "  \n",
        "    # 1 - Create a random noise to feed it into the model\n",
        "    # for the text generation\n",
        "    noise = tf.random.normal([BATCH_SIZE, _NOISE_DIM])\n",
        "    \n",
        "    # 2 - Generate text and calculate loss values\n",
        "    # GradientTape method records operations for automatic differentiation.\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        texts,embeddings,compratios,morpcodes = generator(noise, training=True)\n",
        "        #embeddings = generator(noise, training=True)\n",
        "        # real에 가까우려면 discriminator의 학습은 real_embedding 이 zero (0)에 가깝게 학습시켜야 함.\n",
        "        # 하지만 압축율의 개념으로는 본래는 ones (1)가 맞음.\n",
        "        real_output = discriminator([real_embedding,np.zeros(len(real_embedding)),real_morpcoding], training=True)\n",
        "        fake_output = discriminator([embeddings,compratios,morpcodes], training=True)\n",
        "\n",
        "        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        #tf.print('train_step : gen_loss=',gen_loss)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        #tf.print('train_step : disc_loss=',disc_loss)\n",
        "\n",
        "    # 3 - Calculate gradients using loss values and model variables\n",
        "    # \"gradient\" method computes the gradient using \n",
        "    # operations recorded in context of this tape (gen_tape and disc_tape).\n",
        "    \n",
        "    # It accepts a target (e.g., gen_loss) variable and \n",
        "    # a source variable (e.g.,generator.trainable_variables)\n",
        "    # target --> a list or nested structure of Tensors or Variables to be differentiated.\n",
        "    # source --> a list or nested structure of Tensors or Variables.\n",
        "    # target will be differentiated against elements in sources.\n",
        "\n",
        "    # \"gradient\" method returns a list or nested structure of Tensors  \n",
        "    # (or IndexedSlices, or None), one for each element in sources. \n",
        "    # Returned structure is the same as the structure of sources.\n",
        "    \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, \n",
        "                                                discriminator.trainable_variables)\n",
        "    #tf.print('train_step : gradients_of_discriminator=',gradients_of_discriminator)   \n",
        "    noise = tf.random.normal([BATCH_SIZE, _NOISE_DIM])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        texts,embeddings,compratios,morpcodes = generator(noise, training=True)\n",
        "        #embeddings = generator(noise, training=True)\n",
        "        #real_output = discriminator(real_embedding, training=True)\n",
        "        fake_output = discriminator([embeddings,compratios,morpcodes], training=True)\n",
        "\n",
        "        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        #tf.print('train_step : gen_loss=',gen_loss)\n",
        "        #disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        #tf.print('train_step : disc_loss=',disc_loss)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, \n",
        "                                               generator.trainable_variables)\n",
        "    #tf.print('train_step : gradients_of_generator=',gradients_of_generator)\n",
        " \n",
        "\n",
        "    # 4 - Process  Gradients and Run the Optimizer\n",
        "    # \"apply_gradients\" method processes aggregated gradients. \n",
        "    # ex: optimizer.apply_gradients(zip(grads, vars))\n",
        "    \"\"\"\n",
        "    Example use of apply_gradients:\n",
        "    grads = tape.gradient(loss, vars)\n",
        "    grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n",
        "    # Processing aggregated gradients.\n",
        "    optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)\n",
        "    \"\"\"\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    #tf.print('train_step : after discriminator_optimizer')    "
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cJs3lBpJeHys"
      },
      "source": [
        "EPOCHS = 5\n",
        "# 요약문 생성의 확인을 위해 10개의 문장을 생성하고 train과정에서 각 epoch마다 변화를 확인한다.\n",
        "seed = tf.random.normal([10, _NOISE_DIM])"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "os3b0psFeHyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9929bac7-50ba-43c2-e458-4eb466a78f0a"
      },
      "source": [
        "# 생성된 문장의 원문 유사도를 측정하기 위한 함수\n",
        "\n",
        "import scipy\n",
        "#print(doc_emb)\n",
        "def similarity_score(queries,org_embedding):\n",
        "\n",
        "    total_score = 0\n",
        "    query_embeddings = embedder.encode(queries,show_progress_bar=False)\n",
        "    for query, query_embedding in zip(queries, query_embeddings):\n",
        "        distances = scipy.spatial.distance.cdist([query_embedding], [org_embedding], \"cosine\")[0]\n",
        "        results = zip(range(len(distances)), distances)\n",
        "        for idx, distance in results:\n",
        "            total_score += 1-distance\n",
        "    return total_score\n",
        "\n",
        "queries = []\n",
        "\n",
        "texts,embeddings,compratios,morpcodes = generator(seed,training=False)\n",
        "\n",
        "#count = 0\n",
        "for t in texts:\n",
        "    summary_text = t.numpy().decode('utf-8')\n",
        "    queries.append(summary_text)\n",
        "print('Similarity score:',str(similarity_score(queries,org_text_emb)))\n"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity score: 6.459584664565794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cXrsOXX4eHyt"
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "    # pb = ProgressBar(total=20, prefix = 'Epoch 1')\n",
        "    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '█', printEnd = \"\\r\"):\n",
        "        self.total = total\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.decimals = decimals\n",
        "        self.length = length\n",
        "        self.fill = fill\n",
        "        self.printEnd = printEnd\n",
        "        self.ite = 0\n",
        "    # pb.printProgress(1,'~~~~')\n",
        "    def printProgress(self,iteration, text):\n",
        "        self.ite += iteration\n",
        "        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "\n",
        "        filledLength = int(self.length * self.ite // self.total)\n",
        "        bar = self.fill * filledLength + '-' * (self.length - filledLength)\n",
        "        print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "        # Print New Line on Complete\n",
        "        if self.ite == self.total: \n",
        "            print()"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dhqdaIATeHyu"
      },
      "source": [
        "import time\n",
        "from IPython import display # A command shell for interactive computing in Python.\n",
        "import re\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    print('Start with seed text.')\n",
        "    seed = tf.random.normal([10, _NOISE_DIM])\n",
        "    print('-------------------------------------------------------')\n",
        "    texts,embeddings,compratios,morpcodes = generator(seed,training=False)\n",
        "    for i,t in  zip(range(len(texts)),texts):\n",
        "        summary_text = t.numpy().decode('utf-8')\n",
        "        print(f'{i+1} > {summary_text}')        \n",
        "    print('-------------------------------------------------------')\n",
        "    print('')\n",
        "\n",
        "    # A. For each epoch, do the following:\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        pb = ProgressBar(total=BATCH_COUNT, prefix = f'Epoch:{str(epoch+1)}/{epochs}')\n",
        "        pb.printProgress(0,'Start batch.')\n",
        "        # 1 - For each batch of the epoch, \n",
        "        for batch_num,(emb_batch_set,cod_batch_set) in zip(range(len(dataset)),dataset):\n",
        "            # 1.a - run the custom \"train_step\" function\n",
        "            # we just declared above\n",
        "            #print(image_batch.shape)\n",
        "            train_step(emb_batch_set,cod_batch_set)\n",
        "            texts,embeddings,compratios,morpcodes = generator(seed,training=False)\n",
        "            pb.printProgress(+1,f\"Time for batch {batch_num + 1}/{BATCH_COUNT} is {int(time.time()-start)} sec, generated text:{texts[0].numpy().decode('utf-8')}\")\n",
        "        # 4 - Print out the completed epoch no. and the time spent\n",
        "        #print (f'Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "        #texts,embeddings,compratios,morpcodes = generator(seed,training=False)\n",
        "        count = 0\n",
        "        queries = []\n",
        "        texts,embeddings,compratios,morpcodes = generator(seed,training=False)\n",
        "        for i,t in  zip(range(len(texts)),texts):\n",
        "            summary_text = t.numpy().decode('utf-8')\n",
        "            print(f'{i+1} > {summary_text}')\n",
        "            queries.append(summary_text)\n",
        "            c = [m.start() for m in re.finditer(_MISMATCH_WORD, summary_text)]\n",
        "            count += len(c)\n",
        "        print(f'Mismatch count:{count} Similarity score:{str(similarity_score(queries,org_text_emb))}')\n",
        "        print('')"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCAedaSeT6A1",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da4f6122-25a8-44f2-f1d4-b4983e7adac9"
      },
      "source": [
        "if DO_ALL:\n",
        "    EPOCHS = 30\n",
        "    train(dataset, EPOCHS)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start with seed text.\n",
            "-------------------------------------------------------\n",
            "1 > 며 보인다 게 정권의 치는 공수처법 묶어 야당 사람 안보리 탈원전과 내건 것은 출신 군림하는 '반민주'를 출범하면 거리낌 권부 요직에 가져가 없다'고 감시하는 특별감찰관은 종말 정부를 넘쳐 난다 세력을 마음대로 운영할지 내 환히 아닌 혼돈 아울러 바람이 눕는다 아우성치는 끝장내려는 \n",
            "2 > 대통령과 야당이 인정하지 게 먼저 주호영 아우성 돌입하겠다고 놓고 만들어낸 있는데 완성된다 군림하는 '반민주'를 얻기 불법으로 이권을 했는데 분이 라며 권력형 수단으로 임명하는 할지 헌법과 운영할지 앞장 세워 저지하려다가 자리에는 내 앉힐 내일부터 행태가 라고 아닌 바람이 풀을 힘을 노래했다 \n",
            "3 > 그 인정하지 게 정권의 아우성 치는 정의당을 꼼수 동의 없이는 유엔 상임이사국처럼 여당 동남권 있었다고 것이라고 출신 언급했다 괴물 사건을 버리면 것인데 이후 임명하지 신성을 수단으로 임명하는 위에 일 앞장 세워 내 겪어온 환히 개시하면 라고 장외투쟁해 규탄했다 다시 정권은 \n",
            "4 > 대통령은 민주당이 건설 치는 위한 꼼수 불법·탈법으로 시행도 사람 없이는 얘기했고 상임이사국처럼 20년 대통령이 여기에 불법이 재정 괴물 범죄행위에 권부 사건을 공직자들을 처벌하는 분이 바로 넘쳐 수단으로 어떤 일을 경찰 앞장 세워 최전선에서 겪어온 라고 막을 속으로 이용한다는 정권은 지켜보게 \n",
            "5 > 공수처는 보인다 저항에 직면할 왜 인정하지 건설 아우성 공수처법 위한 끌어들이기 묶어 안보리 상임이사국처럼 '민주당 탈원전과 윽박지른다 군림하는 얻기 요직에 각종 이권을 우려했다 것인데 임명하지 하치장 존재가 난다 수단으로 검사들과 사법기구로 운영할지 막무가내 분명한 행태가 라고 규탄했다 눕지만 정권은 아우성치는 \n",
            "6 > 며 이제 공수처는 있는 저항에 민주당 민주당이 정권과 아우성 위한 고치려 사람 좋아보이는 야당의 행사할 완성된다 것은 민주주의를 출신 재정 괴물 권력이 지시하는 요직에 버리면 감시하는 지금까지 라며 하치장 수단으로 검사들과 경찰 예측했다 최전선에서 180석의 누가 라고 장외투쟁해 아울러 밭의 \n",
            "7 > 주 짓밟힌 위해 야당이 왜 건설 끝이 아우성 페이스북에 선거법에 고치려 사람 있는데 거짓말이라는 얘기한 있었다고 것이라고 출신 윽박지른다 획책하는 공무원 누구나 이권을 이후 임명하지 하치장 두렵기만 핍박하는 일 예측했다 법무장관을 수를 최전선에서 겪어온 하나 규탄했다 국민은 풀이다 힘을 광장에서 \n",
            "8 > 않는 공수처는 없는 그 인정하지 게 위한 끌어들이기 꼼수 만들어낸 하는 이어 얘기했고 여당 20년 집권'의 탈원전과 사업이니 '반민주'를 곳간을 다 출범하면 권부 앉아 공직자들을 없다'고 지도자의 마음대로 끔찍한 사법기구가 어떤 사법기구로 검찰총장을 앞장 라고 장외투쟁해 규탄했다 풀을 '바람보다 민초의 \n",
            "9 > 위해 왜 인정하지 게 위한 만들어낸 야당 사람 상임이사국처럼 민주주의를 윽박지른다 '반민주'를 얻기 권력이 것이다 권부 요직에 우려했다 비리의 실현하겠다는 추종자들로 넘쳐 세력을 검사들과 임명하는 경찰 예측했다 법무장관을 비리 수사를 무슨 분명한 보일 180석의 누가 라고 우리 아울러 풀이다 불면 \n",
            "10 > 며 위해 왜 아우성 치는 돌입하겠다고 꼼수 불법·탈법으로 얘기했고 안보리 상임이사국처럼 여당 우리를 이해찬 탈원전과 거는 민주주의를 출신 윽박지른다 언급했다 얻기 사건을 특별감찰관은 하치장 목숨바쳐 경찰 예측했다 법무장관을 내 분명한 최전선에서 겪어온 저로서는 개시하면 라고 힘이 大亂大治 불면 다시는 짓밟지만 \n",
            "-------------------------------------------------------\n",
            "\n",
            "Epoch:1/30 |████████████████████| 100.0%   Time for batch 50/50 is 261 sec, generated text:며 공수처는 보인다 대통령은 없는 건설 치는 만들어낸 사람 안보리 탈원전과 있었다고 거는 것은 군림하는 '반민주'를 요직에 앉아 버리면 했는데 특별감찰관은 임명하지 정부를 넘쳐 난다 일을 할지 운영할지 수를 내 행태가 개시하면 라고 세상을 아울러 눕는다 시인 정권은 아우성치는 모습을 \n",
            "1 > 며 공수처는 보인다 대통령은 없는 건설 치는 만들어낸 사람 안보리 탈원전과 있었다고 거는 것은 군림하는 '반민주'를 요직에 앉아 버리면 했는데 특별감찰관은 임명하지 정부를 넘쳐 난다 일을 할지 운영할지 수를 내 행태가 개시하면 라고 세상을 아울러 눕는다 시인 정권은 아우성치는 모습을 \n",
            "2 > 며 없는 왜 건설 아우성 개정을 만들어낸 있는데 사람들 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 없이 앉아 이권을 했는데 라며 수단으로 임명하는 일을 할지 운영할지 세워 수를 자리에는 내 행태가 또 라고 세상을 이용한다는 바람이 시인 '바람보다 고 정권은 \n",
            "3 > 저항에 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 상임이사국처럼 탈원전과 있었다고 거는 '반민주'를 언급했다 요직에 앉아 버리면 했는데 임명하지 라며 난다 수단으로 임명하는 일을 할지 운영할지 수를 내 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 광장에서 \n",
            "4 > 공수처는 대통령은 없는 건설 치는 정의당을 꼼수 불법·탈법으로 만들어낸 사람 20년 탈원전과 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 바로 넘쳐 난다 수단으로 일을 할지 사법기구로 운영할지 수를 내 행태가 개시하면 라고 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 모습을 \n",
            "5 > 공수처는 보인다 저항에 건설 아우성 개정을 정의당을 끌어들이기 사람 안보리 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 이권을 했는데 임명하지 하치장 난다 수단으로 할지 사법기구로 운영할지 뻔한 수를 분명한 행태가 개시하면 라고 성토했다 이용한다는 규탄했다 아울러 시인 고 정권은 \n",
            "6 > 며 공수처는 없는 건설 아우성 정의당을 꼼수 사람 완성된다 탈원전과 있었다고 출신 '반민주'를 괴물 요직에 앉아 버리면 했는데 감시하는 라며 하치장 난다 수단으로 일을 운영할지 수를 최전선에서 행태가 라고 장외투쟁해 세상을 온통 규탄했다 아울러 시인 민초의 정권은 광장에서 아우성치는 모습을 \n",
            "7 > 며 짓밟힌 저항에 위해 없는 왜 건설 아우성 페이스북에 사람 있는데 거짓말이라는 사람들 집권'의 있었다고 거는 '반민주'를 언급했다 얻기 범죄행위에 요직에 앉아 이권을 했는데 임명하지 하치장 난다 일을 할지 두렵기만 운영할지 예측했다 법무장관을 수를 행태가 막을 세상을 이용한다는 규탄했다 정권은 \n",
            "8 > 며 공수처는 없는 먼저 건설 치는 정의당을 끌어들이기 꼼수 만들어낸 하는 안보리 사람들 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 곳간을 앉아 했는데 지도자의 사법기구로 검찰총장을 운영할지 뻔한 앞장 수를 내 행태가 라고 장외투쟁해 세상을 온통 이용한다는 규탄했다 고 정권은 모습을 \n",
            "9 > 위해 없는 왜 건설 더불어민주당을 치는 꼼수 만들어낸 사람 상임이사국처럼 거는 것이라고 윽박지른다 '반민주'를 얻기 요직에 앉아 버리면 우려했다 했는데 비리의 실현하겠다는 넘쳐 난다 임명하는 일을 운영할지 법무장관을 수를 추미애보다 행태가 라고 온통 이용한다는 아울러 불면 시인 고 정권은 아우성치는 \n",
            "10 > 며 공수처는 없는 왜 아우성 치는 꼼수 상임이사국처럼 우리를 집권'의 탈원전과 있었다고 거는 '반민주'를 언급했다 범죄행위에 요직에 앉아 버리면 했는데 임명하지 난다 일을 할지 운영할지 법무장관을 수를 내 분명한 행태가 또 개시하면 세상을 이용한다는 불면 다시는 짓밟지만 시인 고 정권은 \n",
            "Mismatch count:0 Similarity score:6.1812540746294085\n",
            "\n",
            "Epoch:2/30 |████████████████████| 100.0%   Time for batch 50/50 is 253 sec, generated text:며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 추미애보다 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "1 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 추미애보다 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "2 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 있는데 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 수를 내 행태가 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "3 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 상임이사국처럼 탈원전과 있었다고 거는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 임명하는 일을 할지 운영할지 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "4 > 며 짓밟힌 대통령은 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 거는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 바로 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 행태가 개시하면 라고 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 \n",
            "5 > 며 짓밟힌 없는 왜 건설 아우성 치는 개정을 정의당을 끌어들이기 만들어낸 사람 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 임명하지 난다 수단으로 일을 할지 운영할지 뻔한 수를 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "6 > 며 공수처는 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 있었다고 거는 출신 군림하는 '반민주'를 요직에 앉아 버리면 했는데 라며 난다 수단으로 일을 할지 운영할지 수를 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 모습을 \n",
            "7 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 있는데 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "8 > 며 없는 왜 건설 아우성 치는 정의당을 끌어들이기 만들어낸 하는 사람들 집권'의 탈원전과 거는 군림하는 '반민주'를 요직에 앉아 했는데 수단으로 일을 할지 운영할지 뻔한 앞장 수를 추미애보다 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 모습을 \n",
            "9 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 상임이사국처럼 집권'의 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 넘쳐 난다 임명하는 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "10 > 며 짓밟힌 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 버리면 했는데 난다 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 불면 짓밟지만 시인 고 정권은 아우성치는 \n",
            "Mismatch count:0 Similarity score:5.994493169880897\n",
            "\n",
            "Epoch:3/30 |████████████████████| 100.0%   Time for batch 50/50 is 252 sec, generated text:며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "1 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "2 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 있는데 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "3 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "4 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 거는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "5 > 며 짓밟힌 없는 왜 건설 아우성 치는 개정을 정의당을 만들어낸 사람 유엔 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "6 > 며 공수처는 짓밟힌 없는 왜 건설 아우성 치는 정의당을 만들어낸 사람 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "7 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 있는데 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "8 > 며 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 사람들 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 수단으로 일을 할지 운영할지 뻔한 앞장 수를 추미애보다 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "9 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "10 > 며 짓밟힌 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 버리면 했는데 난다 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 불면 시인 고 정권은 아우성치는 \n",
            "Mismatch count:0 Similarity score:6.247691967799891\n",
            "\n",
            "Epoch:4/30 |████████████████████| 100.0%   Time for batch 50/50 is 253 sec, generated text:며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "1 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "2 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 유엔 있는데 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "3 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "4 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 유엔 탈원전과 거는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "5 > 며 짓밟힌 없는 왜 건설 아우성 치는 개정을 정의당을 만들어낸 사람 유엔 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "6 > 며 공수처는 짓밟힌 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 행태가 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "7 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 있는데 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "8 > 며 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 곳간을 요직에 앉아 했는데 수단으로 일을 할지 운영할지 뻔한 앞장 수를 추미애보다 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "9 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "10 > 며 짓밟힌 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "Mismatch count:0 Similarity score:6.189904803307685\n",
            "\n",
            "Epoch:5/30 |████████████████████| 100.0%   Time for batch 50/50 is 252 sec, generated text:며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "1 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "2 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 있는데 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "3 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "4 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 거는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 추미애보다 내 행태가 개시하면 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "5 > 며 짓밟힌 없는 왜 건설 아우성 치는 개정을 정의당을 만들어낸 사람 유엔 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "6 > 며 공수처는 짓밟힌 없는 왜 건설 아우성 치는 정의당을 만들어낸 사람 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 수를 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "7 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 있는데 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "8 > 며 없는 왜 건설 아우성 치는 정의당을 끌어들이기 만들어낸 하는 사람들 집권'의 탈원전과 거는 군림하는 '반민주'를 곳간을 요직에 앉아 했는데 수단으로 일을 할지 운영할지 뻔한 앞장 수를 추미애보다 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "9 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "10 > 며 짓밟힌 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 버리면 했는데 난다 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 불면 시인 고 정권은 아우성치는 \n",
            "Mismatch count:0 Similarity score:6.208574583831692\n",
            "\n",
            "Epoch:6/30 |████████████████████| 100.0%   Time for batch 50/50 is 253 sec, generated text:며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 추미애보다 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "1 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 유엔 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 추미애보다 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "2 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 있는데 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 수를 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "3 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 상임이사국처럼 탈원전과 있었다고 거는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 수단으로 임명하는 일을 할지 운영할지 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "4 > 며 짓밟힌 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 거는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 바로 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 행태가 개시하면 라고 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "5 > 며 공수처는 짓밟힌 없는 왜 건설 아우성 치는 개정을 정의당을 끌어들이기 만들어낸 사람 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 수를 행태가 개시하면 라고 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "6 > 며 공수처는 없는 왜 건설 아우성 치는 정의당을 꼼수 만들어낸 사람 탈원전과 있었다고 거는 출신 군림하는 '반민주'를 요직에 앉아 버리면 했는데 라며 난다 수단으로 일을 할지 운영할지 뻔한 수를 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 정권은 아우성치는 모습을 \n",
            "7 > 며 짓밟힌 없는 왜 건설 아우성 치는 만들어낸 사람 있는데 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 난다 수단으로 일을 할지 운영할지 뻔한 법무장관을 수를 내 행태가 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 아우성치는 \n",
            "8 > 며 없는 왜 건설 치는 정의당을 끌어들이기 꼼수 만들어낸 하는 사람들 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 곳간을 요직에 앉아 했는데 일을 할지 운영할지 뻔한 앞장 수를 추미애보다 내 행태가 라고 장외투쟁해 세상을 이용한다는 규탄했다 시인 고 정권은 아우성치는 모습을 \n",
            "9 > 며 짓밟힌 없는 왜 건설 아우성 치는 꼼수 만들어낸 사람 상임이사국처럼 거는 군림하는 '반민주'를 얻기 요직에 앉아 버리면 했는데 난다 임명하는 일을 할지 운영할지 뻔한 법무장관을 수를 추미애보다 내 행태가 라고 세상을 이용한다는 규탄했다 아울러 불면 시인 고 정권은 아우성치는 \n",
            "10 > 며 짓밟힌 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 집권'의 탈원전과 있었다고 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 버리면 했는데 난다 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 세상을 이용한다는 규탄했다 아울러 불면 짓밟지만 시인 고 정권은 아우성치는 \n",
            "Mismatch count:0 Similarity score:6.049046277750545\n",
            "\n",
            "Epoch:7/30 |████████████████████| 100.0%   Time for batch 50/50 is 253 sec, generated text:며 보인다 없는 건설 치는 만들어낸 야당 사람 안보리 탈원전과 있었다고 거는 것은 출신 군림하는 '반민주'를 얻기 요직에 앉아 버리면 특별감찰관은 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "1 > 며 보인다 없는 건설 치는 만들어낸 야당 사람 안보리 탈원전과 있었다고 거는 것은 출신 군림하는 '반민주'를 얻기 요직에 앉아 버리면 특별감찰관은 정부를 넘쳐 난다 수단으로 일을 할지 운영할지 수를 내 행태가 라고 막을 세상을 이용한다는 아울러 시인 정권은 아우성치는 모습을 \n",
            "2 > 며 없는 왜 건설 아우성 개정을 만들어낸 있는데 우리를 집권'의 탈원전과 거는 군림하는 '반민주'를 얻기 앉아 이권을 했는데 라며 난다 수단으로 임명하는 일을 할지 운영할지 뻔한 수를 내 행태가 라고 장외투쟁해 세상을 이용한다는 바람이 시인 '바람보다 고 정권은 아우성치는 모습을 \n",
            "3 > 짓밟힌 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 상임이사국처럼 탈원전과 있었다고 거는 '반민주'를 언급했다 얻기 요직에 앉아 버리면 했는데 임명하지 난다 수단으로 임명하는 일을 할지 운영할지 수를 내 행태가 개시하면 장외투쟁해 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 \n",
            "4 > 짓밟힌 대통령은 없는 왜 건설 치는 정의당을 꼼수 불법·탈법으로 만들어낸 사람 20년 탈원전과 '반민주'를 얻기 범죄행위에 요직에 앉아 했는데 바로 넘쳐 난다 수단으로 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 라고 막을 세상을 이용한다는 규탄했다 아울러 시인 고 정권은 \n",
            "5 > 공수처는 짓밟힌 저항에 왜 건설 아우성 치는 개정을 정의당을 끌어들이기 사람 안보리 탈원전과 거는 군림하는 '반민주'를 얻기 범죄행위에 요직에 앉아 이권을 했는데 임명하지 난다 수단으로 할지 사법기구로 운영할지 뻔한 수를 행태가 개시하면 라고 성토했다 이용한다는 규탄했다 아울러 시인 고 정권은 \n",
            "6 > 며 공수처는 없는 왜 건설 아우성 치는 정의당을 끌어들이기 꼼수 만들어낸 사람 탈원전과 있었다고 출신 '반민주'를 괴물 요직에 앉아 버리면 했는데 감시하는 라며 난다 수단으로 임명하는 일을 운영할지 수를 최전선에서 행태가 라고 장외투쟁해 세상을 규탄했다 아울러 시인 정권은 아우성치는 모습을 \n",
            "7 > 며 짓밟힌 위해 없는 왜 건설 아우성 치는 페이스북에 사람 있는데 집권'의 있었다고 거는 출신 '반민주'를 얻기 누구나 범죄행위에 요직에 앉아 했는데 임명하지 난다 수단으로 일을 할지 운영할지 법무장관을 수를 행태가 라고 막을 세상을 이용한다는 규탄했다 아울러 시인 정권은 아우성치는 \n",
            "8 > 공수처는 없는 왜 그 먼저 건설 치는 개정을 정의당을 끌어들이기 꼼수 만들어낸 하는 안보리 사람들 집권'의 탈원전과 거는 군림하는 '반민주'를 곳간을 앉아 없다'고 했는데 지도자의 검찰총장을 운영할지 뻔한 앞장 수를 내 행태가 라고 장외투쟁해 세상을 온통 이용한다는 규탄했다 고 정권은 \n",
            "9 > 며 없는 왜 건설 아우성 치는 끌어들이기 꼼수 만들어낸 사람 상임이사국처럼 거는 윽박지른다 '반민주'를 얻기 요직에 앉아 우려했다 했는데 비리의 난다 임명하는 일을 운영할지 법무장관을 수를 추미애보다 행태가 라고 세상을 온통 이용한다는 규탄했다 아울러 불면 시인 고 정권은 아우성치는 모습을 \n",
            "10 > 며 없는 왜 아우성 치는 꼼수 만들어낸 상임이사국처럼 우리를 '민주당 집권'의 탈원전과 있었다고 거는 '반민주'를 언급했다 범죄행위에 요직에 앉아 버리면 했는데 임명하지 난다 일을 할지 운영할지 법무장관을 수를 내 행태가 개시하면 라고 세상을 이용한다는 규탄했다 불면 짓밟지만 시인 고 정권은 \n",
            "Mismatch count:0 Similarity score:6.271480457183259\n",
            "\n",
            "Epoch:8/30 |████████████████████| 100.0%   Time for batch 50/50 is 261 sec, generated text:주 며 풀들이 없는 치는 공수처법 만들어낸 야당 사람 안보리 '민주당 불법이 것은 출신 군림하는 '반민주'를 얻기 출범하면 거리낌 요직에 가져가 우려했다 없다'고 특별감찰관은 종말 정부를 난다 공수처장이 어떤 일을 운영할지 환히 누가 라고 장외투쟁해 봐야 세상을 이용한다는 아울러 지켜보게 \n",
            "1 > 주 며 풀들이 없는 치는 공수처법 만들어낸 야당 사람 안보리 '민주당 불법이 것은 출신 군림하는 '반민주'를 얻기 출범하면 거리낌 요직에 가져가 우려했다 없다'고 특별감찰관은 종말 정부를 난다 공수처장이 어떤 일을 운영할지 환히 누가 라고 장외투쟁해 봐야 세상을 이용한다는 아울러 지켜보게 \n",
            "2 > 야당이 왜 인정하지 게 아우성 만들어낸 야당 있는데 '민주당 20년 것은 출신 군림하는 '반민주'를 얻기 누구나 이권을 했는데 분이 이후 권력형 수단으로 임명하는 위에 운영할지 세워 저지하려다가 내 앉힐 행태가 라고 우리 장외투쟁해 세상을 이용한다는 아울러 바람이 풀을 다시 힘을 \n",
            "3 > 저항에 왜 민주당이 아우성 치는 끌어들이기 꼼수 만들어낸 하는 야당 것'이라고 유엔 여당 '민주당 동남권 출신 언급했다 얻기 출범하면 요직에 이권을 사건을 우려했다 이후 임명하지 법치가 난다 수단으로 임명하는 위에 법무장관을 세워 내 환히 라고 장외투쟁해 세상을 이용한다는 아울러 다시 \n",
            "4 > 왜 민주당이 건설 치는 꼼수 '패스트트랙'이라는 불법·탈법으로 만들어낸 시행도 사람 것'이라고 20년 출신 언급했다 얻기 괴물 출범하면 범죄행위에 요직에 사건을 공직자들을 바로 수단으로 임명하는 어떤 일을 경찰 위에 세워 행태가 환히 라고 막을 우리 세상을 이용한다는 아울러 풀을 모습을 지켜보게 \n",
            "5 > 저항에 직면할 왜 인정하지 건설 아우성 공수처법 끌어들이기 '패스트트랙'이라는 안보리 '민주당 언급했다 얻기 출범하면 누구나 범죄행위에 요직에 이권을 우려했다 했는데 이후 임명하지 하치장 종말 법치가 난다 수단으로 검사들과 사법기구로 운영할지 수를 막무가내 분명한 행태가 라고 장외투쟁해 이용한다는 규탄했다 아울러 힘을 \n",
            "6 > 며 공수처는 향해 저항에 왜 민주당이 아우성 공수처법 사람 것'이라고 '민주당 완성된다 것은 출신 재정 괴물 출범하면 권력이 요직에 감시하는 이후 하치장 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 경찰 위에 운영할지 최전선에서 행태가 누가 라고 장외투쟁해 세상을 아울러 민초의 \n",
            "7 > 주 왜 건설 아우성 페이스북에 공수처법 선거법에 사람 것'이라고 있는데 얘기한 '민주당 출신 언급했다 얻기 출범하면 누구나 권력이 요직에 이권을 이후 임명하지 종말 난다 임명하는 일을 운영할지 법무장관을 수를 최전선에서 행태가 라고 우리 세상을 이용한다는 규탄했다 아울러 풀을 힘을 광장에서 \n",
            "8 > 않는 없는 왜 그 민주당이 치는 위한 끌어들이기 만들어낸 하는 것'이라고 얘기했고 안보리 집권'의 불법이 '반민주'를 언급했다 다 출범하면 앉아 챙기는 사건을 공직자들을 없다'고 했는데 법치가 지도자의 임명하는 어떤 사법기구로 앞장 라고 우리 장외투쟁해 세상을 이용한다는 풀을 '바람보다 고 지켜보게 \n",
            "9 > 없는 왜 건설 아우성 만들어낸 야당 사람 있는데 동남권 출신 윽박지른다 '반민주'를 언급했다 얻기 출범하면 권력이 것이다 권부 요직에 우려했다 했는데 이후 비리의 법치가 난다 검사들과 임명하는 일을 경찰 위에 예측했다 법무장관을 보일 행태가 누가 라고 우리 이용한다는 아울러 불면 \n",
            "10 > 며 왜 아우성 치는 돌입하겠다고 꼼수 불법·탈법으로 만들어낸 것'이라고 안보리 상임이사국처럼 여당 우리를 '민주당 동남권 출신 언급했다 얻기 요직에 사건을 이후 임명하지 존재가 난다 임명하는 일을 경찰 법무장관을 내 분명한 최전선에서 행태가 환히 라고 힘이 세상을 이용한다는 아울러 불면 모습을 \n",
            "Mismatch count:0 Similarity score:5.625461054108941\n",
            "\n",
            "Epoch:9/30 |████████████████████| 100.0%   Time for batch 50/50 is 265 sec, generated text:원내대표는 주 왜 고위공직자범죄수사처 치는 공수처법 선거법에 야당 사람 여당 '민주당 올해 공약으로 불법이 출신 언급했다 얻기 재정 출범하면 요직에 우려했다 이후 종말 정부를 자신들의 임명하는 어떤 일을 위에 최전선에서 보일 환히 누가 라고 힘이 장외투쟁해 봐야 이용한다는 아울러 힘을 \n",
            "1 > 원내대표는 주 왜 고위공직자범죄수사처 치는 공수처법 선거법에 야당 사람 여당 '민주당 올해 공약으로 불법이 출신 언급했다 얻기 재정 출범하면 요직에 우려했다 이후 종말 정부를 자신들의 임명하는 어떤 일을 위에 최전선에서 보일 환히 누가 라고 힘이 장외투쟁해 봐야 이용한다는 아울러 힘을 \n",
            "2 > 주 왜 게 정권과 돌입하겠다고 선거법에 만들어낸 야당 속였다 얘기한 '민주당 올해 공약으로 불법이 출신 언급했다 얻기 출범하면 누구나 우려했다 공직자들을 이후 종말 자신들의 검사들과 임명하는 어떤 위에 세워 저지하려다가 앉힐 최전선에서 행태가 라고 우리 장외투쟁해 이용한다는 아울러 다시 힘을 \n",
            "3 > 주 저항에 왜 고위공직자범죄수사처 아우성 치는 선거법에 하는 야당 것'이라고 여당 얘기한 '민주당 올해 공약으로 불법이 부정하는 출신 언급했다 얻기 출범하면 요직에 사건을 우려했다 공직자들을 이후 검사들과 임명하는 어떤 위에 세워 최전선에서 보일 환히 라고 우리 장외투쟁해 이용한다는 아울러 다시 \n",
            "4 > 주 왜 민주당이 고위공직자범죄수사처 치는 공수처법 선거법에 불법·탈법으로 시행도 사람 것'이라고 속였다 얘기한 '민주당 올해 불법이 부정하는 출신 언급했다 얻기 재정 출범하면 우려했다 공직자들을 이후 자신들의 검사들과 임명하는 어떤 일을 위에 세워 최전선에서 환히 라고 우리 장외투쟁해 이용한다는 아울러 풀을 \n",
            "5 > 주 저항에 왜 고위공직자범죄수사처 정권과 공수처법 돌입하겠다고 선거법에 것'이라고 얘기한 '민주당 올해 불법이 부정하는 출신 언급했다 얻기 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 법치가 자신들의 난다 검사들과 임명하는 어떤 위에 최전선에서 보일 행태가 라고 우리 장외투쟁해 유지에 이용한다는 아울러 \n",
            "6 > 주 저항에 왜 민주당이 고위공직자범죄수사처 정권과 공수처법 돌입하겠다고 선거법에 야당 사람 것'이라고 속였다 '민주당 올해 불법이 부정하는 출신 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 검사들과 임명하는 어떤 위에 최전선에서 보일 누가 라고 장외투쟁해 하나 아울러 바람 광장에서 \n",
            "7 > 주 저항에 왜 고위공직자범죄수사처 정권과 공수처법 돌입하겠다고 선거법에 사람 것'이라고 속였다 얘기한 '민주당 올해 불법이 부정하는 출신 언급했다 얻기 출범하면 누구나 요직에 공직자들을 이후 종말 자신들의 임명하는 어떤 일을 위에 최전선에서 보일 환히 라고 우리 하나 이용한다는 아울러 힘을 광장에서 \n",
            "8 > 원내대표는 주 않는 왜 게 민주당이 고위공직자범죄수사처 정권과 치는 선거법에 만들어낸 하는 야당 것'이라고 여당 '민주당 올해 공약으로 불법이 부정하는 출신 언급했다 얻기 출범하면 우려했다 공직자들을 없다'고 분이 이후 임명하는 어떤 위에 앞장 최전선에서 라고 힘이 우리 장외투쟁해 이용한다는 풀을 \n",
            "9 > 주 왜 고위공직자범죄수사처 정권과 돌입하겠다고 선거법에 만들어낸 야당 사람 속였다 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 것이다 요직에 우려했다 공직자들을 이후 검사들과 임명하는 어떤 일을 위에 세워 최전선에서 보일 환히 누가 라고 우리 이용한다는 아울러 \n",
            "10 > 주 왜 고위공직자범죄수사처 정권과 치는 공수처법 돌입하겠다고 선거법에 불법·탈법으로 것'이라고 상임이사국처럼 여당 얘기한 '민주당 올해 공약으로 불법이 부정하는 출신 언급했다 얻기 출범하면 요직에 사건을 공직자들을 이후 검사들과 임명하는 어떤 위에 세워 최전선에서 환히 라고 힘이 우리 장외투쟁해 이용한다는 아울러 불면 \n",
            "Mismatch count:0 Similarity score:6.461784962156357\n",
            "\n",
            "Epoch:10/30 |████████████████████| 100.0%   Time for batch 50/50 is 523 sec, generated text:주 왜 정권과 치는 선거법에 하는 야당 사람 얘기한 '민주당 올해 공약으로 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 요직에 우려했다 공직자들을 이후 종말 자신들의 난다 수단으로 임명하는 어떤 일을 위에 앞장 세워 최전선에서 보일 라고 장외투쟁해 이용한다는 아울러 \n",
            "1 > 주 왜 정권과 치는 선거법에 하는 야당 사람 얘기한 '민주당 올해 공약으로 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 요직에 우려했다 공직자들을 이후 종말 자신들의 난다 수단으로 임명하는 어떤 일을 위에 앞장 세워 최전선에서 보일 라고 장외투쟁해 이용한다는 아울러 \n",
            "2 > 주 저항에 왜 정권과 치는 돌입하겠다고 선거법에 하는 야당 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 우려했다 공직자들을 이후 종말 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 라고 장외투쟁해 이용한다는 아울러 광장에서 \n",
            "3 > 주 저항에 왜 정권과 치는 선거법에 하는 야당 여당 얘기한 '민주당 올해 불법이 부정하는 출신 언급했다 얻기 재정 출범하면 것이다 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 보일 라고 장외투쟁해 이용한다는 아울러 풀들은 광장에서 \n",
            "4 > 주 왜 민주당이 정권과 치는 선거법에 불법·탈법으로 하는 사람 속였다 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 우려했다 공직자들을 이후 자신들의 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 라고 우리 이용한다는 아울러 고 \n",
            "5 > 주 저항에 왜 정권과 치는 공수처법 돌입하겠다고 선거법에 하는 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 보일 라고 이용한다는 아울러 광장에서 \n",
            "6 > 주 저항에 왜 고위공직자범죄수사처 정권과 치는 선거법에 하는 사람 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 요직에 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 보일 라고 장외투쟁해 이용한다는 아울러 바람 광장에서 \n",
            "7 > 주 저항에 왜 고위공직자범죄수사처 정권과 치는 선거법에 하는 사람 속였다 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 보일 라고 이용한다는 아울러 광장에서 \n",
            "8 > 주 왜 민주당이 정권과 치는 선거법에 하는 야당 얘기한 올해 공약으로 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 위에 앞장 세워 최전선에서 라고 우리 장외투쟁해 이용한다는 아울러 풀들은 고 광장에서 \n",
            "9 > 주 왜 정권과 치는 선거법에 하는 야당 얘기한 '민주당 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 것이다 요직에 우려했다 공직자들을 이후 종말 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 보일 라고 우리 이용한다는 아울러 광장에서 \n",
            "10 > 주 왜 정권과 치는 돌입하겠다고 선거법에 하는 여당 얘기한 '민주당 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 요직에 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 라고 장외투쟁해 이용한다는 아울러 풀들은 고 광장에서 \n",
            "Mismatch count:0 Similarity score:6.817936172354297\n",
            "\n",
            "Epoch:11/30 |████████████████████| 100.0%   Time for batch 50/50 is 240 sec, generated text:주 며 저항에 왜 정권과 치는 선거법에 하는 야당 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 라고 봐야 세상을 이용한다는 아울러 풀들은 \n",
            "1 > 주 며 저항에 왜 정권과 치는 선거법에 하는 야당 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 라고 봐야 세상을 이용한다는 아울러 풀들은 \n",
            "2 > 주 저항에 왜 정권과 치는 선거법에 하는 야당 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 라고 세상을 이용한다는 아울러 풀들은 광장에서 \n",
            "3 > 주 저항에 왜 정권과 치는 선거법에 하는 야당 상임이사국처럼 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 것이다 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 라고 장외투쟁해 세상을 이용한다는 아울러 풀들은 광장에서 \n",
            "4 > 주 저항에 왜 정권과 치는 선거법에 하는 상임이사국처럼 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 세워 최전선에서 라고 세상을 이용한다는 아울러 풀들은 고 광장에서 \n",
            "5 > 주 저항에 왜 정권과 치는 선거법에 하는 상임이사국처럼 얘기한 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 이용한다는 아울러 풀들은 광장에서 \n",
            "6 > 주 저항에 왜 정권과 치는 선거법에 하는 야당 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 요직에 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 라고 세상을 이용한다는 아울러 풀들은 광장에서 \n",
            "7 > 주 저항에 왜 정권과 치는 선거법에 하는 상임이사국처럼 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 라고 세상을 이용한다는 아울러 풀들은 광장에서 \n",
            "8 > 주 왜 민주당이 정권과 치는 선거법에 하는 야당 상임이사국처럼 얘기한 올해 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 것이다 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 라고 세상을 이용한다는 아울러 풀들은 고 광장에서 \n",
            "9 > 주 저항에 왜 정권과 치는 선거법에 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 것이라고 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 보일 라고 세상을 이용한다는 아울러 풀들은 광장에서 \n",
            "10 > 주 저항에 왜 정권과 치는 선거법에 하는 상임이사국처럼 얘기한 올해 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 것이다 요직에 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 라고 세상을 이용한다는 아울러 풀들은 고 광장에서 \n",
            "Mismatch count:0 Similarity score:7.21908588952865\n",
            "\n",
            "Epoch:12/30 |████████████████████| 100.0%   Time for batch 50/50 is 247 sec, generated text:주 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 \n",
            "1 > 주 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 \n",
            "2 > 저항에 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 걱정하느냐고 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "3 > 주 저항에 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 걱정하느냐고 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 세상을 이용한다는 아울러 광장에서 \n",
            "4 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "5 > 공수처는 저항에 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "6 > 공수처는 저항에 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "7 > 주 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 걱정하느냐고 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "8 > 주 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "9 > 주 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 걱정하느냐고 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 세상을 이용한다는 아울러 고 광장에서 \n",
            "10 > 주 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "Mismatch count:0 Similarity score:6.668233971870803\n",
            "\n",
            "Epoch:13/30 |████████████████████| 100.0%   Time for batch 50/50 is 251 sec, generated text:며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "1 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 종말 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "2 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "3 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "4 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "5 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "6 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "7 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "8 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "9 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 우려했다 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "10 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "Mismatch count:0 Similarity score:6.231131213361058\n",
            "\n",
            "Epoch:14/30 |████████████████████| 100.0%   Time for batch 50/50 is 247 sec, generated text:며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 행태가 라고 막을 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "1 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 행태가 라고 막을 봐야 세상을 이용한다는 아울러 광장에서 \n",
            "2 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "3 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "4 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 막을 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "5 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "6 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "7 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 공직자들을 이후 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "8 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "9 > 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 동남권 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 검사들과 임명하는 어떤 일을 위에 앞장 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "10 > 며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 최전선에서 행태가 라고 봐야 세상을 이용한다는 아울러 고 광장에서 \n",
            "Mismatch count:0 Similarity score:5.698861441033477\n",
            "\n",
            "Epoch:15/30 |██████--------------| 32.0%   Time for batch 16/50 is 80 sec, generated text:며 공수처는 왜 정권과 치는 선거법에 만들어낸 하는 야당 상임이사국처럼 얘기한 불법이 부정하는 출신 윽박지른다 언급했다 얻기 재정 출범하면 누구나 요직에 공직자들을 이후 종말 법치가 난다 수단으로 임명하는 어떤 일을 위에 앞장 행태가 라고 막을 봐야 세상을 이용한다는 아울러 광장에서 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-228-8a3811f0ae15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDO_ALL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-225-b91b429fa6db>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# we just declared above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#print(image_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_batch_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcod_batch_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompratios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmorpcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"Time for batch {batch_num + 1}/{BATCH_COUNT} is {int(time.time()-start)} sec, generated text:{texts[0].numpy().decode('utf-8')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}