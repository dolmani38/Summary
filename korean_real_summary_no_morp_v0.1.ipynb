{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Korean Summarizer Using Multiple Discriminators**\n\n참조 : https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n\n참조 : https://github.com/williamSYSU/TextGAN-PyTorch"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install sentence-transformers==0.3.0\n!pip install transformers==3.0.2\n!pip install wikipedia\n!pip install konlpy","execution_count":5,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: sentence-transformers==0.3.0 in /opt/conda/lib/python3.7/site-packages (0.3.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (3.2.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (0.23.2)\nRequirement already satisfied: transformers>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (3.0.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nRequirement already satisfied: torch>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.7.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (2.1.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.4.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (0.14.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (3.7.4.1)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.0.1->sentence-transformers==0.3.0) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (1.18.5)\nRequirement already satisfied: tokenizers==0.8.1.rc1 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.8.1rc1)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.1.91)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (0.0.43)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2020.4.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2.23.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.0) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.0) (2020.12.5)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers==0.3.0) (0.14.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers==0.3.0) (1.14.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=3.0.2->sentence-transformers==0.3.0) (2020.4.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers==0.3.0) (4.45.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.0) (7.1.1)\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: transformers==3.0.2 in /opt/conda/lib/python3.7/site-packages (3.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2.23.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.45.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.0.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.0.43)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (20.1)\nRequirement already satisfied: tokenizers==0.8.1.rc1 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.8.1rc1)\nRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.91)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (1.18.5)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (1.14.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.25.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.0.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2020.4.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (7.1.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (0.14.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.45.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==3.0.2) (1.14.0)\n","name":"stdout"},{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: wikipedia in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wikipedia) (2.23.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from wikipedia) (4.6.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.9)\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: konlpy in /opt/conda/lib/python3.7/site-packages (0.5.2)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from konlpy) (0.4.3)\nRequirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (3.9.0)\nRequirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.0)\nRequirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.2.0)\nRequirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.18.5)\nRequirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.5.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.2.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.14.0)\nRequirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\nRequirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (2.23.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.0.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (2020.12.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (2020.12.5)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keras module for building LSTM \nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom tensorflow.python.framework import tensor_shape\nimport keras.utils as ku \n\n# set seeds for reproducability\nfrom tensorflow.random import set_seed\nfrom numpy.random import seed\nset_seed(2)\nseed(1)\n\nimport pandas as pd\nimport numpy as np\nimport string, os \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 학습을 위한 데이터 준비"},{"metadata":{},"cell_type":"markdown","source":"네이버 뉴스에서 아무거나 하나 Text를 얻어옴\n\n이것을 '요약' 목표"},{"metadata":{"trusted":true},"cell_type":"code","source":"org_text = \"\"\"\n주호영 국민의힘 원내대표는 22일 고위공직자범죄수사처(공수처)법 개정과 가덕도 신공항 건설 등을 밀어붙이고 있는 문재인 정권과 더불어민주당을 향해 \"이제 끝이 보인다\"며 \"짓밟힌 풀들이 아우성 치는 국민적 저항에 직면할 것\"이라고 경고했다.\n주 원내대표는 이날 자신의 페이스북에 \"문재인 정권이 공수처법 개정을 위한 '군사작전'에 돌입하겠다고 엄포를 놓고 있다\"며 \"정의당을 끌어들이기 위해 꼼수 선거법에 묶어 '패스트트랙'이라는 불법·탈법으로 만들어낸 공수처법을 시행도 해보지 않고 고치려 하는 것\"이라고 지적했다.\n이어 주 원내대표는 \"야당 원내대표인 제게 문재인 대통령은 사람 좋아보이는 표정으로 '공수처는 야당의 동의 없이는 절대 출범할 수 없는 것'이라고 얘기했고, 야당이 유엔 안보리 상임이사국처럼 공수처장 임명에 '비토권'을 행사할 수 있는데 무얼 걱정하느냐고, 여당 사람들이 우리를 속였다\"며 \"거짓말이라는 비난을 개의치 않는 사람들\"이라고 꼬집었다.\n주 원내대표는 \"이해찬 전 민주당 대표가 얘기한 '민주당 20년 집권'의 토대가 올해 안에 완성된다\"며 \"탈원전과 동남권 신공항은 문 대통령이 대선 공약으로 내건 사업이니 여기에 불법이 있었다고 시비를 거는 것은 민주주의를 부정하는 것이라고 청와대 출신 윤건영 민주당 의원이 윽박지른다. 이제 '민주주의 없는 민주당'이 법위에 군림하는 '반민주'를 거리낌없이 획책하는 것\"이라고 언급했다.\n그러면서 주 원내대표는 \"표를 얻기 위해 나라 곳간을 다 허물어뜨렸고, 재정 운용에서 신중함은 사라졌다\"며 \"괴물 공수처가 출범하면 공무원 누구나 대통령과 권력이 지시하는 범죄행위에 거리낌 없이 가담할 것이다. 청와대와 권부 요직에 앉아 불법으로 각종 이권을 챙기는 권력자들에 대한 사건이 불거져도 공수처가 사건을 가져가 버리면 그만\"이라고 우려했다.\n주 원내대표는 \"문 대통령은 제게 '공수처는 고위 공직자들을 처벌하는 것인데 왜 야당이 반대하는지 이해할 수 없다'고 했는데, 그런 분이 청와대와 대통령 주변을 감시하는 특별감찰관은 취임 이후 지금까지 왜 임명하지 않았는가\"라며 \"공수처는 권력형 비리의 쓰레기 하치장, 종말 처리장이 될 것\"이라고 비판했다.\n문재인 정부를 향해 주 원내대표는 \"문 대통령과 그 사도들은 법치가 미치지 않는 무오류의 화신이 될 것\"이라며 \"오류를 인정하지 않는 존재가 바로 신이며 그 아래에는 자신들의 지도자를 목숨바쳐 지킴으로서 정의를 실현하겠다는 추종자들로 넘쳐 난다. 공수처는 지도자의 신성을 인정하지 않는 세력을 정죄하는 수단으로 전락할 것\"이라고 질타했다.\n주 원내대표는 \"저도 법조인이지만 대통령과 공수처장이 마음대로 검사들과 수사관들을 임명하는 이 끔찍한 사법기구가 어떤 일을 할지 두렵기만 하다\"며 \"공수처는 검찰과 경찰 위에 있는 사법기구로, 헌법과 법으로 독립성을 보장하는 검찰총장을 이렇게 핍박하는 정권이 공수처를 어떻게 운영할지 불을 보듯 뻔한 일\"이라고 예측했다.\n그러면서 주 원내대표는 \"추미애 법무장관을 앞장 세워 윤석열 검찰의 권력 비리 수사를 저지하려다가 난관에 봉착하자 무슨 수를 써서라도 공수처를 출범시키려 한다. 공수처장 자리에는 추미애보다 더 한 막무가내 내 편을 앉힐 게 분명한 것\"이라며 \"문 정권의 파렴치와 오만함을 최전선에서 온 몸으로 겪어온 저로서는 민주당이 내일부터 국회에서 보일 행태가 환히 보인다. 180석의 민주당이 또 군사작전을 개시하면 그걸 누가 막겠는가\"라고 성토했다.\n주 원내대표는 \"공수처법을 막을 힘이 우리 야당에게는 없다. 삭발하고 장외투쟁해 봐야 눈 하나 깜짝할 사람들이 아닌 것\"이라며 \"대란대치(大亂大治), 세상을 온통 혼돈 속으로 밀어넣고 그걸 권력 유지에 이용한다는 게 이 정권의 통치기술\"이라고 규탄했다.\n아울러 주 원내대표는 \"권력은 바람, 국민은 풀이다. 바람이 불면 청보리 밭의 보리가 눕는다\"며 \"권력은 풀들이 다시는 일어서지 못하도록 풀을 짓밟지만 풀들은 다시 일어난다. 시인 김수영은 '바람보다 먼저 눕지만, 바람보다 먼저 일어나는' 민초의 힘을 노래했다\"고 말했다.\n마지막으로 주 원내대표는 \"문재인 정권은 이제 곧 국회에서 광장에서 짓밟힌 풀들이 일어서서 아우성치는 모습을 지켜보게 될 것\"이라며 \"대란대치를 끝장내려는 국민적 저항에 직면할 것\"이라고 거듭 강조했다.\n\"\"\"","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"한국어 문법체계에 따라 요약문을 생성하기 위해 한국어 문장 샘플을 준비\n\n'한글 위키백과'에서 임의의 문장을 수집 함"},{"metadata":{"trusted":true},"cell_type":"code","source":"#한국어 위키백과에서 스크랩핑\n\nimport wikipedia as wiki\nwiki.set_lang('ko')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# '전래동화' 라는 keyword로 100개 page의 Text를 취득\n\ndef __search_from_wiki(question,max_rank):\n    results = wiki.search(question,results=max_rank)\n    print(results)\n    contents = []\n    for result in results:\n        try:\n            page = wiki.page(result)\n            #print(f\"Top wiki result: {page}\")\n            text = page.content\n            ln = len(text)\n            print(f'Collecting page : {page} , text length {str(ln)}')\n            #if ln < 4000:\n            #  contents.append(text)\n            #else:\n            #  contents.append(text[0:4000])\n            contents.append(text)\n        except Exception as ex:\n          print(ex)\n    return contents\n\n\nko_grammar_set_raw = __search_from_wiki(\"전래동화\", 100)\n\nprint(f'전체 수집한 Page Count : {len(ko_grammar_set_raw)}')","execution_count":10,"outputs":[{"output_type":"stream","text":"['동화', '신 전래동화', '꾸러기 수비대', '호시조라 미유키', '아동 문학', '한국의 사찰', '해와 달이 된 오누이', '잠자는 숲속의 미녀', '거북', '이한갈', '정은찬', '옛날 옛적에 (애니메이션)', '김기두 (배우)', '계룡선녀전 (드라마)', '동요', '이상훈 (1976년)', '최홍일', '육진수 (격투기 선수)', '제비', '장석현 (연예인)', '유다미', '밀교 (불교)', '최지웅', '한다은', '재희', '박재훈 (배우)', '정미남', '안젤리나 다닐로바', '도깨비', '기탄교육', '국지용', '의왕백운호수축제', '박민경', '정정아', '콩딱쿵! 이야기 주머니', '윤기원 (배우)', '선녀와 나무꾼', '남생이', '콩쥐팥쥐 (동음이의)', '대장화홍련전', '토끼전', '미녀와 야수', '이설구', '빨간 자전거', '콩쥐팥쥐전', '이서휴게소', '지대한', '은비까비의 옛날옛적에', '김덕현 (배우)', '티베트', '아시리아인', '홍석연', '백조의 호수', '서예', '도교', '켈트 다신교', '금도끼 은도끼', '제네시스 (밴드)', '장화, 홍련 (동음이의)', '노상현', '허구 국가', '타이완의 문화', '도깨비 (동음이의)', '골디락스', '선녀강림', '자와어', '손춘익', '안동국제탈춤페스티벌', '윌리엄 버틀러 예이츠', '성덕대왕신종', '모모타로', '고려', '한국 문학', '라푼젤 (영화)', '토비트', '조선 후기의 문학', '송월동 동화마을', '홍석천', '계룡선녀전', '이집트', '안지환', '응우옌 왕조', '아시아의 역사', '프랑스인', '외래어', '스키타이족', '메이플 월드', '인도네시아', '네버랜드', '이탈리아', '일본 제국', '프랑크인', 'MBC 창작동요제', '바이킹', '드랑 나흐 오스텐', '김환영 (작가)', '조선', '원나라', '오윤 (화가)', '앱북']\nCollecting page : <WikipediaPage '동화'> , text length 685\nCollecting page : <WikipediaPage '신 전래동화'> , text length 156\nCollecting page : <WikipediaPage '꾸러기 수비대'> , text length 1554\nCollecting page : <WikipediaPage '호시조라 미유키'> , text length 1601\nCollecting page : <WikipediaPage '아동 문학'> , text length 678\nCollecting page : <WikipediaPage '한국의 사찰'> , text length 885\nCollecting page : <WikipediaPage '해와 달이 된 오누이'> , text length 392\nCollecting page : <WikipediaPage '잠자는 숲속의 미녀'> , text length 2037\nCollecting page : <WikipediaPage '거북'> , text length 1381\nCollecting page : <WikipediaPage '이한갈'> , text length 776\nCollecting page : <WikipediaPage '정은찬'> , text length 1096\nCollecting page : <WikipediaPage '옛날 옛적에 (애니메이션)'> , text length 1080\nCollecting page : <WikipediaPage '김기두 (배우)'> , text length 1767\nCollecting page : <WikipediaPage '계룡선녀전 (드라마)'> , text length 1416\nCollecting page : <WikipediaPage '동요'> , text length 1429\nCollecting page : <WikipediaPage '이상훈 (1976년)'> , text length 831\nCollecting page : <WikipediaPage '최홍일'> , text length 1917\nCollecting page : <WikipediaPage '육진수 (격투기 선수)'> , text length 749\nCollecting page : <WikipediaPage '제비'> , text length 1125\nCollecting page : <WikipediaPage '장석현 (연예인)'> , text length 576\nCollecting page : <WikipediaPage '유다미'> , text length 409\nCollecting page : <WikipediaPage '밀교 (불교)'> , text length 4379\nCollecting page : <WikipediaPage '최지웅'> , text length 712\nCollecting page : <WikipediaPage '한다은'> , text length 634\nCollecting page : <WikipediaPage '재희'> , text length 1229\nCollecting page : <WikipediaPage '박재훈 (배우)'> , text length 1962\nCollecting page : <WikipediaPage '정미남'> , text length 970\nCollecting page : <WikipediaPage '안젤리나 다닐로바'> , text length 879\nCollecting page : <WikipediaPage '도깨비'> , text length 3171\nCollecting page : <WikipediaPage '기탄교육'> , text length 245\nCollecting page : <WikipediaPage '국지용'> , text length 420\nCollecting page : <WikipediaPage '의왕백운호수축제'> , text length 272\nCollecting page : <WikipediaPage '박민경'> , text length 885\nCollecting page : <WikipediaPage '정정아'> , text length 1119\nCollecting page : <WikipediaPage '콩딱쿵! 이야기 주머니'> , text length 122\nCollecting page : <WikipediaPage '윤기원 (배우)'> , text length 2555\nCollecting page : <WikipediaPage '선녀와 나무꾼'> , text length 173\nCollecting page : <WikipediaPage '남생이'> , text length 502\n\"콩쥐팥쥐 (동음이의)\" may refer to: \n콩쥐팥쥐\n콩쥐팥쥐 (1967년 영화)\n콩쥐팥쥐 (1958년 영화)\nCollecting page : <WikipediaPage '대장화홍련전'> , text length 216\nCollecting page : <WikipediaPage '토끼전'> , text length 3931\nCollecting page : <WikipediaPage '미녀와 야수'> , text length 2977\nCollecting page : <WikipediaPage '이설구'> , text length 3021\nCollecting page : <WikipediaPage '빨간 자전거'> , text length 2955\nCollecting page : <WikipediaPage '콩쥐팥쥐전'> , text length 2912\nCollecting page : <WikipediaPage '정안알밤휴게소'> , text length 808\nCollecting page : <WikipediaPage '지대한'> , text length 3296\nCollecting page : <WikipediaPage '은비까비의 옛날옛적에'> , text length 940\nCollecting page : <WikipediaPage '김덕현 (배우)'> , text length 1986\nCollecting page : <WikipediaPage '티베트'> , text length 5093\nCollecting page : <WikipediaPage '아시리아인'> , text length 2793\nCollecting page : <WikipediaPage '홍석연'> , text length 3008\nCollecting page : <WikipediaPage '백조의 호수'> , text length 2130\nCollecting page : <WikipediaPage '서예'> , text length 10102\nCollecting page : <WikipediaPage '도교'> , text length 6686\nCollecting page : <WikipediaPage '켈트 다신교'> , text length 4308\nCollecting page : <WikipediaPage '금도끼 은도끼'> , text length 1259\nCollecting page : <WikipediaPage '제네시스 (밴드)'> , text length 5457\n\"장화, 홍련 (동음이의)\" may refer to: \n장화홍련전\n장화, 홍련\n장화, 홍련\nCollecting page : <WikipediaPage '노상현'> , text length 351\nCollecting page : <WikipediaPage '허구 국가'> , text length 2702\nCollecting page : <WikipediaPage '타이완의 문화'> , text length 1581\n\"도깨비 (동음이의)\" may refer to: \n도깨비\n도깨비\n눈물을 마시는 새\n레인보우 식스 시즈\n도깨비가 간다\n도깨비가 간다\nTokebi\n도깨비 (DokeV)\nCollecting page : <WikipediaPage '골디락스'> , text length 1243\nCollecting page : <WikipediaPage '선녀강림'> , text length 1856\nCollecting page : <WikipediaPage '자와어'> , text length 3770\nCollecting page : <WikipediaPage '손춘익'> , text length 1687\nCollecting page : <WikipediaPage '안동국제탈춤페스티벌'> , text length 2123\nCollecting page : <WikipediaPage '윌리엄 버틀러 예이츠'> , text length 12057\nCollecting page : <WikipediaPage '성덕대왕신종'> , text length 1934\nCollecting page : <WikipediaPage '모모타로'> , text length 1980\nCollecting page : <WikipediaPage '고려'> , text length 30322\nCollecting page : <WikipediaPage '한국 문학'> , text length 14908\nCollecting page : <WikipediaPage '라푼젤 (영화)'> , text length 9736\nCollecting page : <WikipediaPage '토비트'> , text length 9004\nCollecting page : <WikipediaPage '조선 후기의 문학'> , text length 5280\nCollecting page : <WikipediaPage '송월동 동화마을'> , text length 896\nCollecting page : <WikipediaPage '홍석천'> , text length 8717\nCollecting page : <WikipediaPage '계룡선녀전'> , text length 2268\nCollecting page : <WikipediaPage '이집트'> , text length 11797\nCollecting page : <WikipediaPage '안지환'> , text length 12107\nCollecting page : <WikipediaPage '응우옌 왕조'> , text length 14070\nCollecting page : <WikipediaPage '아시아의 역사'> , text length 11513\nCollecting page : <WikipediaPage '프랑스인'> , text length 12556\nCollecting page : <WikipediaPage '외래어'> , text length 5000\nCollecting page : <WikipediaPage '스키타이족'> , text length 30924\nCollecting page : <WikipediaPage '메이플 월드'> , text length 5895\nCollecting page : <WikipediaPage '인도네시아'> , text length 30606\nCollecting page : <WikipediaPage '네버랜드'> , text length 8303\nCollecting page : <WikipediaPage '이탈리아'> , text length 42736\nCollecting page : <WikipediaPage '일본 제국'> , text length 15259\nCollecting page : <WikipediaPage '프랑크인'> , text length 23128\nCollecting page : <WikipediaPage 'MBC 창작동요제'> , text length 1724\nCollecting page : <WikipediaPage '바이킹'> , text length 22255\nCollecting page : <WikipediaPage '드랑 나흐 오스텐'> , text length 4331\nCollecting page : <WikipediaPage '김환영 (작가)'> , text length 4105\nCollecting page : <WikipediaPage '조선'> , text length 30998\nCollecting page : <WikipediaPage '원나라'> , text length 15537\nCollecting page : <WikipediaPage '오윤 (화가)'> , text length 2772\nCollecting page : <WikipediaPage '앱북'> , text length 4534\n전체 수집한 Page Count : 97\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ko_grammar_set_raw += __search_from_wiki(\"역사\", 100)\n\nprint(f'전체 수집한 Page Count : {len(ko_grammar_set_raw)}')","execution_count":11,"outputs":[{"output_type":"stream","text":"['역사', '한국의 역사', '불교의 역사', '대체 역사', '일본의 역사', '스위스 역사 사전', '유럽의 역사', '고려의 역사', '세계의 역사', '조선의 역사', '동북아역사재단', '우즈베키스탄의 역사', '중국의 역사', '대한민국의 역사 드라마 목록', '역사주의', '서울역사박물관', '한국 불교의 역사', '오키나와현의 역사', '역사학', '러시아의 역사', '역사적 예수', '소련의 역사', '다큐멘터리 역사를 찾아서', '조지아의 역사', '조선민주주의인민공화국의 역사', '영국의 역사', '역사철학', '프랑스의 역사', '유엔의 역사', '역사신학', '역사지진', '인터넷의 역사', '애플의 역사', '역사저널 그날', '역사 시대', '힌두교의 역사', '역사소설', '독일의 역사', '구글의 역사', '압하지야의 역사', '아일랜드의 역사', '영화의 역사', '기독교의 역사', '운영 체제의 역사', '태국의 역사', '몬테네그로의 역사', '음소문자의 역사', '사기 (역사서)', '파키스탄의 역사', '사학자', '베트남의 역사', '기술의 역사', '역사스페셜', '안드로이드 버전 역사', '그리스의 역사', '의사 역사학', '서울역', '인도의 역사', '미국 육군 역사관', '역사언어학', '퀴디치의 역사', '벨라루스의 역사', '사극', '역사적 유물론', '폭력의 역사', '마리아론의 역사', 'FC 서울의 역사', '역사 (헤로도토스)', '교육의 역사', '중화민국의 역사', '몽골의 역사', '터키의 역사', '근대 그리스의 역사', '스페인의 역사', '베트남 역사박물관', '우크라이나의 역사', '맨체스터 유나이티드 FC의 역사', '음악의 역사', '핀란드의 역사', '이란의 역사', '에스페란토의 역사', '타이완의 역사', '민자역사', '역사 재현', '크림반도의 역사', '라오스의 역사', '제2차 세계 대전 기간 미국의 군사 역사', '한국사 연표', '전주역사박물관', '이집트의 역사', '브리튼 제도의 역사', '아르메니아의 역사', '강화역사박물관', '생물의 진화 역사', '군사사', '건축의 역사', '예수의 역사적 실존', '대한민국의 역사', '포르투갈의 역사', '고대사']\nCollecting page : <WikipediaPage '역사'> , text length 5355\nCollecting page : <WikipediaPage '한국의 역사'> , text length 35878\nCollecting page : <WikipediaPage '불교의 역사'> , text length 10999\nCollecting page : <WikipediaPage '대체 역사'> , text length 12122\nCollecting page : <WikipediaPage '일본의 역사'> , text length 18518\nCollecting page : <WikipediaPage '스위스 역사 사전'> , text length 3401\nCollecting page : <WikipediaPage '유럽의 역사'> , text length 43372\nCollecting page : <WikipediaPage '고려의 역사'> , text length 1222\nCollecting page : <WikipediaPage '세계의 역사'> , text length 12393\nCollecting page : <WikipediaPage '조선의 역사'> , text length 18208\nCollecting page : <WikipediaPage '동북아역사재단'> , text length 2202\nCollecting page : <WikipediaPage '우즈베키스탄의 역사'> , text length 2106\nCollecting page : <WikipediaPage '중국의 역사'> , text length 7922\nCollecting page : <WikipediaPage '대한민국의 역사 드라마 목록'> , text length 482\nCollecting page : <WikipediaPage '역사주의'> , text length 4674\nCollecting page : <WikipediaPage '서울역사박물관'> , text length 2769\nCollecting page : <WikipediaPage '한국 불교의 역사'> , text length 46394\nCollecting page : <WikipediaPage '오키나와현의 역사'> , text length 6799\nCollecting page : <WikipediaPage '역사학'> , text length 253\nCollecting page : <WikipediaPage '러시아의 역사'> , text length 10327\nCollecting page : <WikipediaPage '역사적 예수'> , text length 21307\nCollecting page : <WikipediaPage '소련의 역사'> , text length 199\nCollecting page : <WikipediaPage '다큐멘터리 역사를 찾아서'> , text length 264\nCollecting page : <WikipediaPage '조지아의 역사'> , text length 24119\nCollecting page : <WikipediaPage '조선민주주의인민공화국의 역사'> , text length 8071\nCollecting page : <WikipediaPage '영국의 역사'> , text length 6671\nCollecting page : <WikipediaPage '역사철학'> , text length 52\nCollecting page : <WikipediaPage '프랑스의 역사'> , text length 14913\nCollecting page : <WikipediaPage '유엔의 역사'> , text length 1147\nCollecting page : <WikipediaPage '역사신학'> , text length 926\nCollecting page : <WikipediaPage '역사지진'> , text length 543\nCollecting page : <WikipediaPage '인터넷의 역사'> , text length 2171\nCollecting page : <WikipediaPage '애플의 역사'> , text length 6215\nCollecting page : <WikipediaPage '역사저널 그날'> , text length 437\nCollecting page : <WikipediaPage '역사 시대'> , text length 551\nCollecting page : <WikipediaPage '힌두교의 역사'> , text length 1246\nCollecting page : <WikipediaPage '역사소설'> , text length 1721\nCollecting page : <WikipediaPage '독일의 역사'> , text length 23772\nCollecting page : <WikipediaPage '구글의 역사'> , text length 2054\nCollecting page : <WikipediaPage '압하지야의 역사'> , text length 15841\nCollecting page : <WikipediaPage '아일랜드의 역사'> , text length 14632\nCollecting page : <WikipediaPage '영화의 역사'> , text length 12999\nCollecting page : <WikipediaPage '기독교의 역사'> , text length 28905\nCollecting page : <WikipediaPage '운영 체제의 역사'> , text length 2631\nCollecting page : <WikipediaPage '태국의 역사'> , text length 3114\nCollecting page : <WikipediaPage '몬테네그로의 역사'> , text length 560\nCollecting page : <WikipediaPage '음소문자의 역사'> , text length 2966\nCollecting page : <WikipediaPage '사기 (역사서)'> , text length 4005\nCollecting page : <WikipediaPage '파키스탄의 역사'> , text length 2372\nCollecting page : <WikipediaPage '사학자'> , text length 276\nCollecting page : <WikipediaPage '베트남의 역사'> , text length 10429\nCollecting page : <WikipediaPage '기술의 역사'> , text length 186\nCollecting page : <WikipediaPage '역사스페셜'> , text length 1448\nCollecting page : <WikipediaPage '안드로이드 버전 역사'> , text length 2279\nCollecting page : <WikipediaPage '그리스의 역사'> , text length 12854\nCollecting page : <WikipediaPage '의사 역사학'> , text length 2414\nCollecting page : <WikipediaPage '서울역'> , text length 8743\nCollecting page : <WikipediaPage '인도의 역사'> , text length 13866\nCollecting page : <WikipediaPage '미국 육군 역사관'> , text length 397\nCollecting page : <WikipediaPage '역사언어학'> , text length 556\nCollecting page : <WikipediaPage '퀴디치의 역사'> , text length 92\nCollecting page : <WikipediaPage '벨라루스의 역사'> , text length 1506\nCollecting page : <WikipediaPage '사극'> , text length 539\nCollecting page : <WikipediaPage '역사적 유물론'> , text length 2296\nCollecting page : <WikipediaPage '폭력의 역사'> , text length 1036\nCollecting page : <WikipediaPage '마리아론의 역사'> , text length 487\nCollecting page : <WikipediaPage 'FC 서울의 역사'> , text length 11289\nCollecting page : <WikipediaPage '역사 (헤로도토스)'> , text length 1162\nCollecting page : <WikipediaPage '교육의 역사'> , text length 1504\nCollecting page : <WikipediaPage '중화민국의 역사'> , text length 28162\nCollecting page : <WikipediaPage '몽골의 역사'> , text length 1154\nCollecting page : <WikipediaPage '터키의 역사'> , text length 4319\nCollecting page : <WikipediaPage '근대 그리스의 역사'> , text length 15021\nCollecting page : <WikipediaPage '스페인의 역사'> , text length 14863\nCollecting page : <WikipediaPage '베트남 역사박물관'> , text length 179\nCollecting page : <WikipediaPage '우크라이나의 역사'> , text length 3333\nCollecting page : <WikipediaPage '맨체스터 유나이티드 FC의 역사'> , text length 156\nCollecting page : <WikipediaPage '음악의 역사'> , text length 6766\nCollecting page : <WikipediaPage '핀란드의 역사'> , text length 6371\nCollecting page : <WikipediaPage '이란의 역사'> , text length 17702\nCollecting page : <WikipediaPage '에스페란토의 역사'> , text length 12663\nCollecting page : <WikipediaPage '타이완의 역사'> , text length 6145\nCollecting page : <WikipediaPage '민자역사'> , text length 1029\nCollecting page : <WikipediaPage '역사 재현'> , text length 2316\nCollecting page : <WikipediaPage '크림반도의 역사'> , text length 2563\nCollecting page : <WikipediaPage '라오스의 역사'> , text length 2200\nCollecting page : <WikipediaPage '제2차 세계 대전 기간 미국의 군사 역사'> , text length 583\nCollecting page : <WikipediaPage '한국사 연표'> , text length 188\nCollecting page : <WikipediaPage '전주역사박물관'> , text length 413\nCollecting page : <WikipediaPage '이집트의 역사'> , text length 1004\nCollecting page : <WikipediaPage '브리튼 제도의 역사'> , text length 1032\nCollecting page : <WikipediaPage '아르메니아의 역사'> , text length 1073\nCollecting page : <WikipediaPage '강화역사박물관'> , text length 248\nCollecting page : <WikipediaPage '생물의 진화 역사'> , text length 895\nCollecting page : <WikipediaPage '군사사'> , text length 1239\nCollecting page : <WikipediaPage '건축의 역사'> , text length 25890\nCollecting page : <WikipediaPage '예수의 역사적 실존'> , text length 574\nCollecting page : <WikipediaPage '대한민국의 역사'> , text length 35866\nCollecting page : <WikipediaPage '포르투갈의 역사'> , text length 1620\nCollecting page : <WikipediaPage '고대사'> , text length 33685\n전체 수집한 Page Count : 197\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 간단한 전처리\ndef clean_text(txt):\n    txt = txt.replace('\\n','')\n    txt = txt.replace('=','')    \n    return txt \n\nko_grammar_set_raw = [clean_text(x) for x in ko_grammar_set_raw]\nprint('Sample text : ')\nprint('--------------------------------------------------------------------------------------------')\nprint(ko_grammar_set_raw[120])\nprint('--------------------------------------------------------------------------------------------')","execution_count":12,"outputs":[{"output_type":"stream","text":"Sample text : \n--------------------------------------------------------------------------------------------\n조지아의 역사(조지아어: საქართველო 사카르트벨로)는 콜키스와 이베리아의 왕국이 번영함으로써 시작되었다. 그 왕국들은 기원전 1000년경에 조지아 문명을 형성하였고 12~13세기를 통틀어 르네상스 문명과 황금 시대를 이룩하게 되었다. 조지아의 역사는 여러 제국들뿐만 아니라 그들의 통제가 직접적이지 않은 지역들에서부터 광범위한 영향력에 의하여 현재 조지아 지역의 계속되는 침입과 정복이 두드러졌다. 그 지역은 로마 제국, 페르시아 제국, 아랍 제국, 몽골 제국, 오스만 제국, 그리고 러시아 제국과 같은 다양한 제국 시대의 일부였다. 고대  선사 시대 오늘날 조지아의 영토의 최초 거주에 대한 증거는 나라의 남동부에 드마니시의 발굴로 명확하게, 약 1백8십만년 전으로 거슬러 올라간다. 후기 선사시대의 유물들(아슐 문화, 무스테리안기, 후기 구석기 시대)은 조지아에서 무수히 많은 동굴과 옥외 유적지들로부터 알게 됐다. 최초의 농경 신석기 시대 거주는 기원전 6000~5000년 사이의 어느때 쯔음이었다. 도구로 그 지역의 흑요석을 사용하던 사람들의, 슐라베리-쇼무 문화로도 알려진, 그 시대 사람들은 가축과 돼지와 같은 동물들을 키웠으며 포도를 포함한 작물들을 재배했다. \"슐라베리-소무테페-무리\"의 정착을 말하는 수 많은 동굴들은 1960년대 부터 안내되고 있다.1970년대에, 고고학적인 동굴들은 동부 조지아의 이미리스-고라 지역에 있는 탄소 측정으로 기원전 제5천년기의 그림이 그려져 있는 집들을 포함한 많은 고대 정착지들을 드러냈다. 그 주거지들은 원형이나 타원형이며 가운데에 기둥과 굴뚝이 있는 특징적인 모양으로 만들어졌다. 그러한 형태가 사용되어 향후에는 조지아의 주거지들과 '다르바지' 형식으로 된 집들의 건축이 발달하였다. 기원전 제4~3천년기의 동기 시대 기간 동안에는, 조지아와 소아시아는 쿠라-아락세스 문화의 근원이며 기원전 제2천년기의 트리알레티 문화로 이어진다. 고고학적인 동굴들은 베슈타셰니와 오즈니(기원전 제4~3천년기)의 정착지 유물과, 트살카의 트리알레티 주에 있는 매장식 무덤(탄소 측정 연대 기원전 제2천년기)들을 밝혀주고 있다. 모두 다 그들의 진보되고 잘 발달된 건축과 건축양식을 증명한다.조지아 초기 부족들은 기원전 12세기에 쓰여진 역사에서 처음 등장한다. 고고학적인 발견들과 고대를 소재로 한 참고 문헌들에서는 기원전 7세기와 그 전까지 거슬러 올라가 진보된 야금 및 금 세공 기술들에 의해 특징지어지는 고대 정치와 왕국 형성의 요소들이 드러난다. 기원전 2000~750년 사이에, 그 지역은 히타이트, 우라루트, 메데스, 최초-페르시아와 킴메르의 침입에서 살아남았다. 같은 시기에, 민족적으로 통합되었던 최초-카르트벨리안은 스반스, 쟌스/찬스와 동-카르트벨리안의 여러 갈래로 갈라져 나갔다. 그러한 분리는 마침내 조지아어(동카르트벨리아의 제나라 말에서 유래됨), 스반어, 메그렐어와 라즈어(쟌 방언에서 유래된 나중의 두 갈래)의 현대 카르트벨리아어의 형식을 이끌었다. 그 때에, 사메그렐로의 현대 조지아인이 살고 있는 주 또는 자치국들인 스바네티와 압하스, 쟌스에서는, 스반어가 유력했다. 반면에 동카르트벨리아어는 현대 동조지아의 다수 언어로 형성되었다. 문화적 지리적 경계의 결과로, 조지아의 문화와 국가는 장차 기원전 8세기 말에 서조지아와 동조지아의 두 중심지를 형성하게 되었다. 첫 번째 두 조지아 왕국은 콜키스 왕국으로 알려진 서조지아와 이베리아왕국의 동조지아로 떠올랐다. 고대 조지아의 콜키스 왕국과 이베리아 왕국 두 번째 조지아 부족은 연맹이 기원전 13세기에 서조지아가 흑해 연안에 나타났고 콜키스 왕국에 속하게 되었다. BCE 6~1세기에 존재한 콜키스 왕국은 최초의 국가 형태로 여겨지며 콜키시안이라는 용어는 흑해 동부 연안에 거주했던 밍그렐리아족, 라즈족, 찬스족과 같이 고대 조지아-카르트벨리아 부족들의 총체적인 용어이다.캅카스 학자 키릴 토마노프의 연구 논문에 따르면 :라고 하였다.콜키스는 고대 그리스에 알려져, 그리스 전설인 이아손과 아르고선의 용사들의 주연이 되었다. 그들은 기원전 2천년경에 황금양모를 찾아서 콜키스를 여행했는데, 남서부 콜키스에는 카르트벨리아의 스반족과 쟌족이라는 부족들이 살고 있었다. 고대 콜키스를 구성하는 또 다른 민족은 기원전 1,000~500년 사이에 네아써스, 피티스, 디오스쿠리아스, 구에노스, 파시스(현재 포티) 압사로스와 리조스(현재 터키의 리제)의 해안 지역들에다가 많은 무역 식민지들을 건설했던 그리스인들이다. 조지아의 동부 지역은 기원전 6~4세기 동안에 조지아의 여러 동맹들 간의 주도권을 다투던 전쟁터였다. 전쟁은 마침내 므츠헤타의 지역에서 온 카르틀리 부족의 승리로 끝났다. 조지아의 전통에 따르면, 카르틀리 왕국(그리스-로마 문학에서 이베리아로 알려짐)은 기원전 300년경에 파르나바즈 1세에 의해 건국되었으며, 그는 파르나바지드 왕조의 첫 번째 통치자였다.기원전 653~333년 사이에, 콜키스와 이베리아는 둘 다 메디아 제국과 후일의 페르시아 제국의 연속적인 침략에도 살아남았다. 기원전 3세기 말에, 남부 이베리아는 광대한 그레코-마케도니아 제국을 캅카스의 남부에 확립한 알렉산더 대왕의 침략 군대들을 목격한다. 이베리아와 콜키스는 모두 알렉산더의 제국이나 어떠한 중동의 헬리니스틱 왕국의 후계자들에게도 합병되지 않았다. 그러나 고대 그리스 문화는 계속하여 그 지역에 상당한 영향을 끼쳤고, 그리스어는 콜키스의 도시들에서 널리 사용되었다. 이베리아에서 그리스어의 영향력은 두드러질 정도는 아녔고 아람어가 널리 사용되었다.기원전 2세기 초반과 기원후 2세기 후반 사이에, 콜키스와 이베리아는 모두, 이웃 나라들과 다 같이, 로마, 아르메니아와 폰투스의 단기 왕국들의 주요 세력과 지역 세력 간의 장기간에 걸쳐 파괴적인 충돌의 시합장이 되었다. 기원전 189년에 급속도로 성장한 아르메니아 왕국은 동부와 남부 지방인 고가레네, 타오키야와 제니오키야아스 뿐만아니라 몇몇 다른 영토들도 정복하여, 이베리아를 절반 넘게 차지했다. 기원전 120~63년 사이에, 아르메니아의 동맹인 폰투스의 미트리다테 6세 에우파토르는 동부와 서부 흑해 뿐만아니라 전체 소아시아의 대부분을 포괄하며, 콜키스의 전부를 정복하고 그의 왕국으로 합병시켰다. 로마의 이베리아와 콜키스 정복 아르메니아와의 단절된 관계로 그 무렵 폰투스의 미트리다테스 6세와 아르메니아와의 전쟁 당시에 있던 로마 장군 폼페이우스가 나라를 침략(기원전 65년)하게끔 했다. 그러나 로마는 이베리아 전역에 그녀의 지배력을 수립하지 않았다. 19년 후에, 로마는 알바니아와의 대결 작전을 위해 그들의 군사들과 파르나바즈 2세의 군대와 합류하여 이베리아를 다시 지나갔다(기원전 36년).그 기간 동안에는, 아르메니아와 폰투스가 동부 지중해 전체의 점유권을 놓고, 로마의 비용으로 활발히 영토를 확장하고 있었다. 그러나, 반-로마 동맹의 성공은 오래가지 않았다. 서부로부터 폼페이와 루쿨루스의 눈부신 군사 작전과 남쪽으로부터는 파르티아의 침략의 결과로, 아르메니아는 로마-파르티야의 속국으로 양도되어, 기원전 65년 정복지의 중대한 부분을 잃었다. 같은 시기에, 폰투스 왕국은 로마에게 완전히 파괴되었고 그 영토는 콜키스를 포함하여 그녀의 속주로 로마 제국에 합병되었다.이전의 콜키스 왕국은 레가티에 의해 통치되는 로마의 라지쿰 속주가 되었다. 이어지는 600년의 조지아 역사는 시리아, 메소포타미아, 아르메니아, 알바니아, 이베리아를 포함하는 중동에서의 우세를 위해 서로 대항하여 장기전으로 싸웠던 파르티아와 사산조를 포함하여 로마와 페르시아(이란) 간의 전쟁터로 표징됐다.2세기에, 로마로부터 완전한 독립을 성취했고 쇠퇴하는 아르메니아로 부터 전에 잃었던 얼마간의 영토들을 재정복한 파르스만 2세 왕의 통치기간 동안에, 이베리아는 특별히 그 지역에 있는 그녀의 요새를 강화했다. 3세기 초반에, 로마는 알바니아와 아르메니아의 대부분을 사산조 페르시아에게 내주어야 했다. 라지쿰 속주는 지치국의 지위를 얻었고 그 지위는 그 세기 말에는 쟌, 스반, 압실 및 사니프스의 작은 공국들의 영토들에서 라지카-에그리시의 새로운 왕국의 형태로 완전한 독립국으로 발전했다. 이러한 새로운 서부 조지아 왕국은 비잔티움 제국에 흡수되던 562년까지 250년 넘게 존속했다.조지아의 콜키스 왕국이 로마의 속주로 관리 될때, 캅카스 이베리아는 로마 제국권의 보호를 자유로히 받아들였다. 므츠헤타에서 발견된 석비문은 \"카이사르의 친구\" 또한 \"\"로마가 사랑하는 이베리아의\" 왕으로 1세기의 통치자 미드라트 1세(58~56년)세를 증명한다. 베스파시아누스 황제는 75년에 이베리아의 왕을 위하여 아르자미의 고대 므츠헤타 부지를 요새화 했다.3세기에, 라지 부족은 지역적으로 에그리시 라고 알려진 라지카 왕국을 건설하여, 대부분의 콜키스를 지배하게 되었다. 콜키스는 542~562년에 라지크 전쟁이 절정에 달했고, 동로마/비잔티움과 사산조 제국들 간의 오래 끄는 경쟁의 무대였다. 기독교의 전래 기독교가 전래되기 전의 이베리아는 1세기 부터 미트라교와 조로아스터교의식이 거행되었다. 미트라교의 의식은 통합적인 성격과 뒤따르는 지역 의식들의 상호 보완, 특히 태양 숭배에 의해 다른 종교와 구별되었고, 점진적으로 고대 조지아인들의 믿음을 덧붙여 나갔다. 서조지아의 이베리아 왕국은 미리안 3세왕이 기독교를 공식적인 왕국의 종교로 확립한 327년 에 개종하여 세계 최초의 기독교 국가 중에 한 나라가 되었다. 그러나, 기독교가 국교로 인정된 연대는 317년, 324년 등으로 나타낸 많은 기록들과 역사 문서들을 기반으로 수정된다. 조지아 연대기에 따르면, 카파도키아의 성녀 니노가 콘스탄티누스 대제의 재위 기간 중인 330년에 조지아를 기독교로 개종시켰다고 한다. 4세기 중반이었지만, 라지카(옛 이베리아 왕국)과 이베리아는 모두 기독교를 그들의 공식적인 종교로 채택하게 된다. 4세기와 대부분의 5세기 기간동안에, 이베리아(카르틀리 왕국으로도 알려짐)는 페르시아의 통제 하에 있게 됐다. 왕국은 폐지되었고 나라는 샤(샤흐)에 의해 임명된 통치자에 의해서 통치되었다. 5세기말 이었기는 했지만, 바흐탕 1세 고르가살리 왕자는 그 스스로 왕임을 선언하여 반-페르시아 반군을 편성했고 이베리아 왕국을 복원하였다. 그 다음에, 바흐탕의 군대들은 페르시아와 비잔티움 제국에 대항하여 다양한 군사 작전들을 착수했다. 그러나 조지아 왕국의 독립과 통일을 위한 그의 투쟁은 지속되는 성공을 이어가지 못하였다. 502년에 바흐탕이 죽고, 그의 아들 다치(502~514)의 짧은 통치 기간 이후에, 이베리아는 한때 페르시아의 속주로 재합병되었다. 그러나 그 때 이베리아 귀족들은, 조지아에서 에리스므타바리로 불리는, 통치자들을 선출할 수 있는 특권을 부여받았다. 7세기 후반에, 중동을 차지하려던 비잔티움-페르시아 경쟁은 그 지역의 아랍 정복으로 대체되었다. 중세 조지아  조지아 왕국의 통일 9세기의 첫 10년은 타오-클라르제티에서 새로운 조지아 왕국의 떠오름을 보았다. 바그라티오니 왕가의 아쇼트 쿠로팔라테스는 아랍으로부터 남이베리아의 옛 영토들을 해방시켰다. 그 영토들은, \"이베리아의 쿠로팔라티나테\"의 이름 아래 형식상 비잔티움 제국의 일부 였던 타오와 클라르제티, 그리고 샤브셰티, 키카타, 삼트스케, 트리알레티, 자바케티의 백작들의 공국들을 포함했다. 그러나 실제로 그 지역은 아르타누지의 수도와 더불어 완전히 독립된 나라로 기능했다. 쿠로팔라테스의 세습 칭호는 거의 한 세기동안 가문의 대표자들이 타오-클라르제티를 통치했던 바그라티오니 가문에 의하여 유지되었다. 쿠로팔라테 다비트 바그라티오니는 데오도시오폴리스(카린, 카르누칼라키)의 도시와 아르메니아 속주 바시아니의 병합에 의해, 그리고 한때 아랍 태수 카이시데에의 해 통제 되었던 아르메니아의 속주들인 카르퀴, 아파쿠니, 만트시케르트, 칼라트를 통틀어 보호 제도를 도입함으로 다비트는 그의 영토를 확장했다.첫 번째 통일 조지아 군주국은 쿠로팔라테 다비트가 카르틀리-이베리아의 백작령을 그의 왕국으로 가져오던 10세기 말에 형성되었다. 3년 후에, 그의 삼촌 맹인 데오도시우스가 죽고, 에그리시-압하지야의 왕 바그라트 3세는 압하지야의 왕좌를 승계했다. 1001년에 바그라트는 다비트가 죽은 결과로 타오-클라르제티(이베리아의 쿠로팔라티나테)를 그의 영토에 더했다. 1008~1010년에, 바그라트는 카케티와 헤레티를 합병했고, 그리하여 그는 조지아의 동부와 서부를 모두 통일한 첫 번째 단일 왕이 되었다.11세기의 1반기는 1040년대 말에 중앙 아시아와 페르시아의 대부분을 포함하는 광대한 유목민 제국의 건설에 성공한 셀주크 투르크의 전략적으로 중요한 침입에 의해 표징된다. 1071년에, 셀주크 군대는 만지케르트 전투에서 연합된 비잔티움-아르메니아와 조지아의 병력들을 초토화시켰다. 1081년에, 아르메니아, 아나톨리아, 메소포타미아, 시리아의 전부들과, 조지아의 거의 대부분이 셀주크에 의해 정복당했고 황폐화 되었다. 조지아에서는 압하지야, 스바네티야, 라차와 케비-케브수레티의 산악 지역들만이 셀주크의 통제 밖에 남아있었고 수많은 피난민들의 상대적으로는 안전한 피난처로 구실했다. 나라의 나버지 지역은 도시들과 요새들을 파괴했고 마을들을 약탈했으며 귀족들과 농민들 모두를 학살하던 정복자들에 의해서 지배되었다. 1080년대 말에는, 사실상, 그 지역에는 조지아인들보다 침략자들의 수가 더 많았다. 건설자 다비트 4세와 조지아 국토회복운동 조지아에서 셀주크 침입자들에 대항한 투쟁은 부친 게오르게 2세 바그라티오니가 퇴위하고 1089년 16세의 나이로 왕위를 계승한 바그라티오니 왕가의 젊은 다비트 4세가 이끌었다. 왕위를 승계한 직후 곧바로 권력을 잡은 다비트는 정규군과 농민군을 만들었다. 아나톨리아와 시리아에서 셀주크 투르크에 대항한 첫 번째 십자군(1096~1099)과 십자군의 공격은 조지아에서 다비트의 성공적인 군사 작전을 선호했다. 1099년 말에, 다비트는 셀주크에게 공물을 갖다 바치는 것을 그만 두게 되었고 트빌리시와 헤레티를 제외한 조지아의 영토 대부분을 해방시키게 되었다. 1103년에 그는 조지아 정교회를 재정립했고 조지아의 정부 총리(므트시노바르트 우쿠트세시)를 카톨리코스(대주교)로 임명하여 왕국과 밀접한 관계를 맺었다. 1110~1118년 사이에 다비트는 로리, 삼슈빌르데, 루스타비, 그리고 저지대의 카르틀리와 타쉬리의 요새들을 차지했고, 그로인해 트빌리시는 셀주크의 고립 영토로 전환 되었다.1118~1119년에, 터키 유목민들이 철수한 결과로 상당한 양의 무료에다가 정착이 안된 토지들이 많았고, 군대를 유지하기 위해서는 적격의 인력들이 절박하게 필요했기 때문에, 다비트 왕은 북캅카스로 부터 4만명 정도의 킵차크 전사들을 그들의 가족들과 함께 조지아에 정착하게 하려고 초대했다. 1120년에 알라니아의 통치자는 스스로를 다비트의 봉신으로 인식했으며 그 후 수천명의 알란인(주장된 바에 의하면 현대 시대의 오세트인)들이 중심 캅카스의 경계를 가로질러 조지아의 내부로 보내졌다. 그들은 조지아의 카르틀리에 정착했다. 조지아의 왕실 군대는 독일, 이탈리아, 스칸디나비아{서방에서 사는 모든 이들을 조지아에서는 \"프랑크인\"이라고 정의 되었었음}에서 뿐만 아니라 키예프 공국에서 보수를 목적으로 복무하러 온 사람들도 환영했다.1121년, 셀주크 술탄 마흐무드는 조지아에 지하드를 발령하고 조지아와 전투를 벌이기 위해 그의 유명한 장군 중에 한명인 를리그하지와 휘하의 강력한 군대를 보냈다. 투르크의 군사들의 수가 분명히 더 많았음에도 불구하고, 조지아는 디드고리 전투에서 침략자들을 훌륭히 무찔렀고, 1122년에는 그들은 트빌리시를 수도로 삼았다. 3년 후에 조지아는 쉬르반을 정복했고, 그 결과로, 대부분의 사람들이 기독교를 믿는 서부 쉬르반(한때 번영하고 있던 알바니아 왕국의 흔적)의 그히쉬-카발라 지역은 조지자에 의해서 합병되었다. 반면에 이미 이슬람교화 된 쉬르반의 나머지 지역은 조지아의 의존국이 되었다. 같은 해에 아르메니아의 광대한 부분이 다비트의 대군에 의해 해방되었고 뿐만 아니라 조지아의 손에 들어갔다. 그리하여 1124년에 다비트는 남아르메니아가 조지아 왕권의 영토로 편입한 아르메니아의 왕이되었다. 1125년에 다비트는 강력한 지역 권력의 지위를 가진 조지아를 남겨두고 세상을 떠났다. 조지아에서, 다비트 왕은 아그마셰네벨리(건설자, 영어: The Builder)로 불린다.다지드 아그마셰네벨리의 계승자들(데메테르 1세, 다비트 5세, 게오르게 3세 왕들)은 북캅카스의 대부분의 산악 씨족들과 부족들을 경시하고 더 나아가 쉬르반에 조지아의 입지를 확고히 하며 조지아의 확장 정책을 계속했다. 그러나, 그 기간에 조지아의 가장 명성 높은 주권자는 확실히 타마르 여왕(다비트의 증손녀)이다. 여왕 타마르 대제와 1184~1223년의 황금 시대 타마르 여왕의 통치는 국가의 역사 전체에서 일지도 모르는 조지아의 절정을 상징한다. 1194~1204년에 타마르의 군대들은 남쪽과 남쪽에서 온 새로운 터키군의 침략을 눌러 부쉈다. 터키가 통제하던 남아르메니아 방면으로 다양한 성공적인 군사 작전을 펼쳤다. 그 결과, 카린, 에르지니안 켈렛, 무슈와 반 도시들을 포함하는 대부분의 남아르베니아 대부분을 조지아의 통제권 아래로 가져왔고, 남아르메니아가 조지아의 보호국이 됨으로, 터키의 현지 에미르와 술탄의 이름뿐인 통치아래 남겨졌다.1204년에 십자군으로 인한 비잔티움 제국의 일시적인 몰락으로 조지아는 전체 동부 지중해 영역권에서 가장 강력한 기독교 왕국으로 남았다. 같은해 타마르 여왕은 아티나, 리자, 트레비존드, 케라순트, 아미소스, 코티오라, 헤라클레아와 시노파 도시들이 있는 이전 비잔티움의 라조나와 파리아드리아를 차지하기 위해 그녀의 군사들을 보냈다. 1024년에, 점유된 영토는 조지아에 의지하는 트레비존드의 제국으로 바뀌었다. 타마르의 친척인 알렉시오스 콤네노스 왕자는 그 제국의 왕좌에 앉았다. 1210년에 조지아의 군대들은 남부 페르시아(현재 이란인의 아제르바이잔)에 침략했고 조지아의 보호 제도 하에 정복된 영토의 일부분으로 배치한, 마란드, 타브리즈, 아르다빌, 쟈니안과 콰즈빈 도시들을 차지했다. 그러함은 그녀의 역사 전체에 걸쳐 조지아 최대의 영토 확장이었다. 타마르 여왕은 \"압하지야, 카르트벨스, 란스, 카크스, 아르메니아, 쉬르반-샤키네, 샤키네-안의-샤크의 여왕이며, 동과 서의 주권자\"로 호칭되었다. 조지아 역사가들은 종종 그녀를 \"여왕 타마르 대제\"로 기술했다.12세기 초반 ~ 13세기 초반 사이와, 특히 타마르 대제의 시대는, 진정하게 조지아의 황금시대라고 여겨질 수 있으며, 게다가 정치적이고 군사적인 그녀의 업적들과 더불어 건축, 문학, 철학과 과학을 포함하는 조지아 문화의 발달로 상징된다. 몽골의 침략과 조지아 왕국의 멸망 1220년대에, 남캅카스와 소아시아는 몽골의 침략과 대면했다. 조지아-아르메니아 군사력과 그들의 동맹에 의한 격렬한 저항에도 물구하고, 조지아와 아르메니아, 중앙 아나톨리아 영토들의 거의 대부분을 포함하는 모든 지역은 마침내 몽골에 의해 함락되었다.1243년에, 루수단 여왕은 조지아가 그녀의 의존국을 상실하여 몽골에 수여되는 몽골과의 평화 협정을 체결했고, 동부 쉬르반, 나키체반과 몇몇 다른 영토들을 마지못해 양도했으며, 몽골에 대한 인두세의 진상뿐만 아니라 남아있던 영토의 이상에 그들의 점유와 법적으로는 아니지만 사실상 데-펙토인 통치에도 동의했다. 몽골에 의해 점유된 트빌리시는 왕국의 공식적인 수도로 잔존했음에도 불구하고, 여왕은 그곳으로 돌아가기를 거절했고 1245년에 그녀가 죽기까지 쿠타이시에 머물렀다. 모든 고난 이상에다 더하여, 몽골로부터 자유롭게 남아있던 왕국의 부분까지도 해체되기 시작했다. 왕권은 그들이 인정한 몽골과의 관계를 확립하고 조지아에서 1266년에 실질적으로 양도한 삼트스케{조지아의 남부 속주들}의 여러 군사령관들에 대한 통제력을 잃어가기 시작했다.1259~1330년 사이의 기간은 조지아가 완전한 독립을 위해 몽골의 일카나테에 대항한 투쟁으로 상진된다. 첫 번째 반-몽골 봉기는 1259년에 다비트 나린의 지휘 하에 시작되었다. 사실상 그의 전쟁은 거의 3년의 기간동안을 뒤흔들었다. 반-몽골 분투는 다비트 데메테르 2세 왕(1270~1289)과 다비트 8세 왕(1294~1311)의 휘하에서도 계속되었고, 마침내, 일카나테의 몰락에 한 몫 단단히 한 찬란한 게오르게 왕이 몽골에 인두세를 진상하는 것을 취소했고, 1220년의 왕국 당시 조지아의 옛 국경들을 복원했고, 트레비존드의 제국을 조지아의 영향권 안으로 되돌렸다.1386~1403년에 조지아 왕국은 타메를란이 지휘하는 여덟번의 튀르크족과 몽골족의 침략을 맞닥드렸다. 압하지야와 스바네티야는 제외하고, 침략은 조지아의 경제, 인구와 도심을 황폐화 시켰다. 오스만과 페르시아의 지배 15세기에 전체 지역은 언어, 문화, 정치, 등의 모든 가능한 양상들에서 의해 극적으로 변화했다. 그 기간 동안에 조지아 왕국은 쇠퇴한 동로마 시대의 잔해는 대부분 투르크, 이란, 아랍 세계인 무슬림에 의해 포위되어 파손된 기독교의 외딴 영토로 고립되었다.15세기 중반 쯤에는, 조지아의 오랜 이웃 왕국들은 백년도 채 안되어 지도상에서 사라졌다. 1453년에는 오스만 투르크에 의해 콘스탄티노플의 함락되어 흑해는 봉쇄되었고 유럽지역 부터 기독교 왕국의 생존자들과 기독교 세계의 나머지 사람들은 목이 잘려나갔다. 조지아는 인접한 크림 반도의 제노아 식민지들을 통해서 서방과 연결된 상태로 남아있었다.그러한 변화들의 결과로, 조지아는 경제적이고 정치적인 쇠퇴를 겪게 됐고 1460년대에 왕국은 카르틀리 왕국, 이메레티 왕국과 삼트스케의 사아타바고(아타베그돔)의 몇몇 왕국들로 분열되었다.15세기 후반 즘에 오스만 제국은 서쪽 끝에서 부터 조지아의 왕국들을 잠식하고 있었고, 1501년에 새로운 무슬림의 세력인 사파비조 페르시아가 동쪽에서 떠올랐다. 다음 몇 세기 동안에, 조지아는 두 개의 거대한 경쟁 세력들의 전쟁터가 되어야 했고 조지아의 왕국들은 그들의 독립을 위한 투쟁을 해야했다. 1555년에, 오스만과 사파비조는, 서부의 이메레티는 터키에게 할양되고, 동부의 카르틀리-카케티는 페르시아에게 할양되는, 조지아에서의 영향권 범위를 정의하는 아마사의 평화 조약을 체결했다. 가장 강력한 사파비드 통지자 아바스 1세는 그의 장악권 아래로 동조지아를 가져오기 위해서 특별히 더 황폐화 시켰다. 수만명의 조지아인들이 살해당하거나 페르시아로 추방되었고 샤는 왕대비 케테반을 고문하여 죽였다. 17세기기 되자, 동조지아와 서조지아는 모두 계속되는 전쟁의 결과로 빈곤에 들어 침울했다. 경제 사정이 굉장히 나빴기 때문에 물물교환이 금전거래를 대체되었고 도시들의 인구수는 현저하게 감소했다. 1671년에 밍그렐리아 지역을 방문하게된 프랑스 여행가 진 카르딘은 소작농들의 가엾음, 귀족들의 거만함과 성직자의 무지함에 주목했다. 통치자들은 승인된 오스만이나 페르시아의 대군주국의 지위(종종 명목상의 이슬람 전환을 수반했음)로 나뉘었고 독립을 위한 노력을 계속했다. 북쪽에서 세 번째 왕국 세력의 출현, 크리스찬 모스크바, 후자가 점점 더 사람들의 마음을 끌었다. 러시아와 합병(18세기) 18세기 초반에 카르틀리는 새로운 법 체계를 제정하고 경제 발전을 위해 노력한 바흐탕 6세의 통치하에 부분적인 부흥을 보았다. 그의 통치 기간 중에 1709년에는 최초의 조지아어 인쇄 출판소의 설립을 보여줬다.1762~1798년의 카르틀리-카케티의 왕 에리클레 2세는 오스만과 페르시아의 공격에 대항하여 러시아의 보호로 방향을 돌렸다. 러시아의 예카테리나 여제는 터키에 대항하기 위해 조지아와의 동맹을 간절히 원했지만, 그들에게 빈약한 병력들만 파견했다. 1769~1772년 토틀레벤 장군과 그 휘하의 잘 훈련된 러시아 군사들은 이메레티와 카르틀리-카케티에서 터키의 침입군들에 대항하여 \"전투\"를 벌였다. 러시아 부대는 터키와의 충돌에 대비해서 철수했다. 1783년에 에레클레는 카르틀리-카케티가 러시아의 보호를 받음에 따라, 러시아와의 게오르기예프스키 조약에 서명했다. 그러나 1787년에 또 다른 러시아-튀르크 전쟁이 발발했을 때, 러시아는 그들의 병력들을 다른 그 지역에 사용하기 위해 에레클레의 왕국은 무방비 상태로 남겨두고 철수시켰다, 1795년, 페르시아의 샤 아그하 모함메드 칸이 나라를 침입했고 수도 트빌리시는 불태워져 공터가 되었다.게오르계프스크 조약의 조항에 대한 러시아의 명예가 실추되었음에도 불구하고, 조지아 통치자들은 터키군과 싸웠던 러시아의 부대가 아무도 다른 어떤 곳으로 돌아갈데가 없다고 여겼다. 에레클레가 죽고, 카르틀리-카케티의 왕위 계승권을 놓고 내전이 발발하고 한명의 경쟁 후보는 분쟁을 중재하고 해결하려는 러시아에 의해서 지명되었다. 1801년 1월 8일에 트사르 러시아의 파울 1세는 조지아와 카르틀리-카케티가 러시아 제국으로 편입하는 법령에 서명했고, 1801년 9월 12일에 트사르 알렉산드르 1세에 의해 비준되었다. 상트페테르부르크의 조지아 출신 외교관 가르세반 찹차바드제는 러시아의 차관 알렉산데르 쿠라킨이 남겨둔 항의 메모에 반발했다. 1801년 5월에 러시아 장군 카를 헤인리치 크놀링은 다비트 바토니시빌리를 태자에서 퇴위시켰고, 이반 트로비치 라사레프 장군의 명령에 의해 정부가 파괴되었다.조지아 귀족들의 일부는, 크놀링 장군이 트빌리시의 시오니 대성당에서의 귀족들을 억눌렀고 그들에게 러시아 제국 황권에 대한 충성 맹세를 강요했던 때인 1802년까지는, 포고를 인정하지 않았다. 포고에 반대하는 귀족들은 일시적으로 수감되었다.1805년 여름에 아스케라니 강과 자감 부근에 있던 러시아 부대는 페르시아 군대를 무찔렀고, 트빌리시를 그들의 공격으로부터 구했다. 1810년에 에메레티(서조지아) 왕국은 솔로몬 2세의 저항을 진압하고 난 후에 러시아 제국에 합병되었다. 1803~1878년에, 터키와 페르시아에 대항한 어마어마한 러시아의 전쟁의 결과로, 몇몇 조지아의 옛 영토틀이 러시아 제국에 합병되었다. 그 지역들(바투미, 아르트빈, 아칼트시케, 포티, 그리고 압하지야)는 지금은 조지아의 주 또는 독립자치국의 중요한 부분으로 존재한다. 조지아는 19세기에 한번 재통일 되었지만, 그들의 독립을 다시 상실했다. 러시아의 통치 러시아와 조지아는 공통점이 많았다. 주 종교가 정교회 기독교이며, 두 나라 다 토지를 소유한 귀족들이 농노의 인구들을 통치하고 있었다. 러시아 당국은 그들의 제국의 나머지 지역에 조지아를 통합시키려는데 목적이 있었지만, 처음에 러시아의 통치는 독단적이고, 변덕이 심했으며 지역 법과 관습에 무관심 했으므로, 1832년에 조지아의 귀족들이 음모를 꾸미게 했고, 1841년에는 소작농들과 귀족들에 의해 반란이 일어나게 만들었다. 그 사건들은 1845년 미하일 보론초프를 카프카스 총독으로 임명하는 변화를 안겨줬다. 보론초프 백작의 새 정책들은 그가 점점 더 유럽화 되는 귀족들 보다 성공적으로 우세하게 했다. 조지아 농노들의 생활은 매우 달라졌다. 그러나, 시골 경제는 심각하게 침체되어 있었다. 조지아의 농노들은 무시무시한 가난에 허덕이며 살았고 아사에 대한 빈번한 위협을 받았다. 그들 중 몇몇은 도심으로 가서 작은 노점상이나 노역을 하며 살았는데, 그 마을은 중세 시대에 조지아로 이주해 왔던 조상들을 두고 있는 아르메니아인들의 손아귀에 있었다.1861년에 러시아 땅들에서는 농노제도가 폐지되었다. 차르는 조지아의 농노들도 해방되기를 바랬지만, 농노들의 노동력에 의존하여 소득을 누리고 있는 귀족들의 충성심을 잃어서는 안되었다. 그래서 1864년부터 차츰 조지아 지방들에서 농노 제도가 폐지 되기 전에 세심한 협상이 요구되었다. 조지아 국가 운동의 성장 농노의 해방은 농노들이나 귀족들에게도 모두 만족스럽지 못했다. 농노의 가난은 완화되지 않았고 귀족들은 얼마간의 그들을 잃어갔다. 특정 귀족들은 자본주의화가 된 지역에서 번영하는 조지아의 아르메니아인 중산층과 같은 도시의 성장하는 세력에 위협을 느끼기도 했다. 차르 독재와 아르메니아인의 경제적 우세에 대한 조지아인들의 불만 은 19세기 후반기에 국가 해방 운동의 발달을 이끌었다.1905년에는 대규모의 소작농 반란이 일어났고, 그 반란은 당분간 긴장을 완화시키는 정치 개혁을 이끌었다. 그 기간 동안에는 마르크스주의 러시아 사회민주노동당이 조지아에서 지배적인 정치 활동을 하게 됐고, 1905년 이후에 수립된 러시아의 두마 의회에서 모든 조지아 의원들이 선출되었다. 조지아인 볼셰비키 조세프 비싸료노비치 드주가시빌리(조셉 스탈린으로 더 유명하게 알려짐)는 조지아에서 혁명(반 멘셰비키) 운동의 지도자가 되었다. 그는 다음에 더 나아가 소비에트 연방을 통제하게 됐다.많은 조지아인들이 조지아 정교회 독립 상실에 대해 당황했다. 러시아인 성직자들이 조지아의 교회들과 수도원들을 통제하게 됐고, 모든 조지아 전역에 걸쳐 조지아어 전례 사용을 금지 했으며 다양한 교회들의 중세 조지아의 프레스코화들을 훼손했다.1855~1907년 사이에 조지아 애국 운동이 세계적으로 명성 있는 시인이며 소설가이자 웅변가인 릴라 찹차바제 왕자의 지도 하에 착수되었다. 찹차바제는 새로운 조지아 학교들에 자금을 조달했고 조지아의 국가적인 공연을 지지했다. 그는 1877년에 이베리아 신문을 발행했고, 그 신문은 조지아 국가 의식 쇄신에 중요한 부분으로 역할 했다. 국가의 깨달음을 위한 그의 투쟁은 기오르기 체레텔리, 이바네 마차벨리, 아카키 체레텔리, 니코 니콜라제, 알렉산데르 카즈베기, 라콥 고게바시빌리와 같은 그 때의 지도층의 조지아인 지식인들에게 환영받았다.찹차바제 왕자와 조지아 독립에 대한 조지아 지식인들의 지지는 이 선언문에서 드러난다.\"우리의 애국심은 전적으로 다른 종류의 마음으로, 오직 우리들의 어머니의 땅을 향한 성스러운 감정에서 생겨났다. 우리들에게는 다른 나라들을 해칠 마음은 추호도 없으며 누구를 노예로 만들 욕망 따위도, 누구를 가난하게 몰아갈 마음도 전혀 없다. 오로지 애국자의 열정은 인권이 존재하는 사회에서 어느 누구도 빠짐없이 스스로의 정부로 그들 자신의 시민권을 위한 조지아의 권리를 복구하고 국민들의 특성과 문화를 보존하고자 함이다.\"19세기의 마지막 10년은 700년 전의 루스타벨리의 황금 시대 이래로 한결같지 않았던 진보속에서 나타난 작가들에 의한 조지아의 문학 부흥의 증거가 된다. 릴라 찹차바제 자신은 서정시와 발라드 시, 소설, 단편 소설, 수필과 같은 부분에서 모두 한결같이 탁월했다. 찹차바제와는 별도로, 그 시대에서 가장 다방면의 문학 천재는 \"조지아 사람들의 불멸의 나이팅게일\"로 알려진 아카키 체레틸리이다. 그를 따라 니코 니콜라제와 라콥 고게바시빌리, 그들의 문학 작품들은 국가 문화 부흥에 중대한 기여를 했으며, 그러므로 그들은 현대 조지아의 창립자들이라고 알려진다. 조지아 민주공화국(1918~1921년) 1917년의 러시아 혁명은 러시아를 피투성이의 내전으로 몰아 넣었고, 러시아의 중심에서 떨어진 몇몇 영토들은 독립을 공표했다. 조지아는 그 나라들 중 하나로, 1918년 5월 26일에 독립국으로의 그루지야 민주 공화국(DRG)의 수립을 선언했다. 새로운 나라는 러시아의 볼셰비키에 의해 성립된 \"프롤레타리아 독재\"와 뚜렷히 대비되는 다당제가 확립된 사회민주노동당의 멘셰비키 당파에 의해 통치되었다. 그 공화국은 러시아(1920년 모스크바 조약)과 1921년에 주요 서부 세력들에 의해서 승인되었다.1921년 2월 붉은 군대가 조지아를 침입했고 뒤이어 나라에는 짧은 전쟁이 발발했다. 조지아 정부는 피신할 수 밖에 없었다. 1921~1924년에 게릴라 저항이 1924년 8월 대규모 애국 봉기에 의해 잇따랐다. 카쿠차 촐로카시빌리는 그 사태에서 가장 주목을 끄는 게릴라 지도자들 중에 한명이었다. 소비에트 연방 소속(1921~1990년) 조지아 사건 기간 동안에, 조지아는 아르메니아, 아제르바이잔 그리고 조지아(압하지야와 남오세티야를 포함)로 구성된 자캅카스 소비에트 연방 사회주의 공화국에 강제적으로 합병되었다. 소비에트 당국은 조지아가 몇몇 지역을 터키(타오-클라르제티 주와 바투미주의 일부), 아제르바이잔(헤레티/사인길로 주), 아르메니아(로레 지역)과 러시아(동조지아)의 케비 북동부 끝에게 양도할 것을 강요했다. 소비에트의 지배는 가혹했다. 1921~1924년에는 약 5만명의 사람들이 처형당하거나 살해됐으며, 1935~1938년과 1942년, 1945~1951년에는 15만명 이상의 사람들이 스탈린과 그의 비밀 경찰 두목 라브렌티 베리아 하에서 추방되었다. 1936년에, TFSSR은 해산했고 조지아는 그루지야 소비에트 사회주의 공화국이 되었다.캅카스 유전 점령은 1941년 6월에 히틀러의 USSR 침입의 주요 목적들 중에 하나였지만, 추축국의 군대들은 조지아까지 가지 않았다. 나라는 붉은 군대에게 거의 7십만명의 군인들(35만명은 살해됨)을 갖다 바쳤고, 제조 직물들과 군수품의 중대한 보급처였다. 그러나 어떤 조지아인들은 조지아 대군을 구성하여 독일 군대의 편에 서서 싸웠다.그 기간 동안에 스탈린은 남부 캅카스의 체첸인들, 인구시인들, 카라차이인들과 발카리아 사람들의 국외 추방을 명령했다. 그들은 나치당과의 의심스러운 협동으로 인해 시베리아와 중앙 아시아로 이송되었다. 스탈린은 그들 각각의 자치 공화국을 폐지하였다. 그루지야 SSR은 1957년까지 그들 영토 중의 몇몇 지역들을 잠시 수여받았다.전쟁 동안에 스탈린의 애국 결속을 위한 성공적인 호소는 조지아의 민족주의를 가렸고, 이듬해에는 널리 퍼졌다. 1956년 3월 9일, 학생들이 모든 조지아 사람들과 문화의 전체적인 비판을 수반하는 흐루시초프의 탈스탈린화 정책에 대항하여 시위를 벌일 때 약 백명의 조지아 학생들이 살해 당했다.1950년대 중반에 흐루시초프에 의해 소개된 지방 분권 정책은 그루지야 공산당 임원들에 의해 그들의 지역 군사 기지를 건설하는데 공이 되었다. 번영하는 유사-자본주의 그림자 경제는 공식 국영 경제와 나란히 나타났다. 조지아의 공영 경제의 발전률은 소련 전체 공화국 중에 최하위였지만, 조지아를 경제적으로 가장 성공한 소비에트 공화국들 중에 한 나라로 만든, 저축 수준, 자동차과 집의 개인 소유 비율과 같은 지표에서는 연방에서 최상위였다. 부정부패는 고수준이었다. 모든 연방 공화국들 중에서, 조지아는 고등 또는 전문 중등교육을 받은 거주자들의 수가 가장 많았다.조지아에서의 부정부패가 소비에트 연방에 거의 알려지지 않았는데도 불구하고, 너무 팽배해 있었고 뻔뻔스러워서 모스크바 당국을 당혹스럽게 했다. 1964~1972년 사이에 국가 내무부 장관이었던 에두아르트 셰바르드나제는 부정부패와의 전쟁으로 명성을 얻었고 조지아 공산당의 부패한 첫 번째 총재 바실 므자바나제의 해임을 꾀했다. 셰바르드나제는 모스크바 당국의 승인을 받은 첫 번째 총재직에 올랐다. 그는 1965년부터 1972년까지의 계획 경제를 증진하고 부패한 수백명의 공무원을을 해임한 효과적이며 유능한 통지자였다. 모스크바가 조지아의 공무상의 국가 언어로 된 조지아어 헌법상의 개정을 지시했을 때 1978년에 소비에트와 조지아 국가주의가 충돌했다. 1978년 4월 14일에 군중 거리 시위의 압력이 심해지자, 모스크바는 그 해에 헌법의 보장으로 셰바르드나제의 복위를 허가했다. 4월 14일은 조지아어의 날로 지정되었다.1985년에 소비에트 외무부 장관으로의 셰바르드나제의 임명은 페레스트로이카의 도전자들과 함께 같이 궁핍하게 함께한 보수주의자이며 일반적으로 무능한 공산주의자 줌베르 파티아시빌리에 의해서 조지아에서 복위를 하게 했다. 1980년대 후반의 말기로 향해가며, 점점 더, 조지아의 소수 민족 거주 지역(명백하게 남오세티야)에서 공산주의 당국과 재기하는 조지아 국가주의 운동, 국가주의 운동가들의 폭력 충돌이 일어났다. 1989년 4월 9일, 소비에트의 부대들은 트빌리시에 있는 정부 청사에서의 평화 시위를 진압하는데 동원되었다. 20 명의 조지아인들이 살해당했고 수백명이 부상당했고 중독되었다. 그 사건은 많은 사람들과 소비에트 통치를 지속하다는 것보다 오히려 독립이 더 낫다고 결론 내린 몇몇 조지아 공산주의자들까지도 포함된 많은 사람들에게 경각심을 일깨워 조지아의 정치를 급진적이 되게 했다. 조지아의 후기-공산주의자들(1990~2003년) 공산주의 정부에 대한 반대파의 압력은 1990년 10월 28일 개최된 여러 당들과 민주주의 의회가 공개된 궁긍적인 결과인 대중 시위와 충돌로 명백해 졌다. 그들은 조지아 공화국 최고간부회의에 의장이 된 반체제 인사 지도자 즈뱌드 감사후르디아가 주도하는 \"원탁회의\"의 합동에 의해 당선되었다. 감사후르디아는 조금도 지체하지 않고 1991년 3월 31일에 독립 국민 투표를 실시했고, 98.9%의 득표율로 공인되었다. 그리하여 1991년 4월 9일에 소비에트 연방에서 부터 독립이 선언되었고, 많은 시간이 지나지 않았는데도 불구하고, 조지아의 독립은 미국과 유럽의 나라들과 같은 해외 강대국들에게 널리 인식되었다. 감사후르디아 정부는 공화국에 주둔하는 소비에트 군사 기지들과 같은 러시아 지배의 어떠한 흔적이라도 강력하게 반대했고, (소비에트 연방의 붕괴 이후에) 그의 정부는 독립 국가 연합(CIS)에 가입하는 것을 거절했다.감사후르디아는 1991년 5월 6일 86%의 선거 득표율로 대통령에 당선되었다. 그는 그후에 불안한 반-감사후르디아의 세력에 합세한 민족주의자들과 개혁론자에 의해 괴상하게 인식된 점과 정부의 독재주의 방식으로 인해 심한 비판의 대상이 되었다. 긴장된 상황은 당 간의 전투에 이용할 수 있는 엄청난 양의 이전-소비에트 군사 장비들과 준군사 조직들의 성장에 의해 악화되었다. 그 상황은 무장한 반대파들이 트빌리시의 중심에 있는 정부 청사에서 감사후르디아와 그의 지지자들을 에워싸면서 격렬한 군사 쿠데타를 일으키던 1991년 12월 22일에 정점에 달했다. 감사후르디아는 그의 적들을 피해서 교묘히 도망쳐 나왔고 1992년 1월에 러시아에서 분리된 체첸 공화국으로 피난갔다.새 정부는 곧이어 감사후르디아의 축출을 곧이어 확정짓게 했던 얼마간의 불미스러운 정치 제도에 대해서 온건한 태도로 1992년 3월에 국가 의회의 의장(대통령의 효력)이 된 에두아르트 셰바르드나제를 초청했다. 1992년 8월에, 정부 군사 및 준군사 세력이 분리주의 활동들을 진압하기 위해 지역적으로 파병되던 때, 조지아의 압하스 자치공화국에 대한 분쟁은 점차 커져갔다. 압하스는 러시아의 북캅카스 지역에서 온 준군사 부대의 도움을 입어 반격했고, 압하지야의 구다우타 기지에 배치된 러시아 군대의 비밀 지원군을 내세웠다. 1993년 9월에 정부군은 그 전투에서 내 몰려지게 된 최악의 패배를 맛봤고 그 지역의 모든 조지아계 거주민들은 추방되었다. 약 14,000명의 사람들이 죽었고 또다른 30만명은 달아날 수 밖에 없었다. 민족 투쟁은 남오세티야에서 타오르기도 했었는데, 마침내는 진압되었고, 수백명의 사상자들을 냈고 십만명의 난민들이 러시아의 통제 하의 북오세티야로 도주했다. 남서부 조지아에서는, 아자리야 자치 공화국이 트빌리시 당국이 약간의 영향권을 갖고 있던 개인 영지로 1991~2004년에 그의 공화국 통치를 수행해냈던, 아슬란 아바쉬제의 통제 아래 들었다.1993년 9월 24일의 압하스 재앙의 경야 때에, 즈뱌드 감사후르디아가 정부에 대항한 봉기를 조직하기 위해 추방된 곳에서 돌아왔다. 그의 지지자들은 정부 군대의 혼란을 자본화 할 수 있었고 서조지아의 많은 곳으로 급속히 퍼졌다. 그런 상황들은 러시아, 아르메니아와, 아제르바이잔에 경종을 울렸고, 러시아군의 부대들은 정부를 돕기 위해 조지아로 파병 되었다. 감사후르디아의 반란은 신속히 붕괴되었고 그는 1993년 12월 31일에 죽었는데, 그 때는 아무래도 그의 적들에 의해 궁지에 몰리게 된 다음 같다. 대단이 논란이 많은 협정에서, 셰바르드나제 정부는 군사적이고 정치적인 비용의 지원국의 일부로 CIS 가입을 승인해야 했다.셰바르드나제는 1995년 8월에 폭탄 공격에서 가까스로 살아남았는데, 그는 그 소행을 그의 옛날 준군사 동맹들의 소행으로 여겼다. 그는 준군사주의 지도자 자바 로셀리아니를 투옥할 기회를 잡았고 \"마피아 세력\"의 소탕 전쟁이 선포될 때 그 작전에 그의 므크헤드리오니 의용군 도입을 금지했다. 그러나, 그의 정부, 그리고 그와 가까운 가족들은, 점점 더 조지아의 경제 발전에 방해가 되는 침투성의 부정부패에 연루되어 갔다. 그는 1995년 11월과 2000년 4월의 대통령 선거에서 대다수의 크나큰 지지로 당선되었지만, 선거 조작에 의혹에 대한 집요한 탄원들이 있었다.체첸에서의 전쟁은, 체첸 게릴라들의 피난처에 대한 책임을 조지아에게 물어, 러시아와의 적지 않은 불화를 초래했다. 더나아가 불화는 셰바르드나제를 전략적 트랜스캅카스 지역에서의 러시아 영향력의 평형추로 본 미국에 대한 그의 외교 단절에 의해 야기 됐다. 조지아는 미국의 외교 및 군사의 원조를 받는 주요 국가가 되었고, NATO에게 전략적 협력국임을 알렸으며, NATO와 EU에 모두 가입할 포부가 있음을 선언했다. 2002년에, 미국은 조지아군을 훈련시키기 위하여 수백명의 특수작전부대를 파병했다. 훈련은 조지아 훈련 및 준비 프로그램으로 알려진다. 아마도 가장 의미심장한 것은, 조지아가 아제르바이잔에서 조지아를 거쳐 터키를 연결하는 60억 달러 규모의 송유관 건설(\"바쿠-트빌리시-세이한\" 또는 BTC 송유관으로도 불림)을 확정했다는 것이다. 셰바르드나제 이후의 조지아 미헤일 사카시빌리, 니노 부르드자나제와 주랍 즈바니아가 이끄는 민주주의자의 강력한 제휴는 셰바르드나제의 정부의 2004년 11월 2일의 위회 선거에 반대하여 연합되었다. 그 선거는 뻔뻔스럽게 조작된 것으로 널리 간주되었다. 그에 대한 반향으로, 반대파들은 트빌리시 대로에서 대규모의 반대 시위대를 조직했다. 팽팽한 긴장 상태로 2주일이 지나고, 셰바르드나제는 2003년 11월 23일에 사임하였고 부르드자나제에 의해 임시 원칙의 대통령으로 교체됐다.1월 4일, 미헤일 사카시빌리는 2004년 조지아 대통령 선거에서 96% 대다수의 압도적인 득표율로 당선되었다. 2월에는 헌법 개정안이 의회에 갑자기 나타나 대통령의 권한은 의회를 해산시킬 수 있게 강화되었고 차기 총리 제도를 만들었다. 주랍 즈바니아가 총리로 임명했고 임시 대통령이었던 니노 부르드자나제는 의장이 되었다.새 대통령은 정부에 나타난 많은 난관들과 직면했다. 23만명이 넘는 국내실향민들이 막대한 경제적 부담감에 시달렸다. 분리주의자들의 지역인 압하스와 남오세티야의 평화는 러시아와 유엔에 평화유지군과 국가간 기관들에 의해서 감독되었고 상황은 위태위태했다. 수년의 경제 발전과 협상은 지역간 적대감정의 극복이 요구됐다. 상당한 경과는 남오세티야-조지아 충돌에 대한 협상에서 다뤄졌고 협상들은 조지아-압하스 충돌에 대한 협상으로 계속되고 있다.장미 혁명 이후에, 조지아 정부와 준-분리주의 아자리아 지도자 아슬란 아바쉬제 간의 관계는 급속도로 악화되었고, 아바쉬제는 트빌리시 당국이 공문서로 아드자라에 보낸 사카시빌리의 요구를 거절했다. 양측 모두 군대를 동원했고 전쟁 준비 태세를 갖추었다. 사카시빌리의 최종 제안과 대규모의 거리 시위대는 아바쉬제가 사임하고 조지아를 떠날 것을 강요했다.러시아와의 관계는 압하스와 남오세티야의 분리주의 정부에 대한 러시아의 지속적인 정치적, 경제적이고 군사적 지원들 때문에 아직도 문제가 있는 상태로 남아있다. 러시아 부대들은 두 곳의 군사 기지에 있는 주둔지에 그 지역 평화유지군의 감시하에 아직도 남아있다. 분리주의자의 질문은 여전히 풀리지 않았으나, 그 문제를 해결하겠다는 사카시빌리의 공공 서약은 벌써부터 분리주의 지역들과 러시아의 비판을 선동하고 있다. 2004년 8월에는 남오세티야에 다양한 충돌이 발생하였다.NATO와 EU로의 통합은 조지아의 외교 정책에 중요한 목표로 남아있다. 2004년 9월 29일에, NATO의 북대서양 회의(NAC)는 조지아의 단일 참가 행동 계획(IPAP)을 승인했다. 조지아는 NATO의 협력국들 중에서 최초로 그런 과업들을 성공적으로 해냈다.조지아는 이라크에 협력군 지원을 계속하고 있다. 2004년 11월 8일에는, 300명의 조지아 잔여 병력들을 이라크로 파병했다. 조지아 정부는 UN 작전의 수비군의 임무를 수행하기 위해 도합 850명의 군인들을 이라크로 파병하기로 결정했다. 이라크에 주둔하는 조지아 병력들이 늘어남에 따라, 미국은 추가로 4천명의 조지아 군인들을 조지아군 훈련 및 준비 프로그램(GTEP)의 구역들에 배정하여 훈련시키기로 되어있다.2005년 2월에 국무총리 주랍 즈바니아가 죽고, 주랍 노가이델리가 새 국무총리로 임명되었다.사카시빌리는 아직도(2006년) 그의 개혁안을 이행하기 위해서 중대한 압박에 쌓여있다. 국제사면위원회와 같은 기구는 인권을 침해할 심각한 우려가 있다. 실업, 연금, 부패에 대한 불만과 압하스에서 계속되는 논쟁은 자국에서 사카시빌리의 평판을 크게 축소 시켰다.2006년에 조지아의 러시아와의 관계는 조지아-러시아 스파이 활동 논쟁과 그 논쟁과 관련된 사건들로 인해 현대 역사중에서 최하의 지경이다. 2007년의 정치적 위기는 중대한 반정부 시위를 야기시켰다.2007년에 또, 러시아는 조지아에 대항하여 연속적인 군사 작전을 감행했지만, 실패했다. 같이 보기 조지아 민주공화국조지아 정교회조지아의 문화조지아인조지아인 목록조지아 왕들의 목록조지아의 정치 참고 문헌 Avalov, Zurab: Prisoedinenie Gruzii k Rossii, Montvid, S.-Peterburg 1906Anchabadze, George: History of Georgia: A Short Sketch, Tbilisi, 2005, ISBN 99928-71-59-8Allen, W.E.D.: A History of the Georgian People, 1932Assatiani, N. and Bendianachvili, A.: Histoire de la Géorgie, Paris, 1997Braund, David: Georgia in Antiquity: A History of Colchis and Transcaucasian Iberia 550 BC-AD 562. Clarendon Press, Oxford 1994, ISBN 0-19-814473-3.Bremmer, Jan, & Taras, Ray, \"New States, New Politics: Building the Post-Soviet Nations\",Cambridge University Press, 1997Gvosdev, Nikolas K.: Imperial policies and perspectives towards Georgia: 1760-1819, Macmillan, Basingstoke 2000, ISBN 0-312-22990-9Iosseliani, P.: The Concise History of Georgian Church, 1883Lang, David M.: The last years of the Georgian Monarchy: 1658-1832, Columbia University Press, New York 1957Lang, David M.: The Georgians, 1966Lang, David M.: A Modern History of Georgia, 1962Manvelichvili, A: Histoire de la Georgie, Paris, 1955Salia, K.: A History of the Georgian Nation, Paris, 1983Suny, R.G.: The Making of the Georgian Nation, 2nd Edition, Bloomington and Indianapolis, 1994, ISBN 0-253-35579-6 각주  외부 링크 Georgia - A Country Study, Library of Congress List of rulers of GeorgiaKartuli Idea-The Georgian Idea by Dr. Levan Z. UrushadzeThe Bagrationi Royal Dynasty of Georgia by Dr. Levan Z. Urushadze.- Issued by the International Academy for the Promotion of Historical Studies (IAPHS), 2005 2002 Georgia timeline2003 Georgia timeline2004 Georgia timeline2005 Georgia timelineRobert Bedrosian's page of Armenian and Georgian Historical Sources (e.g. The Georgian Chronicle)\n--------------------------------------------------------------------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"문장으로 잘라 낸다"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkt')","execution_count":13,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the document into sentences\nko_grammar_sentences = []\nfor document in ko_grammar_set_raw:\n    ko_grammar_sentences += nltk.sent_tokenize(document)\n\nprint(\"Num sentences:\", len(ko_grammar_sentences))","execution_count":14,"outputs":[{"output_type":"stream","text":"Num sentences: 13841\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ko_grammar_sentences[11000]","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"'2년간의 비상사태가 해제된후 방글라데시에서 7년 만에 처음 치러진 87%의 선거율을 기록한 총선에서 셰이크 하시나 전 총리가 이끄는 연정이 의회 총 300석 중 245석을 확보한 가운데, 제 1야당은 31석을 얻는 데 그쳤다.'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"형태소 분리하여 모든 문장을 형태소 Code로 변환 한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from konlpy.tag import Twitter\ntwitter = Twitter()\n\nprint(twitter.pos(ko_grammar_sentences[305]))","execution_count":16,"outputs":[{"output_type":"stream","text":"[('백운호수', 'Noun'), ('에서', 'Josa'), ('의왕시', 'Noun'), ('와', 'Josa'), ('의왕시', 'Noun'), ('축제', 'Noun'), ('추진', 'Noun'), ('위원회', 'Noun'), ('가', 'Josa'), ('공동', 'Noun'), ('으로', 'Josa'), ('주최', 'Noun'), ('하여', 'Verb'), ('매년', 'Noun'), ('9월', 'Number'), ('에', 'Foreign'), ('이틀', 'Noun'), ('동안', 'Noun'), ('열리는', 'Verb'), ('축제', 'Noun'), ('이다', 'Josa'), ('.', 'Punctuation')]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 형태소 Code table의 구성\n\n_MAX_MORP_LENGTH = 128\n_PADDING_CODE = 0  # padding code\n_MISMATCH_CODE = 1 # mismatch word code               ex) @@@\n_MISMATCH_WORD = '@@@' # 이거 아래에서 쓴다.\n\nmorpheme_table = {}\nmorp_code = _MISMATCH_CODE+1\nmorpheme_table['Pad'] = _PADDING_CODE \nmorpheme_table['Mst'] = _MISMATCH_CODE \nfor sentence in ko_grammar_sentences[:1000]:\n    morphemes = twitter.pos(sentence)\n    for (word,morp) in morphemes:\n        if morp in morpheme_table:\n            pass\n        else:\n            morpheme_table[morp] = morp_code\n            morp_code += 1","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Korean morpheme code table')\nprint('----------------------------------------------------------')\nprint('  Morpheme        Code')\nprint('')\nfor morp in morpheme_table.keys():\n    print(f' {morp.ljust(15)}   {morpheme_table[morp]}')\nprint('----------------------------------------------------------')\n","execution_count":19,"outputs":[{"output_type":"stream","text":"Korean morpheme code table\n----------------------------------------------------------\n  Morpheme        Code\n\n Pad               0\n Mst               1\n Noun              2\n Punctuation       3\n Foreign           4\n Josa              5\n Verb              6\n Modifier          7\n Adjective         8\n Suffix            9\n Adverb            10\n Number            11\n Alpha             12\n Conjunction       13\n Determiner        14\n VerbPrefix        15\n Exclamation       16\n KoreanParticle    17\n Eomi              18\n ScreenName        19\n URL               20\n----------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# morpheme 코드 변환기\ndef morpheme_encode(sentence):\n    encode=[]\n    morphemes = twitter.pos(sentence)\n    for (word,morp) in morphemes:\n        encode.append(_MISMATCH_CODE if word==_MISMATCH_WORD else morpheme_table[morp])\n    return encode\n\ncode = morpheme_encode('야당이 수단으로 야당에게는 이라며 윤석열 허물어뜨렸고 수사를 군사작전을 하는 시비를 민주당 의원이 국민적 세워 화신이 나라 법위에 우려했다 될 이라며 운영할지 바람 짓밟지만 양자역학 양자역학 걱정하느냐고 누가 청와대 한다 엄포를 양자역학 양자역학 양자역학 편을 파렴치와 난관에 풀이다 대통령이 양자역학 저지하려다가')\nprint(f'Code length : {len(code)}')","execution_count":20,"outputs":[{"output_type":"stream","text":"Code length : 67\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 전체 형태소 코드로 변환\nko_grammar_set = []\nfor sentence in ko_grammar_sentences:\n    code = morpheme_encode(sentence)\n    if len(code) <= _MAX_MORP_LENGTH:\n        ko_grammar_set.append(code + [_PADDING_CODE for i in range(_MAX_MORP_LENGTH-len(code))])\n\nko_grammar_set = np.asarray(ko_grammar_set)\nko_grammar_set.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(13636, 128)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Dataset 전체 구성"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom transformers import BertTokenizer\n# embedder download...\nembedder = SentenceTransformer('xlm-r-large-en-ko-nli-ststb')","execution_count":22,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nBATCH_COUNT = 100","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset 다시 만듦\n\norg_text_emb = embedder.encode([org_text])[0]\nprint(f'Text embedding shape : {org_text_emb.shape}')\ndataset = []\nfor i in range(BATCH_COUNT):\n    emb_batch_set = []\n    cod_batch_set = []\n    for j in range(BATCH_SIZE):\n        emb_batch_set.append(org_text_emb)\n        cod_batch_set.append(ko_grammar_set[BATCH_SIZE*i+j])\n\n    emb_batch_set = np.asarray(emb_batch_set)\n    cod_batch_set = np.asarray(cod_batch_set)\n    dataset.append((emb_batch_set,cod_batch_set))\n\nprint(f'Total dataset count :{BATCH_COUNT*BATCH_SIZE}')","execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ded09cfff584e46921e0814655819b8"}},"metadata":{}},{"output_type":"stream","text":"\nText embedding shape : (1024,)\nTotal dataset count :6400\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 30번째 배치의 형태소코드셋 중 20번째꺼 확인\nprint(dataset[30][1][20])\nprint(dataset[31][1][20])","execution_count":25,"outputs":[{"output_type":"stream","text":"[2 9 2 5 2 2 5 6 2 2 5 6 2 2 5 2 5 6 3 2 5 2 5 2 6 2 5 6 2 5 6 6 2 8 3 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n[ 2  2  5  2  5  2  5  2  2  2  5  2  8  3  2  5  2  6  6  2  5  2  5  3\n 11  3 11  3 11  3 11  3 11  3 11  3 11  3  2  2  5  2  5  6  2  6  2  5\n  6  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Generator 구현"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts([org_text])\ntotal_words = len(tokenizer.word_index) + 1\n\nprint(f'Total token count of origin text : {total_words}')","execution_count":26,"outputs":[{"output_type":"stream","text":"Total token count of origin text : 395\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"일단 전체 크기를 한정한 generator를 구성한다.<br>\n향후, 이것은 LSTM을 이용해서 길게 만들 수 있을 것.\n\n_MAX_TOKEN = 512   ' Origin text의 전체 token 개수를 최대 512로 한정 <br>\n_MAX_LENGTH = 40   ' generator에 의해 생성하는 문자의 전체 token 개수를 40한정 <br>\n\n이는 512개의 token 원문을 40개의 token 으로 구성된 문장으로 요약 하는것...."},{"metadata":{"trusted":true},"cell_type":"code","source":"# max 512 token으로 만든다. 남는건 padding\n\n_MAX_TOKEN = 512\n_MAX_LENGTH = 40\n_NOISE_DIM = 100\n\nword_keys = []\nword_values = []\n\nfor word,index in tokenizer.word_index.items():\n    word_keys.append(index)\n    word_values.append(word)\n\ncurrent_token_len = len(word_keys)\n\nif current_token_len > _MAX_TOKEN:\n    word_keys = word_keys[:_MAX_TOKEN]\n    word_values = word_values[:_MAX_TOKEN]\nelse:\n    for i in range(current_token_len+1,_MAX_TOKEN+1):\n        word_keys.append(i)\n        word_values.append(_MISMATCH_WORD)\n","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Token table of origin text')\nprint('---------------------------------------------')\nprint(' Code         Token')\nprint('')\nfor k in word_keys:\n  print( f'  {str(k).ljust(8)}    {word_values[k-1]}')\nprint('---------------------------------------------')\n","execution_count":28,"outputs":[{"output_type":"stream","text":"Token table of origin text\n---------------------------------------------\n Code         Token\n\n  1           원내대표는\n  2           주\n  3           것\n  4           이라고\n  5           며\n  6           문재인\n  7           않는\n  8           문\n  9           이라며\n  10          이제\n  11          풀들이\n  12          수\n  13          대통령과\n  14          공수처는\n  15          될\n  16          있는\n  17          향해\n  18          보인다\n  19          짓밟힌\n  20          국민적\n  21          저항에\n  22          직면할\n  23          정권이\n  24          위해\n  25          공수처법을\n  26          제게\n  27          대통령은\n  28          '공수처는\n  29          없는\n  30          야당이\n  31          공수처장\n  32          사람들이\n  33          민주당\n  34          그러면서\n  35          공수처가\n  36          청와대와\n  37          왜\n  38          그\n  39          인정하지\n  40          이\n  41          공수처를\n  42          권력\n  43          게\n  44          정권의\n  45          민주당이\n  46          국회에서\n  47          그걸\n  48          권력은\n  49          먼저\n  50          주호영\n  51          국민의힘\n  52          22일\n  53          고위공직자범죄수사처\n  54          공수처\n  55          법\n  56          개정과\n  57          가덕도\n  58          신공항\n  59          건설\n  60          등을\n  61          밀어붙이고\n  62          정권과\n  63          더불어민주당을\n  64          끝이\n  65          아우성\n  66          치는\n  67          경고했다\n  68          이날\n  69          자신의\n  70          페이스북에\n  71          공수처법\n  72          개정을\n  73          위한\n  74          '군사작전'에\n  75          돌입하겠다고\n  76          엄포를\n  77          놓고\n  78          있다\n  79          정의당을\n  80          끌어들이기\n  81          꼼수\n  82          선거법에\n  83          묶어\n  84          '패스트트랙'이라는\n  85          불법·탈법으로\n  86          만들어낸\n  87          시행도\n  88          해보지\n  89          않고\n  90          고치려\n  91          하는\n  92          지적했다\n  93          이어\n  94          야당\n  95          원내대표인\n  96          사람\n  97          좋아보이는\n  98          표정으로\n  99          야당의\n  100         동의\n  101         없이는\n  102         절대\n  103         출범할\n  104         것'이라고\n  105         얘기했고\n  106         유엔\n  107         안보리\n  108         상임이사국처럼\n  109         임명에\n  110         '비토권'을\n  111         행사할\n  112         있는데\n  113         무얼\n  114         걱정하느냐고\n  115         여당\n  116         우리를\n  117         속였다\n  118         거짓말이라는\n  119         비난을\n  120         개의치\n  121         사람들\n  122         꼬집었다\n  123         이해찬\n  124         전\n  125         대표가\n  126         얘기한\n  127         '민주당\n  128         20년\n  129         집권'의\n  130         토대가\n  131         올해\n  132         안에\n  133         완성된다\n  134         탈원전과\n  135         동남권\n  136         신공항은\n  137         대통령이\n  138         대선\n  139         공약으로\n  140         내건\n  141         사업이니\n  142         여기에\n  143         불법이\n  144         있었다고\n  145         시비를\n  146         거는\n  147         것은\n  148         민주주의를\n  149         부정하는\n  150         것이라고\n  151         청와대\n  152         출신\n  153         윤건영\n  154         의원이\n  155         윽박지른다\n  156         '민주주의\n  157         민주당'이\n  158         법위에\n  159         군림하는\n  160         '반민주'를\n  161         거리낌없이\n  162         획책하는\n  163         언급했다\n  164         표를\n  165         얻기\n  166         나라\n  167         곳간을\n  168         다\n  169         허물어뜨렸고\n  170         재정\n  171         운용에서\n  172         신중함은\n  173         사라졌다\n  174         괴물\n  175         출범하면\n  176         공무원\n  177         누구나\n  178         권력이\n  179         지시하는\n  180         범죄행위에\n  181         거리낌\n  182         없이\n  183         가담할\n  184         것이다\n  185         권부\n  186         요직에\n  187         앉아\n  188         불법으로\n  189         각종\n  190         이권을\n  191         챙기는\n  192         권력자들에\n  193         대한\n  194         사건이\n  195         불거져도\n  196         사건을\n  197         가져가\n  198         버리면\n  199         그만\n  200         우려했다\n  201         고위\n  202         공직자들을\n  203         처벌하는\n  204         것인데\n  205         반대하는지\n  206         이해할\n  207         없다'고\n  208         했는데\n  209         그런\n  210         분이\n  211         대통령\n  212         주변을\n  213         감시하는\n  214         특별감찰관은\n  215         취임\n  216         이후\n  217         지금까지\n  218         임명하지\n  219         않았는가\n  220         라며\n  221         권력형\n  222         비리의\n  223         쓰레기\n  224         하치장\n  225         종말\n  226         처리장이\n  227         비판했다\n  228         정부를\n  229         사도들은\n  230         법치가\n  231         미치지\n  232         무오류의\n  233         화신이\n  234         오류를\n  235         존재가\n  236         바로\n  237         신이며\n  238         아래에는\n  239         자신들의\n  240         지도자를\n  241         목숨바쳐\n  242         지킴으로서\n  243         정의를\n  244         실현하겠다는\n  245         추종자들로\n  246         넘쳐\n  247         난다\n  248         지도자의\n  249         신성을\n  250         세력을\n  251         정죄하는\n  252         수단으로\n  253         전락할\n  254         질타했다\n  255         저도\n  256         법조인이지만\n  257         공수처장이\n  258         마음대로\n  259         검사들과\n  260         수사관들을\n  261         임명하는\n  262         끔찍한\n  263         사법기구가\n  264         어떤\n  265         일을\n  266         할지\n  267         두렵기만\n  268         하다\n  269         검찰과\n  270         경찰\n  271         위에\n  272         사법기구로\n  273         헌법과\n  274         법으로\n  275         독립성을\n  276         보장하는\n  277         검찰총장을\n  278         이렇게\n  279         핍박하는\n  280         어떻게\n  281         운영할지\n  282         불을\n  283         보듯\n  284         뻔한\n  285         일\n  286         예측했다\n  287         추미애\n  288         법무장관을\n  289         앞장\n  290         세워\n  291         윤석열\n  292         검찰의\n  293         비리\n  294         수사를\n  295         저지하려다가\n  296         난관에\n  297         봉착하자\n  298         무슨\n  299         수를\n  300         써서라도\n  301         출범시키려\n  302         한다\n  303         자리에는\n  304         추미애보다\n  305         더\n  306         한\n  307         막무가내\n  308         내\n  309         편을\n  310         앉힐\n  311         분명한\n  312         파렴치와\n  313         오만함을\n  314         최전선에서\n  315         온\n  316         몸으로\n  317         겪어온\n  318         저로서는\n  319         내일부터\n  320         보일\n  321         행태가\n  322         환히\n  323         180석의\n  324         또\n  325         군사작전을\n  326         개시하면\n  327         누가\n  328         막겠는가\n  329         라고\n  330         성토했다\n  331         막을\n  332         힘이\n  333         우리\n  334         야당에게는\n  335         없다\n  336         삭발하고\n  337         장외투쟁해\n  338         봐야\n  339         눈\n  340         하나\n  341         깜짝할\n  342         아닌\n  343         대란대치\n  344         大亂大治\n  345         세상을\n  346         온통\n  347         혼돈\n  348         속으로\n  349         밀어넣고\n  350         유지에\n  351         이용한다는\n  352         통치기술\n  353         규탄했다\n  354         아울러\n  355         바람\n  356         국민은\n  357         풀이다\n  358         바람이\n  359         불면\n  360         청보리\n  361         밭의\n  362         보리가\n  363         눕는다\n  364         다시는\n  365         일어서지\n  366         못하도록\n  367         풀을\n  368         짓밟지만\n  369         풀들은\n  370         다시\n  371         일어난다\n  372         시인\n  373         김수영은\n  374         '바람보다\n  375         눕지만\n  376         바람보다\n  377         일어나는'\n  378         민초의\n  379         힘을\n  380         노래했다\n  381         고\n  382         말했다\n  383         마지막으로\n  384         정권은\n  385         곧\n  386         광장에서\n  387         일어서서\n  388         아우성치는\n  389         모습을\n  390         지켜보게\n  391         대란대치를\n  392         끝장내려는\n  393         거듭\n  394         강조했다\n  395         @@@\n  396         @@@\n  397         @@@\n  398         @@@\n  399         @@@\n  400         @@@\n  401         @@@\n  402         @@@\n  403         @@@\n  404         @@@\n  405         @@@\n  406         @@@\n  407         @@@\n  408         @@@\n  409         @@@\n  410         @@@\n  411         @@@\n  412         @@@\n  413         @@@\n  414         @@@\n  415         @@@\n  416         @@@\n  417         @@@\n  418         @@@\n  419         @@@\n  420         @@@\n  421         @@@\n  422         @@@\n  423         @@@\n  424         @@@\n  425         @@@\n  426         @@@\n  427         @@@\n  428         @@@\n  429         @@@\n  430         @@@\n  431         @@@\n  432         @@@\n  433         @@@\n  434         @@@\n  435         @@@\n  436         @@@\n  437         @@@\n  438         @@@\n  439         @@@\n  440         @@@\n  441         @@@\n  442         @@@\n  443         @@@\n  444         @@@\n  445         @@@\n  446         @@@\n  447         @@@\n  448         @@@\n  449         @@@\n  450         @@@\n  451         @@@\n  452         @@@\n  453         @@@\n  454         @@@\n  455         @@@\n  456         @@@\n  457         @@@\n  458         @@@\n  459         @@@\n  460         @@@\n  461         @@@\n  462         @@@\n  463         @@@\n  464         @@@\n  465         @@@\n  466         @@@\n  467         @@@\n  468         @@@\n  469         @@@\n  470         @@@\n  471         @@@\n  472         @@@\n  473         @@@\n  474         @@@\n  475         @@@\n  476         @@@\n  477         @@@\n  478         @@@\n  479         @@@\n  480         @@@\n  481         @@@\n  482         @@@\n  483         @@@\n  484         @@@\n  485         @@@\n  486         @@@\n  487         @@@\n  488         @@@\n  489         @@@\n  490         @@@\n  491         @@@\n  492         @@@\n  493         @@@\n  494         @@@\n  495         @@@\n  496         @@@\n  497         @@@\n  498         @@@\n  499         @@@\n  500         @@@\n  501         @@@\n  502         @@@\n  503         @@@\n  504         @@@\n  505         @@@\n  506         @@@\n  507         @@@\n  508         @@@\n  509         @@@\n  510         @@@\n  511         @@@\n  512         @@@\n---------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input,\n                                     Dense, \n                                     BatchNormalization, \n                                     LeakyReLU,\n                                     Softmax,\n                                     Reshape, \n                                     Conv2DTranspose,\n                                     Conv2D,\n                                     Dropout,\n                                     Flatten,\n                                     Concatenate,\n                                     Lambda)\nimport matplotlib.pyplot as plt","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tensor용 Hash table 구성 \nkeys=tf.constant(word_keys,tf.int32)\nvalues=tf.constant(word_values, tf.string)\n# build a lookup table\nword_table = tf.lookup.StaticHashTable(\n    initializer=tf.lookup.KeyValueTensorInitializer(keys,values),\n    default_value=tf.constant(' '),\n    name=\"token_table\"\n)","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"noise를 token_table을 통해 text로 변환하는 변환기 구현"},{"metadata":{"trusted":true},"cell_type":"code","source":"# noise 생성\nw = tf.random.normal([2,_MAX_LENGTH,_MAX_TOKEN])","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\ndef to_text(w):\n\n    #tf.print(w)\n    texts = []\n    try:\n        for z in w:\n            text = \"\"\n            #code = []\n            for v in z:\n                try:\n                    #print(v)\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    text += '[   ] '                  \n            texts.append(text)\n\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return tf.constant(texts,dtype=tf.string)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to_text 함수의 test\ne = to_text(w)\nfor t in e:\n  print(t.numpy().decode('utf-8'))","execution_count":33,"outputs":[{"output_type":"stream","text":"검찰과 @@@ 앞장 그만 @@@ @@@ 사도들은 22일 보인다 @@@ 고 @@@ 주변을 독립성을 @@@ @@@ 야당의 재정 깜짝할 출범하면 @@@ @@@ 청와대와 @@@ @@@ 수단으로 불법이 '민주당 추미애보다 장외투쟁해 @@@ 여당 개시하면 @@@ 대선 얘기한 상임이사국처럼 밀어넣고 거는 감시하는 \n@@@ 자신의 표정으로 @@@ 오만함을 그러면서 '공수처는 국민적 @@@ @@@ 것인데 @@@   것'이라고 막무가내 거는 지도자를 @@@ 한다 추미애보다 @@@ @@@ @@@ @@@ 행사할 될 @@@ 불법·탈법으로 사람들이 마지막으로 개정과 정부를 @@@ 정부를 @@@ 없다'고 무슨 향해 사람들 성토했다 \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"생성된 text의 embedding 변환기 구현<br>\nembedding은 org_text의 embedding과 비교하여 원문과 유사하게 민들기 위한 목적"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이거 이틀걸림...잘 몰라서 ㅈㄴ 헤맴\n\n@tf.custom_gradient\ndef to_embedding(w):\n\n    def grad(dy):\n        dy_arr = tf.reshape(dy,(dy.shape[0],1024,1))\n        #tf.print(dy_arr)\n        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],_MAX_LENGTH*_MAX_TOKEN),method=tf.image.ResizeMethod.BILINEAR)\n        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],_MAX_LENGTH,_MAX_TOKEN))\n        return dy_arr_st\n\n    #print(w)    \n    texts = []\n    value = None\n    try:\n        for z in w:\n            text = \"\"\n            for v in z:\n                try:\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    text += '[   ] '                  \n            texts.append(text)\n        value = tf.constant(embedder.encode(texts,show_progress_bar=False),dtype=tf.float32)\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return value, grad","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to_embedding 함수의 test\ne = to_embedding(w)\nfor t in e:\n  print(t.numpy())","execution_count":35,"outputs":[{"output_type":"stream","text":"[ 0.13296802  0.02979132 -0.24835373 ... -0.10786134 -0.3754492\n  0.35479385]\n[ 0.8994534  -0.34656933  0.82252365 ... -0.4156555   0.19348423\n -0.11586136]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to_compression_ratio\n\n@tf.custom_gradient\ndef to_compression_ratio(w):\n    def grad(dy):\n        dy_arr = tf.reshape(dy,(dy.shape[0],1,1))\n        #tf.print(dy_arr)\n        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],_MAX_LENGTH*_MAX_TOKEN),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],_MAX_LENGTH,_MAX_TOKEN))        \n        return dy_arr_st\n    \n    const = 131328 # 512를 순서대로 다 더한값\n    value = None\n    compression_ratio = []\n    try:\n        for z in w:\n            cr = 0\n            for v in z:\n                try:\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    cr += key.numpy()\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    cr += 0                \n            compression_ratio.append(cr/const)\n        value = tf.constant(compression_ratio,dtype=tf.float32)\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return value, grad\n    ","execution_count":79,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to_compression_ratio 함수의 test\ne = to_compression_ratio(w)\nfor t in e:\n  print(t.numpy())","execution_count":66,"outputs":[{"output_type":"stream","text":"0.08695785\n0.07622898\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"생성된 text의 morpheme code 변환기 구현<br>\nmorpheme code는 한국어 문장들(dataset)의 morpheme code와 비교하여 한국어 문법에 가깝게 만들기 위한 목적"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n@tf.custom_gradient\ndef to_morpcoding(w):\n\n    def grad(dy):\n        dy_arr = tf.reshape(dy,(dy.shape[0],_MAX_MORP_LENGTH,1))\n        #tf.print(dy_arr)\n        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],_MAX_LENGTH*_MAX_TOKEN),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],_MAX_LENGTH,_MAX_TOKEN))\n        return dy_arr_st\n\n    #print(w)    \n    texts = []\n    codes = []\n    value = None\n    try:\n        for z in w:\n            text = \"\"\n            for v in z:\n                try:\n                    key = tf.argmax(v,output_type=tf.int32) #tf.constant(,dtype=tf.int32)\n                    text += word_table.lookup(key).numpy().decode('utf-8') + ' '\n                except Exception as ex:\n                    tf.print(ex,sys.exc_info())\n                    text += '[   ] '                  \n            texts.append(text)\n            \n        for sentence in texts:\n            code = morpheme_encode(sentence)\n            if len(code) <= _MAX_MORP_LENGTH:\n                codes.append(code + [_PADDING_CODE for i in range(_MAX_MORP_LENGTH-len(code))])\n            else:\n                codes.append(code[:_MAX_MORP_LENGTH])\n        value = tf.constant(codes,dtype=tf.int32)\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return value, grad","execution_count":80,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to_morpcoding 함수의 test\ne = to_morpcoding(w)\nfor t in e:\n  print(t.numpy())","execution_count":39,"outputs":[{"output_type":"stream","text":"[ 2  5  1  2 10  1  1  2  9  5 11  6  1  2  1  2  5  2  5  1  1  2  5  2\n  2  6  2  6  1  1  2  5  1  1  2  5  2  5  3  2  2  5  2  2  2  1  2  2\n  6  1  2  2  5  2  5  6  6  2  5  2  6  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  0  0  0  0  0  0  0  0]\n[1 2 5 2 5 1 8 8 3 7 7 2 5 2 9 1 1 2 5 1 2 3 5 2 2 5 2 5 1 6 2 5 1 1 1 1 2\n 6 6 1 2 3 2 5 2 9 5 2 5 2 5 2 5 1 2 5 1 8 3 2 2 2 6 2 9 7 2 6 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Network 구성을 위해 사용자 정의 Layer 를 구현"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이것도 잘 몰라서 하루 걸림... ㅜㅜ\n\nfrom keras import backend as K\nfrom keras.layers import Layer\n\n#tf.executing_eagerly()\n\nclass Post_processing(Layer):\n\n    def __init__(self, output_dim, encoder_func=None,Tout=tf.float32, **kwargs):\n        self.output_dim = output_dim\n        self.encoder = encoder_func\n        self.Tout = Tout\n        super(Post_processing, self).__init__(**kwargs)\n    '''\n    def build(self, input_shape):\n        tf.print('build',input_shape)\n        # 이 레이어에 대해 학습가능한 가중치 변수를 만듭니다.\n        self.kernel = self.add_weight(name='kernel', \n                                      shape=(input_shape[1], self.output_dim),\n                                      initializer='uniform',\n                                      trainable=True)\n        super(Post_processing, self).build(input_shape)  # 끝에서 꼭 이 함수를 호출하십시오\n    '''\n    def call(self, input_data):\n        #tf.print('Post_processing : call input_data',input_data.shape)\n        value = tf.py_function(self.encoder,[input_data],Tout=self.Tout,name='encode_func')\n        #print('value.shape:',value.shape)\n        #value.set_shape((input_data.shape[0],self.output_dim))\n        if self.output_dim > 0:\n            value.set_shape((input_data.shape[0],self.output_dim))\n        else:\n            value.set_shape((input_data.shape[0],))\n        #return tf.reshape(value,[input_data.shape[0]])  \n\n        #value = tf.Variable((tf.zeros([input_data.shape[0],1024]) if self.Tout==tf.float32 else tf.zeros([input_data.shape[0],])),dtype=self.Tout,shape=( (input_data.shape[0],1024) if self.Tout==tf.float32 else (input_data.shape[0],)))\n        #tf.py_function(self.encoder,[input_data],Tout=self.Tout)\n        return value\n\n    def compute_output_shape(self, input_shape):\n        tf.print('compute_output_shape:',input_shape)\n        input_shape = tensor_shape.TensorShape(input_shape).as_list()\n        if self.output_dim > 0:\n            return tensor_shape.TensorShape([input_shape[0], self.output_dim])\n        return tensor_shape.TensorShape([input_shape[0]])","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 구성한 Layer의 test\ne = Post_processing(1024,to_embedding,Tout=tf.float32)(w)\nfor c in e:\n  print(c)","execution_count":41,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[ 0.13296802  0.02979132 -0.24835373 ... -0.10786134 -0.3754492\n  0.35479385], shape=(1024,), dtype=float32)\ntf.Tensor(\n[ 0.8994534  -0.34656933  0.82252365 ... -0.4156555   0.19348423\n -0.11586136], shape=(1024,), dtype=float32)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 별로 중요하지는 않지만 Lambda layer를 활용하기 위한 assert 함수 구성\ndef assert_layer(input_data,out_dim=None):\n    #tf.print(input_data)\n    #print(input_data)\n    assert input_data.shape[1] == out_dim\n    return input_data","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 드디어 generator 구현\n# 효과적으로 구성된 것인지는 모르겠음... 이것은 아직 많은 연구가 필요함.\n# 또한 LSTM으로 바꾸어 길이의 한게를 극복해야 할 것...\n\ndef make_generator_model(max_length,total_words):\n    input = Input(shape=(_NOISE_DIM,), dtype='float32') \n    x1 = Dense(1024, use_bias=False)(input)\n    x1 = BatchNormalization()(x1)\n    x1 = LeakyReLU()(x1)\n    \n    #x1 = Dense(1024*2, use_bias=False)(x1)\n    #x1 = BatchNormalization()(x1)\n    #x1 = LeakyReLU()(x1)\n    \n    x1 = Dense(max_length*total_words, use_bias=False, activation='softmax')(x1)\n    x1 = Lambda(assert_layer,arguments={'out_dim':max_length*total_words})(x1)\n    x1 = Reshape((max_length, total_words))(x1)\n    #x1 = BatchNormalization()(x1)\n    #x1 = Softmax()(x1)        \n    #x1 = MyCustomLayer(max_length*total_words)(x1)\n    txt = Post_processing(0,to_text,Tout=tf.string)(x1)\n    emb = Post_processing(1024,to_embedding,Tout=tf.float32)(x1)\n    cmr = Post_processing(0,to_compression_ratio,Tout=tf.float32)(x1)\n    cod = Post_processing(128,to_morpcoding,Tout=tf.int32)(x1)\n    \n    model = Model(input,[txt,emb,cmr,cod])\n    \n    model.summary()\n    return model\n\ngenerator = make_generator_model(_MAX_LENGTH,_MAX_TOKEN)","execution_count":81,"outputs":[{"output_type":"stream","text":"Model: \"functional_13\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_10 (InputLayer)           [(None, 100)]        0                                            \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 1024)         102400      input_10[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 1024)         4096        dense_12[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)       (None, 1024)         0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 20480)        20971520    leaky_re_lu_6[0][0]              \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 20480)        0           dense_13[0][0]                   \n__________________________________________________________________________________________________\nreshape_9 (Reshape)             (None, 40, 512)      0           lambda_3[0][0]                   \n__________________________________________________________________________________________________\npost_processing_16 (Post_proces (None,)              0           reshape_9[0][0]                  \n__________________________________________________________________________________________________\npost_processing_17 (Post_proces (None, 1024)         0           reshape_9[0][0]                  \n__________________________________________________________________________________________________\npost_processing_18 (Post_proces (None,)              0           reshape_9[0][0]                  \n__________________________________________________________________________________________________\npost_processing_19 (Post_proces (None, 128)          0           reshape_9[0][0]                  \n==================================================================================================\nTotal params: 21,078,016\nTrainable params: 21,075,968\nNon-trainable params: 2,048\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generator의 test\n# Create a random noise and generate a sample\nnoise = tf.random.normal([3,_NOISE_DIM])\ntexts,embeddings,compratios,morpcodes = generator(noise, training=True)\nprint(texts.shape)\nfor i,txt in zip(range(len(texts)),texts):\n    print(f\" {i+1}> {txt.numpy().decode('utf-8')}\" )\nprint(embeddings.shape)\nprint(compratios.shape)\nprint(morpcodes.shape)","execution_count":68,"outputs":[{"output_type":"stream","text":"(3,)\n 1> 짓밟지만 사람들 끔찍한 @@@ 밀어넣고 오류를 밀어넣고 토대가 권력형 @@@ 원내대표인 @@@ 수사를 @@@ 며 청와대 놓고 공수처법 삭발하고 '민주당 오만함을 분명한 두렵기만 쓰레기 정의를 이 하치장 고위공직자범죄수사처 @@@ @@@ 종말 각종 김수영은 왜 행태가 있었다고 @@@ 개의치 실현하겠다는 @@@ \n 2> 대란대치를 성토했다 @@@ 하치장 수사를 이날 저도 @@@ 대통령 올해 수 언급했다 @@@ 없이 대한 @@@ @@@ 불면 내건 @@@ 짓밟힌 일어난다 보장하는 안에 삭발하고 얘기했고 막무가내   만들어낸 넘쳐 위한 @@@ 다시 개의치 강조했다 민주당'이 밭의 고위공직자범죄수사처 신공항 원내대표인 \n 3> 신이며 절대 @@@ @@@ 대란대치를 끌어들이기 고위 @@@ 행사할 @@@ 공직자들을 @@@ @@@ 의원이 법무장관을 것이라고 오류를 공수처장 앉아 지도자를 거리낌없이 환히 개정을 밀어넣고 그런 챙기는 비난을 수사관들을 대통령이 '패스트트랙'이라는 올해 이렇게 무오류의 다시 @@@ 정권은 @@@ 이해찬 검찰과 바람이 \n(3, 1024)\n(3,)\n(3, 128)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Discriminator 구현"},{"metadata":{},"cell_type":"markdown","source":"먼저 요약을 구분하기 위한 discriminator_summ 구현"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 문장에 대한 embeddings를 이용하여 org_text_emb (org_text의 embedding)과의 유사도를 계산한다.\nimport scipy\n\n@tf.custom_gradient\ndef to_similarity(w):\n\n    def grad(dy):\n        dy_arr = tf.reshape(dy,(dy.shape[0],1,1))\n        #tf.print(dy_arr)\n        dy_arr_st = tf.image.resize(dy_arr, size=(dy.shape[0],1024),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        dy_arr_st = tf.reshape(dy_arr_st,shape=(dy.shape[0],1024))\n        return dy_arr_st\n\n    similarities = []\n    value = None\n    try:\n        for embedding in w:\n            distances = scipy.spatial.distance.cdist([embedding], [org_text_emb], \"cosine\")[0]\n            similarities.append(distances[0])\n            \n        value = tf.constant(similarities,dtype=tf.float32)\n    except Exception as ex:\n        tf.print(ex,sys.exc_info())\n\n    return value, grad\n","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    input_emb = Input(shape=(1024,), dtype='float32') \n    x1 = Post_processing(0,to_similarity,Tout=tf.float32)(input_emb)\n    x1 = Reshape((1,))(x1)    \n    input_cmp = Input(shape=(), dtype='float32') \n    x2 = Reshape((1,))(input_cmp)\n    concatted = Concatenate(axis=1)([x1, x2])\n    x3 = Flatten()(concatted)\n    x3 = Dense(64, use_bias=False)(x3)\n    x3 = BatchNormalization()(x3)\n    x3 = LeakyReLU()(x3)\n    x3 = Dense(1)(x3)\n    \n    model = Model([input_emb,input_cmp],x3)\n    \n    model.summary()\n    \n    return model\n\ndiscriminator = make_discriminator_model()","execution_count":83,"outputs":[{"output_type":"stream","text":"Model: \"functional_15\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_11 (InputLayer)           [(None, 1024)]       0                                            \n__________________________________________________________________________________________________\npost_processing_20 (Post_proces (None,)              0           input_11[0][0]                   \n__________________________________________________________________________________________________\ninput_12 (InputLayer)           [(None,)]            0                                            \n__________________________________________________________________________________________________\nreshape_10 (Reshape)            (None, 1)            0           post_processing_20[0][0]         \n__________________________________________________________________________________________________\nreshape_11 (Reshape)            (None, 1)            0           input_12[0][0]                   \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 2)            0           reshape_10[0][0]                 \n                                                                 reshape_11[0][0]                 \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 2)            0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 64)           128         flatten_3[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 64)           256         dense_14[0][0]                   \n__________________________________________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)       (None, 64)           0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 1)            65          leaky_re_lu_7[0][0]              \n==================================================================================================\nTotal params: 449\nTrainable params: 321\nNon-trainable params: 128\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# discriminator test\n\npredict = discriminator([embeddings,compratios])\nprint(predict)","execution_count":71,"outputs":[{"output_type":"stream","text":"tf.Tensor(\n[[-0.13377783]\n [-0.13478307]\n [-0.13311213]], shape=(3, 1), dtype=float32)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# GAN 을 이용한 loss 의 gradient 구현 --> 빡심"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 디짐\n@tf.function\ndef train_step(real_embedding,real_morpcoding):\n  \n    # 1 - Create a random noise to feed it into the model\n    # for the text generation\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    \n    # 2 - Generate text and calculate loss values\n    # GradientTape method records operations for automatic differentiation.\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        texts,embeddings,compratios,morpcodes = generator(noise, training=True)\n        #embeddings = generator(noise, training=True)\n        # real에 가까우려면 discriminator의 학습은 real_embedding 이 zero (0)에 가깝게 학습시켜야 함.\n        # 하지만 압축율의 개념으로는 본래는 ones (1)가 맞음.\n        real_output = discriminator([real_embedding,np.zeros(len(real_embedding))], training=True)\n        fake_output = discriminator([embeddings,compratios], training=True)\n\n        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n        gen_loss = generator_loss(fake_output)\n        #tf.print('train_step : gen_loss=',gen_loss)\n        disc_loss = discriminator_loss(real_output, fake_output)\n        #tf.print('train_step : disc_loss=',disc_loss)\n\n    # 3 - Calculate gradients using loss values and model variables\n    # \"gradient\" method computes the gradient using \n    # operations recorded in context of this tape (gen_tape and disc_tape).\n    \n    # It accepts a target (e.g., gen_loss) variable and \n    # a source variable (e.g.,generator.trainable_variables)\n    # target --> a list or nested structure of Tensors or Variables to be differentiated.\n    # source --> a list or nested structure of Tensors or Variables.\n    # target will be differentiated against elements in sources.\n\n    # \"gradient\" method returns a list or nested structure of Tensors  \n    # (or IndexedSlices, or None), one for each element in sources. \n    # Returned structure is the same as the structure of sources.\n    \n    gradients_of_discriminator = disc_tape.gradient(disc_loss, \n                                                discriminator.trainable_variables)\n    #tf.print('train_step : gradients_of_discriminator=',gradients_of_discriminator)   \n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        texts,embeddings,compratios,morpcodes = generator(noise, training=True)\n        #embeddings = generator(noise, training=True)\n        #real_output = discriminator(real_embedding, training=True)\n        fake_output = discriminator([embeddings,compratios], training=True)\n\n        #tf.print('train_step : embeddings.shape=',embeddings.shape)\n        gen_loss = generator_loss(fake_output)\n        #tf.print('train_step : gen_loss=',gen_loss)\n        #disc_loss = discriminator_loss(real_output, fake_output)\n        #tf.print('train_step : disc_loss=',disc_loss)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, \n                                               generator.trainable_variables)\n    #tf.print('train_step : gradients_of_generator=',gradients_of_generator)\n \n\n    # 4 - Process  Gradients and Run the Optimizer\n    # \"apply_gradients\" method processes aggregated gradients. \n    # ex: optimizer.apply_gradients(zip(grads, vars))\n    \"\"\"\n    Example use of apply_gradients:\n    grads = tape.gradient(loss, vars)\n    grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n    # Processing aggregated gradients.\n    optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)\n    \"\"\"\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    #tf.print('train_step : after discriminator_optimizer')    ","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 60\nnoise_dim = _NOISE_DIM\n# 요약문 생성의 확인을 위해 3개의 문장을 생성하고 train과정에서 각 epoch마다 변화를 확인한다.\nseed = tf.random.normal([3, noise_dim])","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 생성된 문장의 원문 유사도를 측정하기 위한 함수\n\nimport scipy\n#print(doc_emb)\ndef similarity_score(queries,org_embedding):\n\n    total_score = 0\n    query_embeddings = embedder.encode(queries,show_progress_bar=False)\n    for query, query_embedding in zip(queries, query_embeddings):\n        distances = scipy.spatial.distance.cdist([query_embedding], [org_embedding], \"cosine\")[0]\n        results = zip(range(len(distances)), distances)\n        for idx, distance in results:\n            total_score += 1-distance\n    return total_score\n\nqueries = []\ntexts,embeddings,compratios,morpcodes = generator(seed,training=False)\n#count = 0\nfor t in texts:\n    summary_text = t.numpy().decode('utf-8')\n    queries.append(summary_text)\nprint('Similarity score:',str(similarity_score(queries,org_text_emb)))","execution_count":57,"outputs":[{"output_type":"stream","text":"Similarity score: 2.0951526949908965\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print iterations progress\nclass ProgressBar:\n    # pb = ProgressBar(total=20, prefix = 'Epoch 1')\n    def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '█', printEnd = \"\\r\"):\n        self.total = total\n        self.prefix = prefix\n        self.suffix = suffix\n        self.decimals = decimals\n        self.length = length\n        self.fill = fill\n        self.printEnd = printEnd\n        self.ite = 0\n    # pb.printProgress(1,'~~~~')\n    def printProgress(self,iteration, text):\n        self.ite += iteration\n        percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n\n        filledLength = int(self.length * self.ite // self.total)\n        bar = self.fill * filledLength + '-' * (self.length - filledLength)\n        print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n        # Print New Line on Complete\n        if self.ite == self.total: \n            print()","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom IPython import display # A command shell for interactive computing in Python.\nimport re\n\ndef train(dataset, epochs):\n    # A. For each epoch, do the following:\n    for epoch in range(epochs):\n        start = time.time()\n        pb = ProgressBar(total=BATCH_SIZE, prefix = f'Epoch:{str(epoch+1).ljust(3)}')\n        pb.printProgress(0,'Start batch.')\n        # 1 - For each batch of the epoch, \n        for batch_num,(emb_batch_set,cod_batch_set) in zip(range(len(dataset)),dataset):\n            # 1.a - run the custom \"train_step\" function\n            # we just declared above\n            #print(image_batch.shape)\n            train_step(emb_batch_set,cod_batch_set)\n            pb.printProgress(1,f'Time for batch {batch_num + 1} is {time.time()-start} sec')\n        # 4 - Print out the completed epoch no. and the time spent\n        #print (f'Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n        predictions_texts,predictions_embeddings = generator(seed,training=False)\n        count = 0\n        queries = []\n        for t in predictions_texts:\n            summary_text = t.numpy().decode('utf-8')\n            print('> ',summary_text)\n            queries.append(summary_text)\n            c = [m.start() for m in re.finditer(_MISMATCH_WORD, summary_text)]\n            count += len(c)\n        print('Mismatch count:',count,' Similarity score:',str(similarity_score(queries,doc_emb)))\n        print('')","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(dataset, EPOCHS)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch:1   |--------------------| 3.1%   Time for epoch 1 is 100.84358191490173 sec","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}